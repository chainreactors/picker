---
title: Scam Sites at Scale: LLMs Fueling a GenAI Criminal Revolution
url: https://www.netcraft.com/blog/llms-fueling-gen-ai-criminal-revolution/
source: Over Security - Cybersecurity news aggregator
date: 2024-08-30
fetch_date: 2025-10-06T18:07:34.165902
---

# Scam Sites at Scale: LLMs Fueling a GenAI Criminal Revolution

[**GUIDE:** The Total Economic Impactâ¢ of Netcraft Brand Protection | Download now â](../lp/forrester-tei-study)

[Pricing](../get-pricing)

[Contact Us](../contact)

[Report Fraud](https://report.netcraft.com/)

[Login](https://services.netcraft.com/)

Platform

Solutions

[Why Netcraft](../why-netcraft)

Resources

Company

[GET Demo](../book-a-demo)

[**GUIDE:** The Total Economic Impactâ¢ of Netcraft Brand Protection | Download now â](../lp/forrester-tei-study)

[**GUIDE:** The Total Economic Impactâ¢ of Netcraft Brand Protection | Download now â](../lp/forrester-tei-study)

[Pricing](../get-pricing)

[Contact Us](../contact)

[Report Fraud](https://report.netcraft.com/)

[Login](https://services.netcraft.com/)

Platform

Solutions

[Why Netcraft](../why-netcraft)

Resources

Company

[GET Demo](../book-a-demo)

[**GUIDE:** The Total Economic Impactâ¢ of Netcraft Brand Protection | Download now â](../lp/forrester-tei-study)

[## ALL POSTS](../resources/blog)

[## ALL POSTS](../resources/blog)

[## ALL POSTS](../resources/blog)

# Scam Sites at Scale: LLMs Fueling a GenAI Criminal Revolution

By

By

By

Will Barnes

Will Barnes

Will Barnes

|

|

|

August 29, 2024

August 29, 2024

August 29, 2024

![](https://framerusercontent.com/images/jxxRGtMLzq6QxJ4GYRCCbx2QFQ.svg?width=27&height=28)

![](https://framerusercontent.com/images/qxE8AF5N0tvgi2NQPrJxo2Fjec8.svg?width=27&height=28)

![](https://framerusercontent.com/images/iPf6JKc4mxyBKQ0kzbQ3awaw.svg?width=27&height=28)

![Reddit logo](https://framerusercontent.com/images/SgQ1svDD2syGHlolx4eeBq0UPA.svg?width=28&height=29)

![](https://framerusercontent.com/images/i5FusiiIJ7C5eGWkAxwQ99JpYyw.png?width=1424&height=718)

![](https://framerusercontent.com/images/i5FusiiIJ7C5eGWkAxwQ99JpYyw.png?width=1424&height=718)

![](https://framerusercontent.com/images/i5FusiiIJ7C5eGWkAxwQ99JpYyw.png?width=1424&height=718)

![](https://framerusercontent.com/images/i5FusiiIJ7C5eGWkAxwQ99JpYyw.png?width=1424&height=718)

**This article explores Netcraftâs research into the use of generative artificial intelligence (GenAI) to create text for fraudulent websites in 2024. Insights include:**

* **A 3.95x increase in websites with AI-generated text observed between March and August 2024, with a 5.2x increase over a 30-day period starting July 6, and a 2.75x increase in July aloneâa trend which we expect to continue over the coming months**
* **A correlation between the July spike in activity and one specific threat actor**
* **Thousands of malicious websites across the 100+ attack types we support**
* **AI text is being used to generate text in phishing emails as well as copy on fake online shopping websites, unlicensed pharmacies, and investment platforms**
* **How AI is improving search engine optimization (SEO) rankings for malicious content**

July 2024 saw a surge in large language models (LLMs) being used to generate content for phishing websites and fake shops. Netcraft was routinely identifying thousands of websites each week using AI-generated content. However, in that month alone we saw a 2.75x increase (165 per day on the week centered January 1 vs 450 domains per day on the week centered July 31) with no influencing changes to detection. This spike can be attributed to one specific threat actor setting up fake shops, whose extensive use of LLMs to rewrite product descriptions contributed to a 30% uplift in the month's activity.

These numbers offer insight into the exponential volume and speed with which fraudulent online content could grow in the coming year; if more threat actors adopt the same GenAI-driven tactics, we can expect to see more of these spikes in activity and a greater upward trend overall.

![](https://framerusercontent.com/images/5WNFvoAoNKdVhfiYOg8eTamR500.png?width=1024&height=779)

Fig 1. Screenshot showing indicators of LLM use in product descriptions by the July threat actor

This and the broader growth in activity between March and August appears to indicate a mass universal scaling up of GenAI being used as a content creation tool for fraudulent websites, with a notable spike showing in the realm of [online stores](https://www.netcraft.com/blog/fake-online-stores-see-black-friday-spike/). This has led to an abundance of malicious websites, attracting victims not only because of the sheer volume of content, but also because of how convincing that content has become.

Cybercrime groups, like other businesses, can create more content in less time using GenAI tools. Over the last 6 months, weâve identified threat actors using these technologies across a range of attacks, from [innovating advance fee-fraud](https://www.netcraft.com/blog/fbi-worldbank-deepfake-scam-analysis/) to [spamming out the crypto space](https://www.netcraft.com/blog/ai-generated-gitbook-lures-phishing-the-crypto-industry/). In total, our observations show LLM-generated text being used across a variety of the [100+ attack types we cover](https://www.netcraft.com/platform/disruption-takedowns/), with tens of thousands of sites showing these indicators.

![](https://framerusercontent.com/images/86AJrLBZNtpimKRI8gBuKYtuVM.png?width=1024&height=590)

*Fig 2. Graph showing the increase in observed websites using LLM-generated text between March and August 2024*

In this article, we explore just the tip of the iceberg: clear-cut cases of websites using AI-generated text. There are many more, with conclusive evidence pointing to the large-scale use of LLMs in more subtle attacks. The security implication of these findings is that organizations must stay vigilant; website text written in professional English is no longer a strong indicator of its legitimacy. With GenAI making it easier to trick humans, technical measures like blocking and taking down content are becoming increasingly critical for defending individuals and brands.

The following examplesâextracted from Netcraft first-party researchâwill help you understand how threat actors are using GenAI tools and shine a light on their motivations.

## âAs an AI language model, I can make scam emails more believableâ

Threat actors in the most traditional forms of cybercrimeâlike phishing and advance fee fraud emailsâare enhancing their craft with GenAI. In one particular campaign, we identified spam feeds containing cloud phishing emails falsely claiming to link to a file download for the userâs family photos:

![](https://framerusercontent.com/images/zZu5qW2by6vM7rwSllDEpeT1dQ.png?width=855&height=721)

*Fig 3.*

![](https://framerusercontent.com/images/i0Lwnw069FuyDLg0g7bARUmcfE.png?width=1024&height=599)

*Fig 4.*

*pCloud phishing email (Fig 3) leading to a traditional phishing URL on my[.]pcloud[.]ltd (Fig 4)*

In this campaign, running since at least the start of June 2024, the prospect of cherished memories being lost to file deletion is used as a lure to a traditional phishing URL. The potential indicator of LLM usage here is âCertainly! Here are 50 more phrases for a family photo:â We might theorize that threat actors, using ChatGPT to generate the email body text, mistakenly included the introduction line in their randomizer. This case suggests a combination of both GenAI and traditional techniques.

Weâve seen signs of threat actorsâ prompts being leaked in responses, providing insight into how they are now employing LLMs. In our [Conversational Scam Intelligence service](https://www.netcraft.com/csi-webinar/#:~:text=Using%20Conversational%20Scam%20Intelligence%2C%20Netcraft's,butchering%2C%20and%20advance%20fee%20fraud.)âwhich uses proprietary AI personas to interact with criminals in real-timeâour team has observed scammers using LLMs to rewrite emails in professional English to make them more convincing. As you can see from the screenshot below in fig 5, what appears to be the LLMâs response to a prompt to rewrite the threat actorâs original text has been accidentally included in the email body. We repor...