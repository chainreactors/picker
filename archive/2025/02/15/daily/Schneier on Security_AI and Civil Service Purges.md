---
title: AI and Civil Service Purges
url: https://www.schneier.com/blog/archives/2025/02/ai-and-civil-service-purges.html
source: Schneier on Security
date: 2025-02-15
fetch_date: 2025-10-06T20:39:44.028088
---

# AI and Civil Service Purges

# [Schneier on Security](https://www.schneier.com/)

Menu

* [Blog](https://www.schneier.com)
* [Newsletter](https://www.schneier.com/crypto-gram/)
* [Books](https://www.schneier.com/books/)
* [Essays](https://www.schneier.com/essays/)
* [News](https://www.schneier.com/news/)
* [Talks](https://www.schneier.com/talks/)
* [Academic](https://www.schneier.com/academic/)
* [About Me](https://www.schneier.com/blog/about/)

### Search

*Powered by [DuckDuckGo](https://duckduckgo.com/)*

Blog

Essays

Whole site

### Subscribe

[![Atom](https://www.schneier.com/wp-content/uploads/2019/10/rss-32px.png)](https://www.schneier.com/feed/atom/)[![Facebook](https://www.schneier.com/wp-content/uploads/2019/10/facebook-32px.png)](https://www.facebook.com/bruce.schneier)[![Twitter](https://www.schneier.com/wp-content/uploads/2019/10/twitter-32px.png)](https://twitter.com/schneierblog)[![Email](https://www.schneier.com/wp-content/uploads/2019/10/email-32px.png)](https://www.schneier.com/crypto-gram)

[Home](https://www.schneier.com)[Blog](https://www.schneier.com/blog/archives/)

## AI and Civil Service Purges

Donald Trump and Elon Musk’s chaotic approach to reform is upending government operations. Critical functions have been [halted](https://www.theguardian.com/us-news/2025/feb/05/musk-doge-takeover-usaid), tens of thousands of federal staffers are being encouraged to [resign](https://www.wsj.com/lifestyle/careers/federal-workers-accept-buyout-offers-be1c00fb), and congressional mandates are being [disregarded](https://thehill.com/business/5124133-democrats-bill-treasury-system-musk/). The next phase: The Department of Government Efficiency [reportedly](https://www.nytimes.com/2025/02/03/technology/musk-allies-ai-government.html) wants to use AI to cut costs. According to *The Washington Post*, Musk’s group has started to [run sensitive data](https://www.washingtonpost.com/nation/2025/02/06/elon-musk-doge-ai-department-education/) from government systems through AI programs to analyze spending and determine what could be pruned. This may lead to the elimination of human jobs in favor of automation. As one government official who has been tracking Musk’s DOGE team told the *Post*, the ultimate aim is to use AI to replace “[the human workforce with machines](https://www.washingtonpost.com/business/2025/02/08/doge-musk-goals/).” (Spokespeople for the White House and DOGE did not respond to requests for comment.)

Using AI to make government more efficient is a worthy pursuit, and this is not a new idea. The Biden administration disclosed more than 2,000 [AI applications](https://github.com/ombegov/2024-Federal-AI-Use-Case-Inventory) in development across the federal government. For example, [FEMA](https://www.dhs.gov/ai/use-case-inventory/fema) has started using AI to help perform damage assessment in disaster areas. The [Centers for Medicare and Medicaid Services](https://ai.cms.gov/assets/CMS_AI_Playbook.pdf) has started using AI to look for fraudulent billing. The idea of replacing dedicated and principled civil servants with AI agents, however, *is* new—and complicated.

The civil service—the massive cadre of employees who operate government agencies—plays a vital role in translating laws and policy into the operation of society. New presidents can issue sweeping executive orders, but they often have no real effect until they actually change the behavior of public servants. Whether you think of these people as essential and [inspiring](https://www.washingtonpost.com/opinions/interactive/2024/michael-lewis-conclusion-who-is-government/) do-gooders, boring bureaucratic functionaries, or as agents of a “[deep state](https://www.theatlantic.com/health/archive/2024/11/deep-state-public-health-trump-kennedy/680621/),” their sheer number and continuity act as ballast that resists institutional change.

This is why Trump and Musk’s actions are so significant. The more AI decision making is integrated into government, the easier change will be. If human workers are widely replaced with AI, executives will have unilateral authority to instantaneously alter the behavior of the government, profoundly raising the stakes for transitions of power in democracy. Trump’s unprecedented purge of the civil service might be the last time a president needs to replace the human beings in government in order to dictate its new functions. Future leaders may do so at the press of a button.

To be clear, the use of AI by the executive branch doesn’t have to be disastrous. In theory, it could allow new leadership to swiftly implement the wishes of its electorate. But this could go very badly in the hands of an authoritarian leader. AI systems concentrate power at the top, so they could allow an executive to effectuate change over sprawling bureaucracies instantaneously. Firing and replacing tens of thousands of human bureaucrats is a huge undertaking. Swapping one AI out for another, or modifying the rules that those AIs operate by, would be much simpler.

Social-welfare programs, if automated with AI, could be redirected to systematically benefit one group and disadvantage another with a single prompt change. Immigration-enforcement agencies could prioritize people for investigation and detainment with one instruction. Regulatory-enforcement agencies that monitor corporate behavior for malfeasance could turn their attention to, or away from, any given company on a whim.

Even if Congress were motivated to fight back against Trump and Musk, or against a future president seeking to bulldoze the will of the legislature, the absolute power to command AI agents would make it easier to subvert legislative intent. AI [has the power to diminish](https://www.techpolicy.press/anatomy-of-an-ai-coup/) representative politics. Written law is never fully determinative of the actions of government—there is always wiggle room for presidents, appointed leaders, and civil servants to exercise their own judgment. Whether intentional or not, whether charitably or not, each of these actors uses discretion. In human systems, that discretion is widely distributed across many individuals—people who, in the case of career civil servants, usually outlast presidencies.

Today, the AI ecosystem is dominated by a small number of corporations that decide how the most widely used AI models are designed, which data they are trained on, and which instructions they follow. Because their work is [largely secretive and unaccountable](https://crfm.stanford.edu/fmti/paper.pdf) to public interest, these tech companies are capable of making changes to the bias of AI systems—either generally or with aim at specific governmental use cases—that are invisible to the rest of us. And these private actors are both vulnerable to coercion by political leaders and self-interested in appealing to their favor. Musk himself created and funded xAI, now one of the world’s largest AI labs, with an [explicitly ideological](https://www.zdnet.com/article/i-tried-xs-anti-woke-grok-ai-chatbot-the-results-were-the-opposite-of-what-i-expected/) mandate to generate anti-“woke” AI and [steer](https://www.wired.com/llm-political-bias/) the wider AI industry in a similar direction.

But there’s a second way that AI’s transformation of government could go. AI development could happen inside of transparent and accountable public institutions, alongside its continued development by Big Tech. Applications of AI in democratic governments could be focused on benefitting public servants and the communities they serve by, for example, making it easier for non-English speakers to access government services, making ministerial tasks such as processing routine applications more efficient and reducing backlogs, or helping constituents weigh in on the policies deliberated by their representatives. Such AI integrations should be done gradually and carefully, with public oversight for their design and implementation and monitoring and guardrails to avoid unacceptable bi...