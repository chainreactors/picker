---
title: 阿西莫夫三定律，还适用于今天的 AI 吗？
url: https://mp.weixin.qq.com/s?__biz=MTMwNDMwODQ0MQ==&mid=2653073110&idx=1&sn=b277757d83dc66d3c5755989bdf48f50&chksm=7e57d36049205a76146ef55cb30a443f45110c7828858b74358ef216851bb3d2050790c61b32&scene=58&subscene=0#rd
source: 极客公园
date: 2025-02-03
fetch_date: 2025-10-06T20:35:39.946787
---

# 阿西莫夫三定律，还适用于今天的 AI 吗？

![cover_image](https://mmbiz.qpic.cn/mmbiz_jpg/8cu01Kavc5YicUicDlynEwnp259M3jfPRNN2ru4TSVup8Ysvv8WMzGuAdyM0v2ywUkcrg584LUwUiaEh0I9ef34PA/0?wx_fmt=jpeg)

# 阿西莫夫三定律，还适用于今天的 AI 吗？

原创

汤一涛

极客公园

![](https://mmbiz.qpic.cn/mmbiz_png/8cu01Kavc5YicUicDlynEwnp259M3jfPRN4QQIF3foRhGUDGSsPW6ZN86bfZR4YJNVk4mlzvfzFIPCta24ebKnhw/640?wx_fmt=png&from=appmsg)

艺术只提供提问，不提供答案，后者需要一点点试出来。

**作者 | 汤一涛****编辑**| 靖宇****

1942 年，伟大的科幻作家艾萨克·阿西莫夫（Isaac Asimov）在他的短篇小说《转圈圈》（Runaround）中首次提出了「机器人三定律」。之后，这些定律因为他的短篇小说集《我，机器人》而广为流传。

> 1、机器人不得伤害人类，也不得因不作为而使人类受到伤害。
>
> 2、机器人必须服从人类给予它的命令，除非这些命令与第一法则相冲突。
>
> 3、机器人必须保护自己的存在，只要这种保护不与第一或第二定律相冲突。

机器人三定律的影响是如此之大，它不但构成了阿西莫夫所有机器人科幻小说的组织原则，甚至渗透进了之后几乎所有的机器人科幻小说，以及所有引用它的书籍、电影、游戏等流行文化中。

例如，1966 年的短篇小说《萨姆的密码》中的「阿森尼翁机器人的三大法则」，就是对机器人三定律的改编；1999 年的电影《2001 太空漫游》中，罗宾·威廉姆斯（Robin Williams）饰演的机器人安德鲁，通过其头部的投影仪全息展示了机器人三定律；至于威尔·史密斯（Will Smith）主演的《我，机器人》，更是花费整部电影的时间详细讨论了这三大定律。

![](https://mmbiz.qpic.cn/mmbiz_png/8cu01Kavc5YicUicDlynEwnp259M3jfPRN7ZTB9oqPn9syvCbnUmsjSicRuibse3NkQV65RFibbic7uIiapDLXLUMhZqQ/640?wx_fmt=png&from=appmsg)安德鲁向新主人马丁一家讲解机器人三定律｜图片来源：medium

**人们甚至发展出了一门专门研究人与机器人关系的学科——机器人伦理学**。这是一门以人类为责任主体，研究如何开发和应用机器人的伦理学。追踪其源头，就是阿西莫夫的三定律。

在阿西莫夫生活的年代，人工智能还处于相当早期的阶段。论文《神经活动中内在思想的逻辑演算》（A Logical Calculus of Ideas Immanent in Nervous Activity）被视为人工智能学科的奠基石，这篇论文在机器人三定律发表后一年公布；直到 1956 年，达特茅斯人工智能夏季研讨会召开，人工智能作为一门学科，才真正创立。

**也就是说，机器人三定律是在一种小说家社会实验的语境下诞生的**。

如果借鉴原教旨主义的概念的话，机器人三定律可以算是机器人伦理学的原教旨主义。今天当然还有众多阿西莫夫的信徒，但是人工智能的现实环境已与当初大不相同。

**这让人不禁十分好奇，在 AI 如此火热的当下，****作为原教旨的机器人三定律，还能指导今天人与 AI 的关系吗**？

***01***

**作为创作工具的机器人三定律**

很难脱离机器人三定律的创作背景讨论它的意义。阿西莫夫在 1975 年接受 Sy Bourgin 采访时提到，他创作机器人三定律的动机，是为了摆脱此前科幻小说《弗兰肯斯坦》式的套路——也就是机器人杀害主人，创造物最终会摧毁其创造者。

因此，从本质上来说，机器人三定律不是一个全面的道德框架，它们是为故事服务的创作工具。它们被创作出来的目的，就是为了**突出一种不确定性、一种冲突的潜在可能，以探讨人与 AI 之间的灰色边界**。

一个有力的证据就是，在阿西莫夫的每一个故事中，机器人三定律都失败了。阿西莫夫故意模棱两可地创造了这 3 个定律，以便制造困境，让角色和观众都面临道德困境。

一旦运用到真实世界，这 3 条被称为「定律」的东西就会轰然崩塌。例如，巡航导弹、军用无人机就是违反第一和第三定律的机器人。它们由计算机控制，只会做它们被编程去做的事情。如果它们被编程去伤害人类，它们就会伤害人类。

从语言学的角度来说，机器人三定律也是无法成立的。因为这 3 项定律是用英语写成的，英语是一种自然语言，本质上是模棱两可的，可以有多种解释。因此，**将机器人三定律编码成精确的、机器可读的指令是不切实际的**。

来自武汉大学哲学系的克里斯·斯托克斯（Chris Stokes）更是在他的论文《Why the three laws of robotics do not work》中逐一解释了为什么机器人三定律是行不通的：

> 1、第一条法则失败是因为语言上的歧义，以及因为过于复杂的伦理问题，这些问题太复杂，无法简单地用是或否来回答。
>
> 2、第二定律失败，因为要求有感知的生物保持奴隶状态的定律，本质上是不道德的。
>
> 3、第三定律失败，因为它导致永久的社会分层，这个定律体系中内置了大量的潜在剥削。

正如 iRobot 的创始人罗德尼·布鲁克斯（Rodney Brooks）所说：「人们问我，我们的机器人是否遵循阿西莫夫的法则。它们不遵循的原因很简单——我无法将阿西莫夫的法则植入它们体内！」

iRobot 的名字正是来自于阿西莫夫的短篇小说集《I，Robot》。这家公司最出名的两个产品，**是扫地机器人和军用武装机器人**。

***02***

**人类的恐惧**

2022 年汤加火山的爆发曾经引发过一场关于「无夏之年」的恐慌。历史上，每逢无夏之年，都会引起气温骤降，进而导致全球性的灾难。

上一个无夏之年发生在 1816 年，印尼的坦博拉火山爆发。积聚的火山灰让全球气温至少下降了 0.4 度，气候反常引起了全球范围内的饥荒、伤寒和暴乱。

那个「潮湿、不适、连绵降雨」的夏天，迫使新婚的雪莱夫妇滞留在了拜伦在日内瓦湖畔的别墅。为了打发时间，拜伦提出了一场写作比赛，看谁能写出最恐怖的故事。雪莱的妻子—玛丽，在那段时间里写出了《弗兰肯斯坦》。

![](https://mmbiz.qpic.cn/mmbiz_png/8cu01Kavc5YicUicDlynEwnp259M3jfPRNfd4zSZudDWmmPhiac4lErdfcib0Gm5peSzIuL5EocxH1dPuewOPpBu8A/640?wx_fmt=png&from=appmsg)1910 年，爱迪生工作室制作了《弗兰肯斯坦》的第一个电影改编版｜图片来源：Wikipedia

今天我们记得《弗兰肯斯坦》当然是因为它是世界上第一部科幻小说。但是请注意，玛丽参加的可是一个恐怖故事比赛，《弗兰肯斯坦》有什么恐怖的呢？

《弗兰肯斯坦》讲述的是生物学家弗兰肯斯坦，利用人类尸体拼凑出了一个怪物。在被人类排斥的过程中，怪物对弗兰肯斯坦产生了怨恨，杀死了他的众多亲友。弗兰肯斯坦最后也因追捕怪物而死。

德国科布伦茨大学的乌尔里克·巴塞尔梅斯（Ulrike Barthelmess）和乌尔里希·福尔巴赫（Ulrich Furbach）认为，《弗兰肯斯坦》反映出的是人类数千年内心的恐惧，即**人类不能像上帝那样创造生物，任何试图这么做的人都会受到惩罚**。

另一个例子是 16 世纪的犹太神话里魔像（Golem）的传说。在其中的一个版本里，拉比利用粘土创造出了魔像，以保护犹太人社区。拉比承诺在每次安息日前关闭魔像以让他休息。但有一次拉比忘记了，于是魔像变成了一个屠杀社区的怪物。

![](https://mmbiz.qpic.cn/mmbiz_png/8cu01Kavc5YicUicDlynEwnp259M3jfPRNNjR9LW3xpwYDUrRoBAHcmP6ADDdtDDbszkw9vicndDSKYAVgbwG2FwA/640?wx_fmt=png&from=appmsg)布拉格的玛哈拉尔与魔像，1899｜图片作者：Mikoláš Aleš

正如美国电影理论家布莱恩·亨德森 (Brian Henderson) 所说，重要的是讲述神话的年代，而不是神话所讲述的年代。换句话说，神话当然是虚构的，但是当时的人们，出于何种动机、何种背景，讲述这样的神话，才是真正重要的。

进一步将「创造生物」这个概念扩展开来，**这种对「创造物」的恐惧，或许也可以理解成一种对技术的恐惧**。希腊神话里，因为将火传播于人间，普罗米修斯受到上帝惩罚，每日受老鹰啄食肝脏之苦。在这个故事中，「火」即技术。有一种学术观点认为，正是因为掌握了火，吃上了熟食，人类才不用耗费大量的能量消化生食，才得以进化出了发达的大脑。与此同时，正是利用了其他动物对火的恐惧，人类才得以在夜间抵御野兽。

巧合的是，《弗兰肯斯坦》的副标题恰好是「另一个普罗米修斯的故事」。

在近现代，人类对技术的恐怖更加常见。例如在工业革命时期的英国，人们就对机器改变世界的能力产生了极大的恐惧，开始了一场专门摧毁纺织机的运动。这场运动的后果是如此严重，以至于议会立法将拆除机器定为死罪。其中一个被称为「卢德分子」的团体，甚至和英国军队爆发了冲突。在今天，「卢德分子」依然用来描述一切新科技的反对者，他们被称为「新卢德分子」。

![](https://mmbiz.qpic.cn/mmbiz_png/8cu01Kavc5YicUicDlynEwnp259M3jfPRNfExv5Vx2JGZydibZ548ynOXwJzN6uGN2F1ubp36jaMQ2IwIUvBhvzjg/640?wx_fmt=png&from=appmsg)卢德运动领袖，1812｜图片来源：Wikipedia

**当我们带着恐惧的视角审视机器人三定律的时候，就可以看到其中充满了对机器人的严防死守，以及背后幽微深长的恐惧心理**。

与此同时，它天然将机器人置于了完全服从的奴隶地位（机器人 robot 源自捷克语 robota，意思正是「强迫劳动」）。这会成为一个问题，取决于我们看待机器人的视角。当我们把机器人视为「工具」时，这是合理的；但是**当我们把机器人视为有感知的生物、甚至连****它****们****自己****也这么觉得时，那这两个「种族」就是天然矛盾的，冲突迟早会发生**。

三江学院副教授、作家刘勃在描述魏晋南北朝时期，北方游牧民族和汉民族之间的民族仇杀时是这么解释的：「当经济优势和政治优势属于同一方的时候，通过建立威权体系，勉强可以维持社会的正常运转，一旦两个优势分属双方，社会的撕裂也就难以避免。」

这个问题放在今天的世界仍然适用。

而眼下，AI 正在做我们认为我们最擅长的所有事情。在某些情况下，它要比人类表现得好得多。在肉眼可见的将来，它也会越来越强大。

***03***

**现实中的机器人法则**

遗憾的是，目前现实世界中并没有一部通行的法律实行。机器人、AI、自动驾驶这些近似的概念相互混杂，有所交叉又各有不同；针对特定国家、地区制订的建议、指导方针、道德框架可以说是一锅大杂烩。

在国家层面，欧美国家是最积极的立法推动者。

欧盟 2024 年的 AI 法案是截至目前最严格的监管法案。它禁止将 AI 用于社会评分目的（利用个人数据个性化推荐就是社会评分的范畴），限制 AI 在犯罪画像中的使用，并要求对 AI 生成的内容进行标签。对被归类为对健康、安全或基本权利构成高风险的 AI 开发者，欧盟 AI 法案制定了一系列特殊要求。

美国国会还没有提出全面的关于 AI 的法案，但在州一级，硅谷所在的加州最为积极。其州长最近签署了 17 项人工智能法案，包括从保护表演者的数字形象到禁止与选举相关的深度伪造。加拿大正试图采取与欧盟类似的方法，其执政党提议已经提议了《人工智能和数据法案》（AIDA）。

相对于机器人三定律对人工智能的强烈限制，**这些法案的共同点在于限制的主体是 AI 的创造者、使用者，也即人类本身**。

![](https://mmbiz.qpic.cn/mmbiz_png/8cu01Kavc5YicUicDlynEwnp259M3jfPRNFU8Om1k1NmDangC7kt7u0pP9DDXMBZ6C647BUTibG9CCChLI6YSYBdQ/640?wx_fmt=png&from=appmsg)欧美国家对于 AI 的相关限制法案同样心口不一｜图片来源：caravel law

与此同时，欧美的监管遭到了大型科技公司的反对。OpenAI CEO Sam Altman 就称，如果监管过于严格，OpenAI 可能会离开欧洲；扎克伯格也在 8 月发表了一篇评论，将欧盟的监管方法描述为「复杂且不连贯」，警告这可能会破坏一个「一代人一次」的创新机会，以及利用 AI 的「经济增长机会」的机会。

在加拿大，亚马逊和微软的高管公开谴责了 AIDA，称其含糊不清且负担沉重；Meta 表示，它可能会推迟在加拿大推出某些人工智能产品。

而在一些非西方国家，态度则截然不同。他们优先考虑的不是监管，而是吸引大型科技公司的投资。印度是最典型的例子，它拥有中美以外最大的互联网产业。目前，印度政府已投入 12 亿美元用于名为「印度 AI」的倡议。其总理莫迪 9 月在一次圆桌会议上与硅谷 CEO 们会面时，他敦促他们「在印度与世界共同开发、共同设计和共同生产」。

目前印度在人工智能领域尚没有监管。而科技巨头方面，OpenAI 承诺通过大量投资开发者社区来支持印度 AI 倡议；亚马逊已拨出数亿美元支持印度人工智能初创企业，并与印度理工学院（IIT）签署了多年人工智能合作协议；微软最近也承诺在印度投资 30 亿美元，用于人工智能培训、云和人工智能基础设施。

可以说，科技巨头在一定层面上极大地影响了全球政府的政策。他们既是 AI 的创造者，也是最大的利益相关者。面对 AI 这样一种超越国界的国界的工具，各国可以制定自己的法律，但也必须就一些基本规则达成共识。毕竟，如果牌桌上连规则都没有的话，这局游戏是必然要崩盘的。

***04***

**AI 自己的建议**

那么，机器或者 AI 自己，是如何看待这个问题的？

最后，我们询问了 ChatGPT，该如何完善阿西莫夫的机器人三定律，以下是它的回答：

1. **增强对人类自主性的尊重**

阿西莫夫的第一定律强调了机器人不能伤害人类，或者因不作为而让人类受到伤害。为了增强 AI 对人类自主性和隐私的尊重，可以增加类似「AI 必须尊重个体的自主选择和隐私权」的原则。例如：

**新建议**：「AI 必须尊重人类的自由意志、隐私权和选择，避免对人类的决策产生不正当影响。」

2. **多层次的责任分配**

阿西莫夫的定律中没有明确如何界定 AI 错误行为的责任，导致可能出现责任归属不清的问题。在现代社会，AI 系统的决策可能涉及复杂的道德和法律层面。因此，应增加条款明确责任归属，避免「责任空白」。

**新建议**：「在 AI 行为引发的问题上，应明确 AI 使用者、开发者、监管机构等多方的责任，并对其行为进行透明化追踪。」

3. **对 AI 的自我意识和自我约束的控制**

阿西莫夫的三定律基于机器人没有自我意识的假设，但随着 AI 技术的发展，越来越多的 AI 系统具备了某种程度的自我学习和适应能力。为了防止 AI 做出不符合人类利益的决策，建议在 AI 系统中嵌入「自我约束」的机制。

**新建议**：「AI 系统必须具备自我约束机制，确保其行为始终符合人类的伦理标准，并具有撤销决策或行为的能力。」

4. **强化道德与伦理框架**

随着 AI 在社会各个层面的深入应用，其决策不仅关乎技术层面的合理性，还涉及伦理问题。例如，AI 在医疗、司法等敏感领域的决策需要更加谨慎。因此，可以建议在三定律中明确规定 AI 系统必须在处理决策时考虑伦理和社会价值观。

**新建议**：「AI 应始终遵循公认的道德和伦理标准，并在处理复杂决策时优先考虑公平、正义和人类福祉。」

5. **可调节性与透明度**

现代 AI 系统往往是黑箱式的，难以理解其决策过程。为了增强人类对 AI 的信任，需要规定 AI 系统应当具备透明度，确保其行为和决策可以被理解、审查和调整。

**新建议**：「AI 的决策过程必须透明，且可由合适的主体审查和调整，以确保其行为符合社会规范和人类利益。」

6. **限制 AI 的目标设定**

如果 AI 的目标设定不当，它可能会采取意外的手段去实现目标，导致对人类的潜在伤害。因此，AI 的目标必须在设计阶段就加以严格限制，确保其目标始终符合人类长远利益。

**新建议**：「AI 的目标设定必须明确受限于人类福祉和社会整体利益，避免执行可能导致长期负面后果的目标。」

不用说，上面这些大词，和当年阿西莫夫创作的「三定律」一样，很难以代码形式「植入」进机器的「芯」中。

也许，正是这种难以完全理解和掌握，才更让 AI 和机器人，更加的让人们欲罢不能吧。

\*头图来源：Salon

本文为极客公园原创文章，转载请联系极客君微信 geekparkGO

**极客一问**

**AI 对机器人三定律****提出**

**的完善建议，你觉得靠谱吗****？**

![](https://mmbiz.qpic.cn/mmbiz_png/8cu01Kavc5YTxYGib55rtMHhP1YJ44FLtVGp8Keyg6D2X3AUhgNicT1ibKKh0fE1eiaGqkSXnTlW0ib96ib3HDAIrnVA/640?wx_fmt=png)

![](https://mmbiz.qpic.cn/mmbiz_png/8cu01Kavc5bo8ia6aJpme5xWlYibaHvSIJ85Kt18K0yX1jvA0lvHsuzCyEYSUvWYqdHOZ6nszkrkchs8EtSVM7zA/640?wx_fmt=png)

![](https://mmbiz.qpic.cn/mmbiz_png/8cu01Kavc5an0KBXb9IbCwiajJefiaywlMX2G9daxebRIz0bpONcZbhCkA7mNIG39fwRUOEzpoBIPvAXIuA82B9Q/640?wx_fmt=png)

**热点视频**

马斯克：年轻人应该戒色，你的 CPU 想色色想得快烧了。

**点赞关注****极客公园视频号****，**

**观看更多精彩视频**

**![](https://mmbiz.qpic.cn/mmbiz_png/8cu01Kavc5an0KBXb9IbCwiajJefiaywlMX2G9daxebRIz0bpONcZbhCkA7mNIG39fwRUOEzpoBIPvAXIuA82B9Q/640?wx...