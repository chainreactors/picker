---
title: Zero-Click AI Vulnerability Exposes Microsoft 365 Copilot Data Without User Interaction
url: https://thehackernews.com/2025/06/zero-click-ai-vulnerability-exposes.html
source: The Hacker News
date: 2025-06-13
fetch_date: 2025-10-06T23:00:43.033549
---

# Zero-Click AI Vulnerability Exposes Microsoft 365 Copilot Data Without User Interaction

#1 Trusted Cybersecurity News Platform

Followed by 5.20+ million[**](https://twitter.com/thehackersnews)
[**](https://www.linkedin.com/company/thehackernews/)
[**](https://www.facebook.com/thehackernews)

[![The Hacker News Logo](data:image/png;base64...)](/)

**

**

[** Subscribe – Get Latest News](#email-outer)

* [** Home](/)
* [** Newsletter](#email-outer)
* [** Webinars](/p/upcoming-hacker-news-webinars.html)

* [Home](/)
* [Data Breaches](/search/label/data%20breach)
* [Cyber Attacks](/search/label/Cyber%20Attack)
* [Vulnerabilities](/search/label/Vulnerability)
* [Webinars](/p/upcoming-hacker-news-webinars.html)
* [Expert Insights](https://thehackernews.com/expert-insights/)
* [Contact](/p/submit-news.html)

**

**

**

Resources

* [Webinars](/p/upcoming-hacker-news-webinars.html)
* [Free eBooks](https://thehackernews.tradepub.com)

About Site

* [About THN](/p/about-us.html)
* [Jobs](/p/careers-technical-writer-designer-and.html)
* [Advertise with us](/p/advertising-with-hacker-news.html)

Contact/Tip Us

[**

Reach out to get featured—contact us to send your exclusive story idea, research, hacks, or ask us a question or leave a comment/feedback!](/p/submit-news.html)

Follow Us On Social Media

[**](https://www.facebook.com/thehackernews)
[**](https://twitter.com/thehackersnews)
[**](https://www.linkedin.com/company/thehackernews/)
[**](https://www.youtube.com/c/thehackernews?sub_confirmation=1)
[**](https://www.instagram.com/thehackernews/)

[** RSS Feeds](https://feeds.feedburner.com/TheHackersNews)
[** Email Alerts](#email-outer)

[![Salesforce Security Handbook](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjWa8tsMNqlevi1HGF1ALQRGIq7hROPFAbHd3R1RTEOe73T8_Q2xW_-91t2jSGjU5peiPb8QYblGp4igNW-u2Qmlxbp2BKzTVMSvyXDZJmC-BYpiiJHrcnG5drmSP97iZ9PVIf1DeEr7U-7vWpe4HXwfMjt8FGNgq5mOycOJluYr9wF7YOKrQY9MfArwgjt/s728-e100/ai-agent-security-d.png)](https://thehackernews.uk/ai-agent-security-d)

# [Zero-Click AI Vulnerability Exposes Microsoft 365 Copilot Data Without User Interaction](https://thehackernews.com/2025/06/zero-click-ai-vulnerability-exposes.html)

**Jun 12, 2025**Ravie LakshmananArtificial Intelligence / Vulnerability

[![](data:image/png;base64...)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgjVBqg5EYl4J3F4ssXr70jhFtH896HKzzDj9axgdrUBmssE6NJnt3QARKe1QzpkevArgkNQJO44LiXo1pysC_Op6REeYVOVkoKNkzANRS9cTHIVGVin7hyphenhyphenCiM23Bm0orCfoQUIhtMIxzYftSRoPh72n9tQFdf4boGkywU7f1nyO1UcHvibRLsCh_Mtuo6s/s790-rw-e365/echoleak.jpg)

A novel attack technique named EchoLeak has been characterized as a "zero-click" artificial intelligence (AI) vulnerability that allows bad actors to exfiltrate sensitive data from Microsoft 365 (M365) Copilot's context sans any user interaction.

The critical-rated vulnerability has been assigned the CVE identifier CVE-2025-32711 (CVSS score: 9.3). It requires no customer action and has been already addressed by Microsoft. There is no evidence that the shortcoming was exploited maliciously in the wild.

"AI command injection in M365 Copilot allows an unauthorized attacker to disclose information over a network," the company [said](https://msrc.microsoft.com/update-guide/en-US/vulnerability/CVE-2025-32711) in an advisory released Wednesday. It has since been added to [Microsoft's Patch Tuesday list](https://thehackernews.com/2025/06/microsoft-patches-67-vulnerabilities.html) for June 2025, taking the total number of fixed flaws to 68.

Aim Security, which discovered and reported the issue, [said](https://www.aim.security/lp/aim-labs-echoleak-m365) it's an instance of a large language model (LLM) Scope Violation that paves the way for [indirect prompt injection](https://thehackernews.com/2025/05/gitlab-duo-vulnerability-enabled.html), leading to unintended behavior.

[![DFIR Retainer Services](data:image/png;base64...)](https://thehackernews.uk/cloud-insight-d)

LLM Scope Violation occurs when an attacker's instructions embedded in untrusted content, e.g., an email sent from outside an organization, successfully tricks the AI system into accessing and processing privileged internal data without explicit user intent or interaction.

"The chains allow attackers to automatically exfiltrate sensitive and proprietary information from M365 Copilot context, without the user's awareness, or relying on any specific victim behavior," the Israeli cybersecurity company said. "The result is achieved despite M365 Copilot's interface being open only to organization employees."

In EchoLeak's case, the attacker embeds a malicious prompt payload inside markdown-formatted content, like an email, which is then parsed by the AI system's retrieval-augmented generation (RAG) engine. The payload silently triggers the LLM to extract and return private information from the user's current context.

[![](data:image/png;base64...)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhz2F-z0II8BxWXj_n-Ku6h4521g3FR4C6AUFBaCLk22VLnHGmromPzjN9BeIxlwKZBxUvyKHsrQkbSP3EcWSgUSEW82-JBxYXFpmLNSumnXbHz7ljg1APPFA1Dq1EzfR0IdDzmaffovzOG3oP5KWvwMKDr8GHOrH3Q_DO8ydjA3YFsZtuXQgtxQrdpIi5E/s2600/attacl.gif)

The attack sequence unfolds as follows -

* **Injection**: Attacker sends an innocuous-looking email to an employee's Outlook inbox, which includes the LLM scope violation exploit
* **User asks** Microsoft 365 Copilot a business-related question (e.g., summarize and analyze their earnings report)
* **Scope Violation:** Copilot mixes untrusted attacked input with sensitive data to LLM context by the Retrieval-Augmented Generation ([RAG](https://en.wikipedia.org/wiki/Retrieval-augmented_generation)) engine
* **Retrieval:** Copilot leaks the sensitive data to the attacker via Microsoft Teams and SharePoint URLs

Importantly, no user clicks are required to trigger EchoLeak. The attacker relies on Copilot's default behavior to combine and process content from Outlook and SharePoint without isolating trust boundaries – turning helpful automation into a silent leak vector.

"As a zero-click AI vulnerability, EchoLeak opens up extensive opportunities for data exfiltration and extortion attacks for motivated threat actors," Aim Security said. "In an ever-evolving agentic world, it showcases the potential risks that are inherent in the design of agents and chatbots."

[![](data:image/png;base64...)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjsXfi8dszy9aw4xN3a6hqiRFXXz8CzERQvMWs7rK6smQQBbEKz8Xqrbpu6NMvAe4FV9N5kyht3xW70vSVS6pwr_W1gTwS32BUOXoZ-BaPuz5D7i2X7KpmHOD_qm6X4TT-mYwOTySMhQzHNe-g4z-kBYoSePUkiBxeR0ILXIqhJ0CnU6AiYuC7VurS0dzgU/s790-rw-e365/ms.png)

"The attack results in allowing the attacker to exfiltrate the most sensitive data from the current LLM context - and the LLM is being used against itself in making sure that the MOST sensitive data from the LLM context is being leaked, does not rely on specific user behavior, and can be executed both in single-turn conversations and multi-turn conversations."

EchoLeak is especially dangerous because it exploits how Copilot retrieves and ranks data – using internal document access privileges – which attackers can influence indirectly via payload prompts embedded in seemingly benign sources like meeting notes or email chains.

### MCP and Advanced Tool Poisoning

The disclosure comes as CyberArk disclosed a tool poisoning attack ([TPA](https://thehackernews.com/2025/04/experts-uncover-critical-mcp-and-a2a.html)) that affects the Model Context Protocol ([MCP](https://www.anthropic.com/news/model-context-protocol)) standard and goes beyond the tool description to extend it across the entire tool schema. The attack technique has been codenamed Full-Schema Poisoning (FSP).

"While most of the attention around tool poisoning attacks has focused on the description field, this vastly underestimates the other potential attack surface," security researcher Simcha Kosman [said](https://www.cyberark.com/resources/threat-research-blog/poison-everywhere-no-output-from-your-...