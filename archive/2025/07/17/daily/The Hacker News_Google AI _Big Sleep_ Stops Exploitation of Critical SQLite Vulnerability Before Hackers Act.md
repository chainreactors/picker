---
title: Google AI "Big Sleep" Stops Exploitation of Critical SQLite Vulnerability Before Hackers Act
url: https://thehackernews.com/2025/07/google-ai-big-sleep-stops-exploitation.html
source: The Hacker News
date: 2025-07-17
fetch_date: 2025-10-06T23:55:47.111338
---

# Google AI "Big Sleep" Stops Exploitation of Critical SQLite Vulnerability Before Hackers Act

#1 Trusted Cybersecurity News Platform

Followed by 5.20+ million[**](https://twitter.com/thehackersnews)
[**](https://www.linkedin.com/company/thehackernews/)
[**](https://www.facebook.com/thehackernews)

[![The Hacker News Logo](data:image/png;base64...)](/)

**

**

[** Subscribe – Get Latest News](#email-outer)

* [** Home](/)
* [** Newsletter](#email-outer)
* [** Webinars](/p/upcoming-hacker-news-webinars.html)

* [Home](/)
* [Data Breaches](/search/label/data%20breach)
* [Cyber Attacks](/search/label/Cyber%20Attack)
* [Vulnerabilities](/search/label/Vulnerability)
* [Webinars](/p/upcoming-hacker-news-webinars.html)
* [Expert Insights](https://thehackernews.com/expert-insights/)
* [Contact](/p/submit-news.html)

**

**

**

Resources

* [Webinars](/p/upcoming-hacker-news-webinars.html)
* [Free eBooks](https://thehackernews.tradepub.com)

About Site

* [About THN](/p/about-us.html)
* [Jobs](/p/careers-technical-writer-designer-and.html)
* [Advertise with us](/p/advertising-with-hacker-news.html)

Contact/Tip Us

[**

Reach out to get featured—contact us to send your exclusive story idea, research, hacks, or ask us a question or leave a comment/feedback!](/p/submit-news.html)

Follow Us On Social Media

[**](https://www.facebook.com/thehackernews)
[**](https://twitter.com/thehackersnews)
[**](https://www.linkedin.com/company/thehackernews/)
[**](https://www.youtube.com/c/thehackernews?sub_confirmation=1)
[**](https://www.instagram.com/thehackernews/)

[** RSS Feeds](https://feeds.feedburner.com/TheHackersNews)
[** Email Alerts](#email-outer)

[![Salesforce Security Handbook](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjWa8tsMNqlevi1HGF1ALQRGIq7hROPFAbHd3R1RTEOe73T8_Q2xW_-91t2jSGjU5peiPb8QYblGp4igNW-u2Qmlxbp2BKzTVMSvyXDZJmC-BYpiiJHrcnG5drmSP97iZ9PVIf1DeEr7U-7vWpe4HXwfMjt8FGNgq5mOycOJluYr9wF7YOKrQY9MfArwgjt/s728-e100/ai-agent-security-d.png)](https://thehackernews.uk/ai-agent-security-d)

# [Google AI "Big Sleep" Stops Exploitation of Critical SQLite Vulnerability Before Hackers Act](https://thehackernews.com/2025/07/google-ai-big-sleep-stops-exploitation.html)

**Jul 16, 2025**Ravie LakshmananAI Security / Vulnerability

[![](data:image/png;base64...)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhu3qcCS8NCIS2fm-S1Je0jaz0BCgrKlh_OvSaUHpPI-G7GE7jHZART5Y8Pq769YvLxqCsCxCgFjkCRgRvr_1jitFtiesIihgeP5q9Edz8_-rR37oVD-_44CpHdjqlACb_jw8Dd32s6shr3kEW7X8MopqY5MRcSBnVm60YN_mHV4L4NKbEg5GmqUDJcEOXS/s790-rw-e365/sqlite-injection.jpg)

Google on Tuesday revealed that its large language model (LLM)-assisted vulnerability discovery framework identified a security flaw in the SQLite open-source database engine before it could have been exploited in the wild.

The vulnerability, tracked as **[CVE-2025-6965](https://nvd.nist.gov/vuln/detail/CVE-2025-6965)** (CVSS score: 7.2), is a memory corruption flaw affecting all versions prior to 3.50.2. It was discovered by [Big Sleep](https://thehackernews.com/2024/11/googles-ai-tool-big-sleep-finds-zero.html), an artificial intelligence (AI) agent that was launched by Google last year as part of a collaboration between DeepMind and Google Project Zero.

"An attacker who can inject arbitrary SQL statements into an application might be able to cause an integer overflow resulting in read off the end of an array," SQLite project maintainers [said](https://www.sqlite.org/cves.html) in an advisory.

[![DFIR Retainer Services](data:image/png;base64...)](https://thehackernews.uk/cloud-insight-d)

The tech giant described CVE-2025-6965 as a critical security issue that was "known only to threat actors and was at risk of being exploited." Google did not reveal who the threat actors were.

"Through the combination of threat intelligence and Big Sleep, Google was able to actually predict that a vulnerability was imminently going to be used and we were able to cut it off beforehand," Kent Walker, President of Global Affairs at Google and Alphabet, [said](https://blog.google/technology/safety-security/cybersecurity-updates-summer-2025/).

"We believe this is the first time an AI agent has been used to directly foil efforts to exploit a vulnerability in the wild."

"GTIG was able to identify artifacts indicating the threat actors were staging a zero day but could not immediately identify the vulnerability," Google told The Hacker News. "The limited indicators were passed along to other Google team members at the zero day initiative who leveraged Big Sleep to isolate the vulnerability the adversary was preparing to exploit in their operations."

In October 2024, Big Sleep was [behind](https://thehackernews.com/2024/11/googles-ai-tool-big-sleep-finds-zero.html) the discovery of another flaw in SQLite, a stack buffer underflow vulnerability that could have been exploited to result in a crash or arbitrary code execution.

[![](data:image/png;base64...)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhqGoplOQ0z6dzsKSElZ4mH4pvDZqlb47auxjAMDJAUY9823NTjpsyilVvzPeaGy4qGWYCDn9BrCoCz9jgX0B6wivcSo5u1w8slDYjMkAwvCRXzbxRtSbbTyuCtqv__jPP-VIUJat7N-ieHl1MAAR_uDBZc1wFUQcPMXllWGh5QiW98Ph6niWr9RmosfXgq/s790-rw-e365/ao-google-.jpg)

Coinciding with the development, Google has also published a white paper to build secure AI agents such that they have well-defined human controllers, their capabilities are carefully limited to avoid potential rogue actions and sensitive data disclosure, and their actions are observable and transparent.

"Traditional systems security approaches (such as restrictions on agent actions implemented through classical software) lack the contextual awareness needed for versatile agents and can overly restrict utility," Google's Santiago (Sal) Díaz, Christoph Kern, and Kara Olive [said](https://research.google/pubs/an-introduction-to-googles-approach-for-secure-ai-agents/).

"Conversely, purely reasoning-based security (relying solely on the AI model's judgment) is insufficient because current LLMs remain susceptible to manipulations like prompt injection and cannot yet offer sufficiently robust guarantees."

To mitigate the key risks associated with agent security, the company said it has adopted a hybrid defense-in-depth approach that combines the strengths of both traditional, deterministic controls and dynamic, reasoning-based defenses.

[![CIS Build Kits](data:image/png;base64...)](https://thehackernews.uk/platform-shield-d)

The idea is to create robust boundaries around the agent's operational environment so that the risk of harmful outcomes is significantly mitigated, specifically malicious actions carried out as a result of prompt injection.

"This defense-in-depth approach relies on enforced boundaries around the AI agent's operational environment to prevent potential worst-case scenarios, acting as guardrails even if the agent's internal reasoning process becomes compromised or misaligned by sophisticated attacks or unexpected inputs," Google said.

"This multi-layered approach recognizes that neither purely rule-based systems nor purely AI-based judgment are sufficient on their own."

Found this article interesting? Follow us on [Google News](https://news.google.com/publications/CAAqLQgKIidDQklTRndnTWFoTUtFWFJvWldoaFkydGxjbTVsZDNNdVkyOXRLQUFQAQ), [Twitter](https://twitter.com/thehackersnews) and [LinkedIn](https://www.linkedin.com/company/thehackernews/) to read more exclusive content we post.

SHARE
[**](#link_share)
[**](#link_share)
[**](#link_share)
**

[**Tweet](#link_share)

[**Share](#link_share)

[**Share](#link_share)

**Share

**
[**Share on Facebook](#link_share)
[**Share on Twitter](#link_share)
[**Share on Linkedin](#link_share)
[**Share on Reddit](#link_share)
[**Share on Hacker News](#link_share)
[**Share on Email](#link_share)
[**Share on WhatsApp](#link_share)
[![Facebook Messenger](data:image/png;base64...)Share on Facebook Messenger](#link_share)
[**Share on Telegram](#link_share)

SHARE **

[AI Agent](https://thehackernews.com/se...