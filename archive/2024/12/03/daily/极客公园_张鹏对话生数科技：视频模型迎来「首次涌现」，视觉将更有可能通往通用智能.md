---
title: 张鹏对话生数科技：视频模型迎来「首次涌现」，视觉将更有可能通往通用智能
url: https://mp.weixin.qq.com/s?__biz=MTMwNDMwODQ0MQ==&mid=2653066772&idx=1&sn=7927452db5fc955c9e8a07a72c32b22f&chksm=7e57eba2492062b42183395fce06ec8b06fa794509f5420e3b968c628ee1cefb72d161c4ac57&scene=58&subscene=0#rd
source: 极客公园
date: 2024-12-03
fetch_date: 2025-10-06T19:40:19.291364
---

# 张鹏对话生数科技：视频模型迎来「首次涌现」，视觉将更有可能通往通用智能

![cover_image](https://mmbiz.qpic.cn/mmbiz_jpg/8cu01Kavc5bBVuwlVvp9Rz0tT8Db1aQBUsYcl6N1yU6yDCoVicoicg011aZgG8J3hBH9BpUL5fZ1H4RwZwibef2uA/0?wx_fmt=jpeg)

# 张鹏对话生数科技：视频模型迎来「首次涌现」，视觉将更有可能通往通用智能

原创

张鹏

极客公园

![](https://mmbiz.qpic.cn/mmbiz_png/8cu01Kavc5abwyEr8w6ibliaw5C5oagUDBa9LbvEbZIm5P66DTLibicWR3Q5qbOzMpgHvuWZTg0P3udCCwv9Jvddcg/640?wx_fmt=png)

![](https://mmbiz.qpic.cn/mmbiz_png/8cu01Kavc5bBVuwlVvp9Rz0tT8Db1aQBiblHnwWzF3K7g1GZAzMzawLN0SicseWfPreicuJeJ2EoRUzrKW1Ex6dicQ/640?wx_fmt=png&from=appmsg)

创业公司最重要的是目标的创新与坚持。

**对话｜张鹏**

**编辑｜Nico**

2024 年接近尾声，这一年多模态领域最大的进展，是从年初就开始的视频生成技术的突破。

Sora 基于 DiT（Diffusion Transformer）架构，把长视频生成的效果提高到了前所未有的水平，也掀起了全球范围内的视频生成热潮。

追随者众多，全球第一个交出成果的是国内大模型团队生数科技的 Vidu。随后数月，生数不断在一致性等模型性能上取得突破，近期发布的 Vidu 1.5 在全球率先突破了视频模型的多主体一致性难题，证实视频模型也有 context window，泛化能力得到验证。它通向「通用」。

事实上，Vidu 背后的团队，比 OpenAI 更早实践了 Diffusion Transformer 架构。2022 年 9 月，还在清华大学朱军教授实验室的鲍凡发表了 U-ViT 架构论文，12 月伯克利团队发布了路线同源的 DiT 架构，这一年的 CVPR，大会接收了清华大学的 U-ViT，反而拒收了 伯克利 的 DiT。

后来团队创业，成立生数。在一个个技术热点的拍打下，生数被市场认知为一家视频生成领域的优秀公司，但不止如此。从创业之初，生数团队就笃定原生的多模态模型能够像语言模型一样通向智能，甚至，多模态比语言模型拥有更高的智能上限。

在不断的实践和尝试后，生数确定，视频是实现通用多模态模型最重要的模态能力。视频可以成为多模态的统一表示，意味着所有模态都可以用视频的形式来呈现，在模型黑盒中同时作为输入与输出——就像 LLM 把语言文字作为统一输入与输出。

这就像是，在发现了大模型的「左脑」语言后，我们又确认了视觉模型作为「右脑」的通向智能的合理性。

我们找到生数科技的 CTO 鲍凡，也是 U-ViT 论文的一作，聊了聊 Vidu 最新版本取得的成果，以及作为全球范围内最早实践 Diffusion Transformer 的专家，他对于视频生成领域的观察和理解。

以下是极客公园创始人张鹏与生数科技联创、CTO 鲍凡的对话，经编辑整理。

![](https://mmbiz.qpic.cn/mmbiz_png/8cu01Kavc5bBVuwlVvp9Rz0tT8Db1aQBXnjViccSOAYFcxF5mZCL9WwjkbTFe9utoVVqstD1UiaXtWianJIicGc3Cw/640?wx_fmt=png&from=appmsg)

***01***

**Vidu 1.5，视频模型的上下文突破**

**张鹏：欢迎鲍凡，在进入具体话题之前，先给我们介绍一下你的经历，你是怎么投身这条大模型路线的？**

**鲍凡：**我是本科时期，很早加入了朱军老师的实验室，一直到博士。一开始在做理论性的工作，博一的时候，还花了一年时间学纯数学的东西。比较巧，最早做了能量模型，可以说是扩散模型的前身，一路下来，算是比较自然的选择。

2020 年开始，我们观察到扩散模型在图像生成质量上的突破，立刻决定 all in，一直从事相关工作，包括加速、可扩展性以及通用性等等，做了几个比较有影响力的工作，Analytic-DPM、UniDiffuser 和 U-ViT 等。然后生数创业，相当于是研究工作到工业界的延续。我在生数负责整体技术，以及围绕技术的组织架构、流程建设等等。

**张鹏：最近 Vidu 1.5 版本发布了，取得了一些令人振奋的进展。先介绍一下这个版本中有哪些突破？**

**鲍凡：**如果用一个词来概括这次的突破，那就是「**上下文能力**」的出现。

具体来说，模型能够灵活理解多张图片作为输入，可以**将多个主体、多个特征之间的关系作为上下文进行记忆和关联**。基于这些输入前提，模型能够个性化调整自己的表现，从而产生相应的视频生成能力。这是非常重要的一个突破点。

**张鹏：体现到视频模型里就是我们说的「一致性」？**

**鲍凡**：没错，一致性是上下文能力的一个重要体现。

**张鹏：就是一个人物形象在整个生成过程中保持连贯，不会出现脸部变形之类的问题？**

**鲍凡：**这其实只是最基础的能力。最初是实现**单个角色的一致性**，但我们逐步扩展了这个概念。现在，我们可以同时处理**多个主体**，让模型理解并维持多个角色之间的交互关系。更进一步，我们实现了**场景的一致性**，可以预先设定场景，让模型在特定场景下生成视频。

随着上下文能力的增强，我们甚至可以支持**音频模态**，不仅能记录人物的外貌，还能保持声音特征的一致性，这些都可以自由指定。

**张鹏**：所以不只是视觉，声音等多个维度的一致性都可以保持下去。

**鲍凡**：是的，多主体一致性的范围包括了声音、场景等多个方面。

**张鹏：从最初维持单个人脸的一致性，到现在能够处理多主体，并在长时间内保持一致，这在技术上最大的挑战是什么？这种技术路线的变化背后有什么深层含义？**

**鲍凡**：技术范式有一个非常大的升级。

可以**类比语言模型里从 Bert 到 GPT 模式的演变**。之前做单个主体的一致性常用的方式是，先预训练一个文生视频模型，然后用 LoRA 的方式把它微调成关于某个（特定）人脸的模型。这非常类似之前 Bert 的范式，预训练，然后在特定问题上做微调。

但现在我们已经转变到一个更通用的模式，类似 GPT，核心是通过上下文的能力去维持多主体一致性。我们不再依赖预训练模型加微调的方式，而是将所有问题都转化为视觉输入、视觉输出的形式，用统一的模型处理。视觉输入作为上下文，可以接收各种内容，从而影响视频生成的行为。这是从特定任务微调转向基于上下文的通用学习方式的重要转变。

我们内部也把它叫做**多模态提示词**，从纯文本的提示词，变成文本、视觉、音频，这些模态都可以作为提示词。

**张鹏：画面的任何一个点都可以理解为一个主体，而任何一种它的组合都是成为了一种主体。理论上，如果多主体扩展到极致，是不是就能实现某种特定风格的持续生成？比如王家卫风格的视频？**

**鲍凡**：没错。

**张鹏：要实现这样的效果，你们具体做了哪些工作？这个结果是在你们预期之中的吗？**

**鲍凡：**其实这种泛化性的出现在我们的预料之中，但具体它会泛化出什么（任务）能力，我们一开始确实无法预测。所以最终看到这个结果时，还是比较惊喜的。

具体做了哪些事情，我认为这是一个技术认知上可以规划的过程。因为我们在语言模型上已经积累了一些经验，可以作为参考。

比如，在任务表示或数据表示方面，我们需要尽可能将各种不同的问题进行统一的表示。举个例子，对于多主体或者单主体的各种问题，都可以**通过一种视频输入、视频输出的形式来表示**。这就类似于语言模型会将各种问题统一表示为文本输入加文本输出的形式。

同时，在架构层面，也不能针对每个问题单独设计一个专门的架构，因为这样会与通用性背道而驰。我们试图**把基于单任务的 Diffusion Transformer 架构，发展为一个通用的架构。**

![](https://mmbiz.qpic.cn/mmbiz_png/8cu01Kavc5bBVuwlVvp9Rz0tT8Db1aQBIa6WYRnSia4yelTVGspVpLraib7JbxOs6MIyO3a0EcbZnAPGFb9zGUoA/640?wx_fmt=png&from=appmsg)

我们的思路是使用一个架构来处理所有的输入和输出。这样，架构本身便能够与具体问题解耦开。凡是可以表示为视频输入和视频输出的问题，都可以用这个架构来处理。

总之，我们在数据和架构两方面实现了统一，通过这两点，最终达成了模型的上下文能力，使其具备更强的通用性。

**张鹏：通过一套完整的架构和流程设置，来对齐到 context window 的目标。这并不是一个非常「直接」提升生成效果的方式，你们设计这套方法的思路是什么？**

**鲍凡：**这与我们一开始设定的目标有关。

我们的目标是打造一个通用的多模态模型。考虑了各种各样的设计。在视频模型的基础上处理一些问题时，常见的方法是采用插件式，在基模上加入一个新的插件，用于处理特定的输入。但这种方案很快就被我们否定了。因为它不够通用。

一个插件只能处理一种特定的输入，解决某一类特定的问题，跟通用性背道而驰。最终，我们还是设计出了一套自己的方案。因为当时发现市面上没有相关的工作可以参考。所以我们基于自身对技术的认知，设计了一套能够支持上下文能力的通用架构。

**张鹏：但这样复杂的 context，推理的性能怎么样？**

**鲍凡：**我们的推理速度并没有受到任何影响，效率仍然保持在全球领先。

这类上下文模型确实存在一个特点：随着上下文窗口长度增加，也就是模型输入内容越多，推理时间成本会相应提高。这类似于大语言模型，输入内容越多，生成每个 token 所需的时间也会相应增加。

但另一方面，我们在扩散模型理论加速方面有非常深厚的积累。虽然多了一些上下文窗口，但我们通过对扩散模型采样算法的理论优化和架构层面的进一步优化，可以实现数十倍的加速。

综合来看，由于上下文长度增加而导致的时间开销增长，没有超过我们在推理速度优化上的提升节奏。

**张鹏：优化已经实现了一个数量级的提升，还有很大空间。但综合来看，视频作为上下文的复杂度应该会超乎想象，接下来综合结果会有什么变化？**

**鲍凡：**如果单纯增加上下文长度，那么时间开销的增长和上下文长度可能是乘积关系，会比线性关系更高一些。

举个例子，当上下文长度从当前的多图扩展到未来的视频上下文，等模型需要理解更长的视频内容的时候，比如长达几分钟甚至十几分钟的带有故事情节的视频，**其推理时间的开销可能会提升一个甚至两个数量级。**

**张鹏：之前大家用****Midjourney****生图的时候，可以将图片作为提示词。这种方式下面，图片所包含的信息量显然比一句话要多得多。因此，要让这个系统能够沿着这个方向发展，一个必要条件就是必须优化系统的效率，否则听起来这种方案就难以实现了，对吧？**

**鲍凡：**对，虽然视频时长的增加可能会让推理时长提升两个数量级，但我们有推理优化技术，能够把推理效率提升几十倍。经过这些优化之后，最终的推理时间还是一个非常可接受的状态。

**张鹏：必须预先计算好需要多少优化空间，才能确保这条路线是可行的。**

**鲍凡：**我认为一切都需要做提前规划。包括我们预想未来某些场景所需要的上下文长度，这些上下文长度会直接影响到我们需要将推理优化到什么程度。所有这些因素都需要提前考量。

***02***

**视频模型的首次「智能涌现」**

**张鹏：文字作为提示词，大家通过****ChatGPT****已经很熟悉了。视觉作为提示词，我们也在一些图片和视频生成模型中见过。你们提到的多主体一致性能够稳定持续生成，这让人联想到 GPT 的特性，这也是一种涌现吗？也就是在达到某个参数规模后自然出现的泛化能力吗？**

**鲍凡：** 多主体一致性这个能力，其实是具有一定泛化性的。比如说，传统的多主体模型可能会考虑两个角色的互动，保持一致性。但我们这个多主体的一致性，它可以泛化到更多层面。比如，可能是抽象的拍摄手法。

在这种情况下，虽然几乎没有对应的训练数据，甚至几乎没有相关的样本，但它依然能在这些非常抽象的场景下表现得非常好。这种能力，**实际上就是涌现出来的能力，是我们在准备数据时没有预料到的**，或者超出了我们原本的预期范围。

**张鹏：「涌现」这个词大家讨论得很多，但可能一直没有一个特别精准的定义。你们怎么理解这个概念？**

**鲍凡：**涌现指的是，当你施加某些要素之后，模型会突然泛化出一些比较通用的能力。这个词最早其实是用在大语言模型的场景中，指的是随着模型的参数量不断增加，达到一定程度时，模型会突然具备一些原本做不到的能力。

在我们的视频模型场景下，像模型的参数量、架构设计和数据设计等，这些要素都会影响模型涌现出的一些能力。

**张鹏：在语言模型中，我们说参数量和涌现的能力是高度相关的，参数量较少时，模型可能就不会出现涌现。**

**那么，在视频模型中，是否也可以理解为，当参数量达到一定规模时，涌现的能力就会出现？还是说，涌现更多是与架构和设计上的创新相关？参数量的 scaling 是否仍然是一个重要因素？**

**鲍凡：**确实如此。我们不仅需要在 scale up 上努力，还需要在数据、模型架构和算法方面投入。这与大语言模型的发展路径不同。大语言模型的架构和数据处理方式已相对成熟，主要挑战是工程实现，而我们面临的挑战更多元。

比如，我们尝试过插件式架构，虽然也投入了大量参数，但模型只能处理已学习过的内容。当我们改用更统一的架构后，模型才展现出了超出训练范围的能力。这说明架构设计对于实现真正的泛化能力至关重要。

**张鹏：你刚才提到，训练数据之外的能力在测试中出现了，这让我挺好奇的。能谈谈具体是怎么理解这些「超越训练范围」的能力吗？**

**鲍凡：**我们的训练是逐步进行的，首先我们会选择比较有限的主体数量作为参考对象。最开始，我们确定的方向是人脸（一致性），然后是单主体，再到多主体，最后逐步引入一些更复杂的场景。所以，我们的计划是按照这个脉络一步步推进的。

但在过程中，我们发现当模型走到某个阶段时，很多原本计划中的步骤已经不再需要做了，许多设想中的能力已经自然涌现出来了，这让我们很惊讶。

**张鹏：你们看到的这个现象，里面有什么可以被总结出来的发现吗？**

**鲍凡：**我们确实有一些反思。一个很重要的点是，模型的设计尽可能简洁和统一。简洁的架构不仅有助于优化，还能更高效地进行知识压缩。更简洁的设计可以让模型在更低的成本下去做泛化，甚至在一些训练数据之外的场景下也能有很好的表现。所以，对于整个机器学习领域来说，我觉得**保持****（架构）****简洁并在此基础上处理更多问题，是第一性原理。**

**张鹏：刚才你说你们早期就在扩散模型这条路上探索，生数科技的成立，本身就是为了实现一个通用的视频多模态模型。**

**当时这个目标是怎么形成的？为什么你们会认为需要设计一套全新的架构？这个目标从设定到最终落实，过程中经历了哪些关键的创新？这个创新的核心是什么？**

**鲍凡：**对，其实这个目标在生数科技成立之前就已经有了。2021 年底，那会还是在实验室阶段，我们认为，在视觉领域，我们需要构建通用的模型，更进一步，我们希望在多模态领域也能够做出通用的模型。

为什么会有这个目标呢？当时虽然 ChatGPT 还未推出，但 OpenAI 的 GPT-3 已经在学术界造成很大影响，我们看到了语言模型中通用性的潜力。我们认为，真正的通用性一定是多模态的，因此我们要更彻底地实现这一点。今年的 Vidu1.5 版本、以及上下文能力，都是基于之前积累的技术和经验。

***03***

**图片、视频、声音、3D，多模态是一件事**

**张鹏：既然 1.5 已带来令人兴奋的变化，而且你们是按阶梯式发展，那估计之前没料到会有这一次的涌现型跳跃。这会不会让你们后续的模型发展计划有所调整？在 1.5 之后，你们主要打算做哪些工作？重点想突破什么、优化什么呢？**

**鲍凡：** 实际上，涌现这件事我们有预料到，但涌现出的具体能力一开始不太好预测。

我们后续要做的事其实和之前还是相对一致，下一步很直接的想法是用更抽象的概念来保持一致性。现在是以图片为参考保持一致，图片参考对象主要是某种主体，之后可参考更抽象的内容，比如著名导演的经典电影片段，像王家卫一些电影，就可能参考他的特定的风格，如抽帧感、运镜调度等，这些都能作为参考对象，也会学习特殊的运镜手法，这些都是后续的想法，也在之前的规划之中。

![](https://mmbiz.qpic.cn/mmbiz_png/8cu01Kavc5bBVuwlVvp9Rz0tT8Db1aQBUiamYVASImZflo9yiaVawn8lgjEbicJwZsHE31rDBWdbib3t5dyGXtYtnA/640?wx_fmt=png&from=appmsg)

**张鹏：即使模型没有见过某些场景，也能保持有效的一致性，这与传统的 Lora 插件模式很不同。那么未来，你们是只在这个机制上进行 Scale up，还是会在这个体系上构建新的东西？**

**鲍凡：**目前我们架构相对成熟，短期内会集中突破以下方面：

一方面，因为上下文长度会不断变长，在数据构建上，要让模型能理解更长的上下文，还要理解更多抽象概念，比如理解拍摄手法、动作等，这都需要构造更长上文窗口的数据。

另一方面，随着上文长度增加，在推理优化时不能让模型推理速度大幅降低，需要采取更深入、激进的策略。当然，scale up 工作也必不可少，这是提升模型能力的重要条件。

总体而言，一是针对上下文长度提升做数据相关工作，二是为保障用户体验做推理优化提高效率的工作，三是进行基本的 scale up 工作。

**张鹏：之前大语言模型面临互联网数据快被用尽的问题。但如果进入多模态领域则会很不同，还有大量数据未被有效利用，至少在 scale up 进程上，能看到有很多待拓展的内容。当然这其中挑战很大，因为它的上下文和信息量比原来大很多，对架构、效率、简洁性要求极高。**

**但就 scaling law 在这个维度来讲，感觉还是挺有希望、挺值得期待的，还有很大发展空间。我这样理解对吗？**

**鲍凡：**对，我觉得多模态数据获取难度比语言模型小很多。一方面模态更多，另一方面语言模型的数据很多源于人类思维形成文字，会比较耗精力，而像视频，随手一拍就有了可用数据，所以多模态尤其是视觉数据获取难度更低，在数据方面也就有更强的 scale up 空间。

**张鹏：我们讨论大语言模型的时候，就是看数据、算法、算力这个三个核心的要素。从现在这个架构的角度来看，你会如何排序这三个要素的重要性？...