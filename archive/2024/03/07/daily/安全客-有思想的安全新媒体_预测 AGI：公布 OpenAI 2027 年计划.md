---
title: 预测 AGI：公布 OpenAI 2027 年计划
url: https://www.anquanke.com/post/id/293655
source: 安全客-有思想的安全新媒体
date: 2024-03-07
fetch_date: 2025-10-06T17:08:32.758585
---

# 预测 AGI：公布 OpenAI 2027 年计划

首页

阅读

* [安全资讯](https://www.anquanke.com/news)
* [安全知识](https://www.anquanke.com/knowledge)
* [安全工具](https://www.anquanke.com/tool)

活动

社区

学院

安全导航

内容精选

* [专栏](/column/index.html)
* [精选专题](https://www.anquanke.com/subject-list)
* [安全KER季刊](https://www.anquanke.com/discovery)
* [360网络安全周报](https://www.anquanke.com/week-list)

# 预测 AGI：公布 OpenAI 2027 年计划

阅读量**106125**

发布时间 : 2024-03-06 11:55:58

**x**

##### 译文声明

本文是翻译文章

译文仅供参考，具体内容表达以及含义原文为准。

为了追求先进的人工智能，OpenAI 的目标是到 2027 年实现通用人工智能 (AGI)。这一雄心勃勃的目标引发了人工智能爱好者和研究人员的好奇和猜测。在最近的一份文件中，OpenAI 透露了他们实现 AGI 的计划的一些细节，并阐明了导致该目标的模型进展。

**文件概要：**

00:00

📄 举报文件一开始就强调猜测，同时透露了 OpenAI 所谓的到 2027 年创建 AGI 的计划。它讨论了一个名为“Q\*”或“QSTAR”的具有 125 万亿个参数的多模态模型，据称该模型已完成训练，但由于未能启动到成本。

05:00

🔍 深入了解该文档，它引用了 GPT-3 和 GPT-4.5 等之前的模型，揭示了内部命名法的变化和某些开发的取消，暗示了 OpenAI 内部复杂且流畅的路线图。

10:00

🤔 然后，该文件谈到了 AGI 的概念，将其定义为能够执行人类可以执行的任何智力任务的智能。它还检查神经元网络之间的关系（通过参数数量来衡量）及其任务表现。

15:00

💡对该文档的进一步探索揭示了人工智能中的缩放定律的参考，特别是 Deep Mind 的龙猫研究论文，该论文表明，即使参数较少，性能也可以随着数据的增加而飙升。

20:00

🚀 叙述转向讨论人工智能进步的影响，杰米斯·哈萨比斯和埃隆·马斯克等行业领袖敦促谨慎行事。它还指出了 OpenAI 的大量资金以及计算最优的 100 万亿参数模型的潜力。

25:00

🌐 该文件深入探讨了人工智能快速发展的更广泛的社会和伦理考虑，质疑 OpenAI 的进步对就业市场、公众意识的影响，以及超级智能“唤醒龙”的潜在风险。

30:00

⏳ 结论性思考 OpenAI 的长期愿景及其到 2027 年解决超级对齐的承诺，旨在将 AGI 安全地引入世界。它表明，只要满足道德考虑，OpenAI 就可以引领超级智能的未来。

**揭示 OpenAI 的计划**
OpenAI 实现 AGI 的计划涉及多个开发阶段和模型进展。根据该文件，OpenAI 的目标是在未来几年训练一个 125 万亿参数的多模态模型，称为 GPT-7。该模型预计将成为人工智能技术及其功能的重大进步。

随着 GPT-5 的发布，OpenAI 已经在这个方向上取得了进展。该文件提到，GPT-5于2023年12月推出，标志着OpenAI模型进展的一个重要里程碑。但需要注意的是，该文档并未提供有关 GPT-5 特性和功能的具体细节。

虽然文件没有提及 GPT-6 发布的具体时间表，但推测将于 2025 年推出。GPT-6 有望进一步增强 AI 模型的能力，为更多人工智能模型的开发铺平道路。先进的系统。

OpenAI的最终目标是达到AGI，即拥有与人类智能相当的通用智能的人工智能系统。虽然该文件没有提供实现 AGI 的详细路线图，但它暗示 GPT-7 可能是朝这个方向迈出的关键一步。

**模型进展：从 GPT 5 到 AGI**
从 GPT-5 到 AGI 的进展涉及扩大 AI 模型的参数和功能。该文件强调了扩展的重要性，像 GPT-7 这样的更大的模型能够实现更好的性能和对复杂任务的理解。

OpenAI 的模型进展基于缩放定律的概念，该定律表明随着模型中参数数量的增加，其性能会提高。凭借 GPT-7 125 万亿个参数的惊人规模，它有望突破人工智能能力的界限，并有可能在某些任务中超越人类水平的表现。

该文件强调了数据在模型开发中的重要性。OpenAI 认为，获取大量高质量数据对于有效训练 AI 模型至关重要。他们将模型中的参数数量与人脑中的突触数量进行比较，强调了对大量数据和计算能力的需求。

虽然该文件没有提供有关 GPT-5 或 GPT-7 训练过程的具体细节，但它暗示了训练这些模型的挑战以及通过迭代开发优化其性能的重要性。

值得注意的是，该文件并未确认 GPT-5 和 GPT-7 的确切功能，因为它是基于泄露的信息和猜测。然而，它提供了一个有趣的视角，让我们了解 OpenAI 的模型进展以及他们在 2027 年实现 AGI 的目标。

**埃隆·马斯克诉讼的影响**
埃隆·马斯克最近针对 OpenAI 的诉讼对该公司及其实现 AGI 的计划产生了重大影响。该诉讼由马斯克的航空航天公司 SpaceX 提起，指控 OpenAI 偏离了为人类造福创造先进人工智能技术的最初目标，而是专注于建立竞争优势。马斯克认为，OpenAI 将人工智能技术开源的决定违背了公司的使命，并可能导致危险人工智能系统的开发。

这起诉讼在人工智能界引起了争议和猜测。一些专家认为，马斯克的担忧是有道理的，OpenAI 在追求 AGI 的过程中应该优先考虑安全和道德因素。其他人则认为，将人工智能技术开源可以促进协作，并可能导致该领域更快的进步。该诉讼的结果仍不确定，但它对 AGI 发展的未来提出了重要问题。

如果马斯克的诉讼成功，可能会对 OpenAI 到 2027 年实现 AGI 的计划产生重大影响。该公司可能需要改变其方法并优先考虑安全措施，这可能会推迟他们开发 AGI 的时间表。此外，该诉讼引起了人们对通用人工智能开发的道德影响的关注，并可能导致该领域的监管和监督加强。

总体而言，埃隆·马斯克对 OpenAI 的诉讼引发了关于 AGI 负责任开发的争论。这场法律战将如何展开以及它将对人工智能技术的未来产生什么影响，还有待观察。

**了解 AGI 级别**
在讨论 AGI 时，了解不同级别的人工智能非常重要。AGI是指具有与人类智能相当的通用智能的系统。然而，AGI 并不是单一的、固定的智能水平。相反，它可以被视为具有不同功能级别的频谱。

1 级：不熟练的 AGI
AGI 谱系的低端是非熟练 AGI。这种智力水平与幼儿或动物的认知能力相当。不熟练的 AGI 可以执行基本任务并遵循简单的指令，但缺乏理解复杂概念或进行抽象思维的能力。

2级：熟练的AGI
熟练的 AGI 代表了更高水平的智能，可与特定领域熟练的人类专业人员相媲美。熟练的 AGI 可以执行复杂的任务并解决其专业领域内的问题。然而，它仍然缺乏概括知识或将技能转移到新领域的能力。

3级：有能力的AGI
有能力的 AGI 的特点是高水平的智力和解决问题的能力。它可以处理广泛的任务并以最少的指导适应新情况。有能力的 AGI 拥有深厚的知识和专业知识，使其在多个领域的表现水平可与高技能的人类专业人员相媲美。

4级：超级智能AGI
超级智能AGI代表了人工智能的最高水平。它在所有领域都超越了人类水平的智力，并且具有在几乎任何智力任务中超越人类的能力。超级智能AGI能够自主学习、自我完善和创造性地解决问题。

值得注意的是，AGI 目前并不存在，并且上述水平是假设的。尽管人工智能系统近年来取得了显着进步，但尚未达到通用人工智能的水平。OpenAI 到 2027 年实现 AGI 的目标是一项重大挑战，需要人工智能技术的进一步进步。

**与人脑参数比较**
了解 OpenAI 的 GPT-7 等人工智能模型规模的一种方法是将它们与人脑进行比较。据估计，人类大脑包含约 1000 亿个神经元，每个神经元通过突触与数千个其他神经元相连。这种复杂的连接网络使大脑能够处理信息并执行复杂的认知任务。

相比之下，OpenAI 的 GPT-7 预计拥有 125 万亿个参数。人工智能模型中的参数可以被认为是人工神经元之间的连接，类似于人脑中的突触。拥有 125 万亿个参数，GPT-7 将具有更大的处理信息和执行复杂任务的能力。

虽然 GPT-7 中的参数数量远高于人脑突触的估计数量，但值得注意的是，这种比较并不是一对一的。人脑是一个高度复杂的器官，其智力不能仅仅通过突触的数量或参数来衡量。

此外，人工智能模型的性能不仅仅取决于参数的数量。其他因素，例如训练数据的质量和模型的架构，也发挥着至关重要的作用。OpenAI 对缩放参数的关注基于缩放定律的概念，这表明具有更多参数的较大模型往往在复杂任务上表现更好。

虽然 GPT-7 等 OpenAI 模型的参数数量可能比人脑更多，但谨慎进行这种比较很重要。人脑是一个具有独特功能的非凡器官，AGI 的目标是复制其一般智能，而不仅仅是其参数计数。这种比较可以作为了解人工智能模型的规模和潜力的一种方式，但不应将其视为智力的直接衡量标准。

**龙猫缩放法则和未来发展**
为了实现通用人工智能 (AGI)，OpenAI 一直专注于扩展其人工智能模型。缩放定律的概念在其模型进展和未来发展中起着至关重要的作用。OpenAI 认为，随着模型中参数数量的增加，其性能和对复杂任务的理解会提高。

OpenAI 计划训练一个 125 万亿参数的多模态模型 GPT-7，他们预计这将是人工智能技术的重大进步。该模型预计将突破人工智能能力的界限，并有可能在某些任务中超越人类的表现。但需要注意的是，该文件并未提供有关 GPT-5 或 GPT-7 训练过程的具体细节。

通过扩大人工智能模型的参数和能力，OpenAI 的目标是在 2027 年实现 AGI。他们认为，获取大量高质量数据对于有效训练人工智能模型至关重要。OpenAI 将模型中的参数数量与人脑中的突触数量进行比较，强调了对大量数据和计算能力的需求。

虽然 GPT-7 等 OpenAI 模型的参数数量可能比人脑更多，但谨慎进行这种比较很重要。人脑是一个具有独特功能的非凡器官，AGI 的目标是复制其一般智能，而不仅仅是其参数计数。这种比较可以作为了解人工智能模型的规模和潜力的一种方式，但不应将其视为智力的直接衡量标准。

人工智能的未来发展可能会涉及尺度法则、数据收集和计算能力的进一步进步。OpenAI 到 2027 年实现 AGI 的雄心勃勃的计划将成为这些发展背后的驱动力。随着人工智能的不断发展，缩放定律和其他进步如何促进通用人工智能的实现将是一件令人着迷的事情。

**伦理问题和行业反应**
埃隆·马斯克 (Elon Musk) 最近针对 OpenAI 的诉讼引发了人工智能行业的重要道德担忧。马斯克认为，OpenAI 已经偏离了创造先进人工智能技术造福人类的初衷。他担心人工智能技术开源可能会导致危险的人工智能系统的发展。

这起诉讼引发了人工智能界的争论。一些专家认为，马斯克的担忧是有道理的，在AGI开发中应优先考虑安全和道德考虑。其他人则认为，开源人工智能技术可以促进协作，并可能导致该领域更快的进步。

OpenAI 尚未公开回应马斯克的诉讼。然而，这起诉讼可能会对 OpenAI 到 2027 年实现 AGI 的计划产生影响。他们可能需要调整方法并优先考虑安全措施，这可能会推迟 AGI 开发的时间表。

AGI 开发的伦理影响超出了马斯克的诉讼范围。随着人工智能技术的不断进步，需要加强监管和监督，以确保负责任地开发和部署通用人工智能系统。

整个人工智能行业都意识到了这些道德问题，并正在积极努力解决这些问题。OpenAI 等组织致力于以安全、透明且符合人类价值观的方式进行研究。他们了解 AGI 开发中道德考虑的重要性，并正在采取措施减轻潜在风险。

随着 AGI 开发的进展，行业合作并建立伦理准则和法规至关重要。这将有助于确保通用人工智能的开发方式有益于社会并最大限度地减少潜在危害。

本文翻译自 原文链接。如若转载请注明出处。

商务合作，文章发布请联系 anquanke@360.cn

本文由**安全客**原创发布

转载，请参考[转载声明](https://www.anquanke.com/note/repost)，注明出处： [https://www.anquanke.com/post/id/293655](/post/id/293655)

安全KER - 有思想的安全新媒体

本文转载自:

如若转载,请注明出处：

安全KER - 有思想的安全新媒体

分享到：![微信](https://p0.ssl.qhimg.com/sdm/28_28_100/t01e29062a5dcd13c10.png)

* [人工智能](/tag/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD)

**+1**7赞

收藏

![](https://p5.ssl.qhimg.com/t010857340ce46bb672.jpg)安全客

分享到：![微信](https://p0.ssl.qhimg.com/sdm/28_28_100/t01e29062a5dcd13c10.png)

## 发表评论

您还未登录，请先登录。

[登录](/login/index.html)

![](https://p0.ssl.qhimg.com/t014757b72460d855bf.png)

[![](https://p5.ssl.qhimg.com/t010857340ce46bb672.jpg)](/member.html?memberId=170061)

[安全客](/member.html?memberId=170061)

这个人太懒了，签名都懒得写一个

* 文章
* **2096**

* 粉丝
* **6**

### TA的文章

* ##### [英国通过数据访问和使用监管法案](/post/id/308719)

  2025-06-20 17:11:10
* ##### [CISA警告：严重缺陷（CVE-2025-5310）暴露加油站设备](/post/id/308715)

  2025-06-20 17:09:03
* ##### [大多数公司高估了AI治理，因为隐私风险激增](/post/id/308708)

  2025-06-20 17:05:02
* ##### [研究人员发现了有史以来最大的数据泄露事件，暴露了160亿个登录凭证](/post/id/308704)

  2025-06-20 17:02:15
* ##### [CVE-2025-6018和CVE-2025-6019漏洞利用：链接本地特权升级缺陷让攻击者获得大多数Linux发行版的根访问权限](/post/id/308701)

  2025-06-20 16:59:36

### 相关文章

* ##### [人工智能可能修复帮助传播了 15 年的漏洞](/post/id/308401)

  2025-06-12 15:19:33
* ##### [浅析新型网络犯罪DeepSeek AI实战应用](/post/id/305102)

  2025-03-18 10:38:20
* ##### [360SRC x Hacking Group丨「奇御」AI安全技术沙龙议题征集！](/post/id/302279)

  2024-11-28 17:43:31
* ##### [从误用到滥用： 人工智能风险与攻击](/post/id/300992)

  2024-10-17 11:00:07
* ##### [一种用于网络钓鱼攻击的生成式人工智能恶意软件](/post/id/300410)

  2024-09-25 14:16:34
* ##### [苹果加入美国政府对人工智能安全的自愿承诺](/post/id/298565)

  2024-07-31 11:23:56
* ##### [Vanta筹集1.5亿美元，加速其AI产品创新](/post/id/298358)

  2024-07-25 15:02:41

### 热门推荐

文章目录

![](https://p0.qhimg.com/t11098f6bcd5614af4bf21ef9b5.png)

安全KER

* [关于我们](/about)
* [联系我们](/note/contact)
* [用户协议](/note/protocol)
* [隐私协议](/note/privacy)

商务合作

* [合作内容](/note/business)
* [联系方式](/note/contact)
* [友情链接](/link)

内容需知

* [投稿须知](https://www.anquanke.com/contribute/tips)
* [转载须知](/note/repost)
* 官网QQ群：568681302

合作单位

* [![安全KER](https://p0.ssl.qhimg.com/t01592a959354157bc0.png)](http://www.cert.org.cn/)
* [![安全KER](https://p0.ssl.qhimg.com/t014f76fcea94035e47.png)](http://www.cnnvd.org.cn/)

Copyright © 北京奇虎科技有限公司 三六零数字安全科技集团有限公司 安全KER All Rights Reserved [京ICP备08010314号-66](https://beian.miit.gov.cn/)[![](https://icon.cnzz.com/img/pic.gif)](https://www.cnzz.com/stat/website.php?web_id=1271278035 "站长统计")

微信二维码

**X**![安全KER](https://p0.ssl.qhimg.com/t0151209205b47f2270.jpg)