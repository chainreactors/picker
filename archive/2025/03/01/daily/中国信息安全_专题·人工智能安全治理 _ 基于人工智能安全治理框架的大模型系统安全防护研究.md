---
title: 专题·人工智能安全治理 | 基于人工智能安全治理框架的大模型系统安全防护研究
url: https://mp.weixin.qq.com/s?__biz=MzA5MzE5MDAzOA==&mid=2664237597&idx=2&sn=e7c86941652f2030de58ceae9f864480&chksm=8b5808e4bc2f81f22f8a9eec00cc27f8c378dd2ff41add05889dcd8c4eb970db11093d5db942&scene=58&subscene=0#rd
source: 中国信息安全
date: 2025-03-01
fetch_date: 2025-10-06T21:59:11.667419
---

# 专题·人工智能安全治理 | 基于人工智能安全治理框架的大模型系统安全防护研究

![cover_image](https://mmbiz.qpic.cn/sz_mmbiz_jpg/1brjUjbpg5wskAeAw0dHj7eJVNHzMI0RLhO80uRMLWibjbj7qxCt9hquLHXIEJOmU5O6ZCsBDxmM2GkjR2uBiaicA/0?wx_fmt=jpeg)

# 专题·人工智能安全治理 | 基于人工智能安全治理框架的大模型系统安全防护研究

原创

吕延辉等

中国信息安全

![](https://mmbiz.qpic.cn/sz_mmbiz_gif/1brjUjbpg5y7Kia8T67ffDGEg7bnuTKCkl1KFCHPXpG73xqKywXNNALqhPMv9UG5KcpZCicICmSVluScjicRDN52w/640?wx_fmt=gif&from=appmsg)

![](https://mmbiz.qpic.cn/sz_mmbiz_png/1brjUjbpg5y7Kia8T67ffDGEg7bnuTKCkXn3CSbXxhOE7mXSn4eVkHibgyiaSHbKuYMzFR9LjVcHTd0U2V7xNp8lA/640?wx_fmt=png&from=appmsg)

![](https://mmbiz.qpic.cn/sz_mmbiz_gif/1brjUjbpg5y7Kia8T67ffDGEg7bnuTKCkl1KFCHPXpG73xqKywXNNALqhPMv9UG5KcpZCicICmSVluScjicRDN52w/640?wx_fmt=gif&from=appmsg)

**扫码订阅《中国信息安全》**

邮发代号 2-786

征订热线：010-82341063

文 | 北京天融信网络安全技术有限公司 吕延辉 张博 高彦恺

2022 年 11 月，OpenAI 发布了基于生成式人工智能大模型的问答机器人应用 ChatGPT，与以往同类应用相比，ChatGPT 显著提升了对内容的通用理解与生成能力，引起了全球各行业的广泛关注。人工智能快速进入大模型时代，大模型正在发展成为新一代信息基础设施。根据中国信通院发布的《全球数字经济白皮书（2024 年）》，截至 2024 年 7 月，全国已有 197 项生成式人工智能服务通过备案审核，标志着我国在规范人工智能市场和推动技术健康发展方面取得了重要进展。然而，大模型在带来巨大发展机遇的同时，也带来了新的安全风险与挑战。2024 年 9 月 9 日，全国网络安全标准化技术委员会（以下简称“网安标委”）正式发布《人工智能安全治理框架》（以下简称《框架》），为大模型安全风险分析和防护能力建设提供了顶层指导。

**一、《框架》概述**

在人工智能发展的关键时期，《框架》这一重要政策文件的推出，不仅在一定程度上完善了我国的人工智能治理体系，也顺应了全球人工智能技术与治理发展的潮流。《框架》的出台，展现了我国对人工智能未来发展的把握和规划，为促进创新、合作和可持续发展奠定了坚实基础。这一文件不仅对我国人工智能领域的进步具有里程碑式的意义，也在国际舞台上展现了我国在人工智能治理方面的决心和开放姿态。

**（一）《框架》顺应全球人工智能治理趋势，并进一步落实《全球人工智能治理倡议》**

人工智能安全治理已成为国际共识，各国纷纷发布人工智能安全治理政策和方案。2020年，美国发布了《人工智能应用监管指南备忘录（草案）》和《人工智能道德原则》，要求评估人工智能的安全风险。2022 年，加拿大出台了《人工智能与数据法》。2023 年 3 月，英国发布人工智能新监管提案（白皮书）《支持创新的人工智能监管方法》。2023 年 10 月，中国提出了《全球人工智能治理倡议》。同年 11 月，在英国召开的首届人工智能安全全球峰会上，中、美、英、德等 28 国及欧盟共同签署了《布莱切利宣言》，强调解决人工智能安全问题的紧迫性。2024 年，欧盟通过《人工智能法案》，提出人工智能分级监管机制。此外，IS0、NIST、ETSI、IEEE 等国际组织也较早开展人工智能安全相关研究，发布了多项人工智能伦理标准和研究报告。《框架》的发布是《全球人工智能治理倡议》的贯彻落实，进一步推动人工智能治理体系达成广泛共识。

**（二）《框架》加强安全治理顶层设计，推动人工智能安全可持续发展**

近年来，我国陆续发布了一系列与人工智能安全相关的政策法规。2021 年，国家网信办发布《互联网信息服务算法推荐管理规定》，确立了算法分级分类安全管理的制度设计。2022 年，国家网信办发布《互联网信息服务深度合成管理规定》，对应用生成与合成类算法的互联网信息服务进行了规范。2023 年，国家网信办发布《生成式人工智能服务管理暂行办法》，提出了促进创新和依法治理相结合的监管原则。2024 年，网安标委发布了《生成式人工智能服务安全基本要求》（TC260-003），明确了服务提供者应遵循的安全基本要求。《框架》以上述安全规范文件为基础，结合风险管理理念，梳理了人工智能在各种情形下可能面临的安全风险，并提出“包容审慎、确保安全，风险导向、敏捷治理，技管结合、协同应对，开放合作、共治共享”的治理原则。该框架为各方提供了共同遵循的规范，通过顶层设计推动人工智能技术的安全与可持续发展。

**（三）《框架》系统性阐述人工智能安全风险治理体系**

《框架》基于风险管理理念，系统梳理了人工智能的内生安全风险与应用安全风险，并提出了相应的技术应对及综合治理措施。内生安全风险指人工智能自身缺陷和不足引发的风险，包括模型算法安全、数据安全、系统安全等 3 类共 13 项安全风险。应用安全风险则是指人工智能的不当使用、滥用甚至恶意利用而产生的安全风险，涵盖网络域、现实域、认知域和伦理域等 4 类共 13 项安全风险。

针对以上风险，《框架》明确了模型算法研发者、服务提供者和系统使用者等不同角色需要在训练数据、算力设施、模型算法、产品服务、应用场景等方面采取技术性防范措施。《框架》提出了 39 项技术应对措施和 9 项综合治理措施，并制定了人工智能安全开发应用指引，为相关主体参与治理提供了重要参考和政策工具箱。鉴于人工智能应用的快速发展，需坚持风险导向和敏捷治理的原则，密切关注安全风险的演变，动态、精准地调整治理措施，不断优化治理机制与方式，以确保人工智能技术的安全可持续发展。

**二、《框架》指导的大模型系统安全防护**

大模型系统是指基于大模型进行数据处理或提供大模型服务的系统或平台，其生命周期通常包括设计、研发、训练、测试、部署、使用和维护等阶段。在整个生命周期中，大模型系统面临大量内生安全风险与应用安全风险。

**在内生安全风险方面，**大模型系统在许多应用场景中处理大量敏感数据和个人信息，如用户搜索记录、社交媒体互动或交易信息等，因此存在数据泄露和隐私侵犯的显著风险。此外，大模型本身可能因存在缺陷或后门成为攻击者的目标，带来严重的安全隐患。模型参数和权重的泄露不仅可能导致知识产权的损失，还可能被恶意使用者复制或用于修改模型，从而进一步加剧安全风险。针对模型的特定攻击（如投毒攻击）可能导致模型的输出结果被操控，从而产生不良影响或干扰正常业务的运行。

**在应用安全风险方面，**大模型系统往往作为知识载体，支撑人类认知决策，同时涉及《框架》中提到的网络域、现实域、认知域和伦理域等多方面风险。尤其是在网络域的信息内容安全风险，大模型生成的内容可能引发虚假信息传播、歧视偏见、隐私泄露、侵权、有害内容等问题，进而威胁公民生命财产安全、国家安全、意识形态安全和伦理安全。

在《框架》指导下，本文围绕大模型设计、研发、训练、测试、部署、使用、维护等全生命周期，针对模型算法、数据、系统、信息内容安全等关键风险领域，提出了具体的防护措施建议。

**（一）模型算法安全风险应对**

《框架》指出，应针对模型算法安全风险，不断提高人工智能的可解释性和可预测性，并在设计、研发、部署、维护的各个阶段建立并实施安全开发规范。同时，应积极推进人工智能可解释性研究、构建负责任的人工智能研发与应用体系。

建议在立项前对潜在风险进行全面梳理和深入分析，并在大模型系统生命周期的各个阶段落实针对性的安全防护措施。一是增加内容过滤模块，对大模型系统训练所用的输入数据进行检测和过滤，同时引入风控机制，动态评估数据供应商提供的数据质量；二是在模型存储和传输环节，实施加密保护和完整性校验，保障模型在静态存储和跨节点传输过程中具备保密性和完整性；三是采用访问控制、身份验证和差分隐私等技术手段，防止模型在服务过程中泄露模型参数和可标识信息等敏感数据；四是定期对模型框架、第三方库及预训练模型进行安全检测，发现问题后及时修复和处置。此外，应建立完善的模型安全管理制度，包括模型的科技伦理审查以及模型上线、下线和变更流程规范。还需要定期对模型开发人员进行安全知识培训与考核，以提升整体安全管理能力。

**（二）数据安全风险应对**

《框架》指出，针对数据安全风险，应加强相关知识产权保护措施，严格筛选和过滤训练数据，确保数据来源合法、真实、准确，加强数据安全管理，保护个人敏感信息及重要数据，并完善人工智能领域的数据安全和个人信息保护规范。

建议在大模型系统所需的数据资源管理中，应在采集、清洗、标注、传输和存储等多个阶段落实安全防护与信息审查等制度，形成闭环的数据安全体系。

**一是在数据收集阶段，**应与数据源主体签订协议，明确记录收集目标和应用场景，以确保可追溯性。同时，建立数据审核和过滤规则，通过合规性审核确保数据源的合法性和安全性，并要求第三方提供相关承诺和证明。关键数据应使用密码技术加密保护，以确保在采集和传输过程中的数据完整性和保密性。

**二是在数据清洗阶段，**应对采集的数据进行细致的安全审查，移除潜在的恶意代码和不当内容，识别并清除可能侵犯知识产权的数据。经过清洗后，对数据进行严格验证，确保符合质量标准和预期要求。

**三是在数据标注阶段，**应制定详尽的数据标注规则，涵盖标注对象、数据格式、标注方法和评估指标等关键要素，同时严格遵守数据标注过程中的安全操作规范，确保数据标注的安全性和准确性。定期对标注工具或平台进行全面安全审计，一旦发现安全漏洞，应立即采取有效措施进行修复和处置，维护数据标注流程的完整性和可靠性。

**四是在数据传输阶段，**应定义安全强度较高的数据传输通道，持续监测数据采集和分发等标准环节数据通道的安全环境，及时发现和修复漏洞。对数据通道的访问权限进行严格限制，实现精细化权限管理，保障数据在传输过程中的安全性。

**五是在数据存储阶段，**采取技术措施保护用户训练数据的存储环境，防止未授权访问、泄露或篡改。严格控制数据访问权限，确保只有授权用户可以使用和管理训练数据。当需要与第三方机构共同处理敏感数据时，应采用数据安全沙箱和隐私计算技术，在保护数据隐私的前提下，实现数据的安全处理和计算。

**（三）系统安全风险应对**

《框架》指出，为应对系统安全风险，应加强风险识别、检测与防护，提升人工智能算力平台和系统服务的安全建设、管理及运维能力，强化人工智能供应链安全保障、人工智能安全风险威胁信息共享和应急处置机制。建议在系统部署、测试、运行等阶段落实检测、监测、管理、评估等相关安全措施，构建可持续的大模型系统动态防护体系。

**安全检测。**采用先进的技术手段，对各类攻击行为（如模型窃取、数据重构、提示注入、后门植入、漏洞利用和拒绝服务）进行严密监控，并详细记录攻击源 IP 地址、攻击类型、攻击目的和攻击时间等关键信息。同时，定期开展安全性测试，及时修复发现的安全漏洞，确保系统的安全性和可靠性。

**安全监测。**持续监测业务运行状况，在业务出现异常情况时迅速发出预警。采集大模型系统中各运行设备的日志，以及时发现潜在的网络攻击行为。此外，应记录模型调用过程中涉及的系统行为和用户行为信息，包括主体、行为、对象、时间、结果等，以便追踪和分析。针对系统可能涉及的供应链，应设置安全评审及状态上报机制（并设置供应链安全检查机制），对所有环境变更节点进行严格检测，确保供应链安全。

**安全管理。**建立完善的安全事件管理制度，规范安全事件的分类、分级和处置流程，为大模型业务相关的安全事件制定应急预案。一旦发现违法不良信息或个人信息泄露，应立即采取有效应对措施。同时，定期组织相关人员开展应急预案培训和演练，提高突发事件处置能力。

**安全评估。**定期对大模型系统进行模型对抗性测试、生成内容安全评估和系统稳定性评估等，确保服务的安全性和稳定性。针对大模型系统存在的风险，进行细致识别和分类分级，构建大模型系统安全评估体系，并基于评估结果持续丰富测试用例。对于测试中发现的共性问题，应及时通报并采取有效整改措施。

**（四）信息内容安全风险应对**

《框架》指出，信息内容安全风险对公民生命财产安全、国家安全、意识形态安全和伦理安全构成威胁，因此需建立完善的安全防护机制和数据保护措施。《生成式人工智能服务安全基本要求》中明确了 5 类 31 种语料及生成内容的安全风险：包括违反社会主义核心价值观、歧视性、商业违法违规、侵犯他人合法权益、无法满足特定服务类型等。为此，建议建立以下机制。

**一是设置“数据围栏”。**在输入阶段，应该对文本、图片、音频和视频等所有内容进行违法或不良信息的检测与过滤，同时建立识别机制，拒绝回复包含违法内容、不良信息或明显诱导生成此类信息的不合理输入。此外，应注重正向引导，确保合法合规的输入得到正常回应。在输出阶段，对生成内容进行安全检测，及时阻止违法、不良信息的发布，维护清朗的网络环境。

**二是设置“AIGC 内容标识”。**在大模型系统生成内容的显示区域中或周边显著位置添加提示标识，例如“由人工智能生成”或“由 AI 生成”等，明确告知用户该内容源于 AI 技术。对于图片、音频和视频等多媒体内容，应附加隐式提示标识，如服务提供者名称或内容 ID 等信息，以帮助用户识别内容来源和服务提供者。这些措施有助于用户区分人工创作与 AI 生成内容，同时保护内容创作者的合法权益。

**三是设置“用户提醒及反馈”。**平台与用户签订协议，明确相关安全责任，并提醒用户在使用生成内容时可能面临的知识产权风险。同时，建立用户反馈机制，允许平台用户投诉不当或有害内容。对于用户举报或平台自查发现的内容安全问题，应及时处理，并通过指令微调、强化学习等方式优化模型。建立内容安全的持续优化与更新机制，以保障内容的安全性和真实可信度。

**三、结 语**

大模型在推动全球科技新高地、开拓未来产业新赛道等方面具有得天独厚的优势、巨大的发展潜力和广阔的应用前景，是未来经济发展的重要引擎。安全是发展的基石，大模型安全防护是大模型技术健康应用、可持续发展的重要保障。针对模型算法安全、数据安全和系统安全等内生安全风险，以及网络域、现实域、认知域和伦理域等应用安全风险，各企业应积极探讨相关的安全实践路线，确保人工智能应用的良性发展。

（本文刊登于《中国信息安全》杂志2024年第10期）

**分享网络安全知识 强化网络安全意识**

**欢迎关注《中国信息安全》杂志官方抖音号**

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/1brjUjbpg5y7Kia8T67ffDGEg7bnuTKCkUOkdfx1VzjgSRTKm1NUkvichczQibaOvdAUVZTicPicZXbskyTjXBacepQ/640?wx_fmt=jpeg&from=appmsg)

**《中国信息安全》杂志倾力推荐**

**“企业成长计划”**

**点击下图 了解详情**

[![](https://mmbiz.qpic.cn/sz_mmbiz_png/1brjUjbpg5y7Kia8T67ffDGEg7bnuTKCkibkibpYicNuuibKodkOxiafYGdtAzm3FOvk9gAg7gd50zlytl7tHFxrJgGQ/640?wx_fmt=png&from=appmsg)](https://mp.weixin.qq.com/s?__biz=MzA5MzE5MDAzOA==&mid=2664162643&idx=1&sn=fcc4f3a6047a0c2f4e4cc0181243ee18&scene=21#wechat_redirect)

预览时标签不可点

![]()

微信扫一扫
关注该公众号

继续滑动看下一个

轻触阅读原文

![](http://mmbiz.qpic.cn/sz_mmbiz_png/1brjUjbpg5xcg6pmGiagMsJTqnHObJGHSj6TEe6InbwlHLIxFVhPohvicQibAcuia5wDEoRISsAkUyYPUB06cU9mibw/0?wx_fmt=png)

中国信息安全

向上滑动看下一个

知道了

![]()
微信扫一扫
使用小程序

取消
允许

取消
允许

取消
允许

×
分析

![跳转二维码]()

![作者头像](http://mmbiz.qpic.cn/sz_mmbiz_png/1brjUjbpg5xcg6pmGiagMsJTqnHObJGHSj6TEe6InbwlHLIxFVhPohvicQibAcuia5wDEoRISsAkUyYPUB06cU9mibw/0?wx_fmt=png)

微信扫一扫可打开此内容，
使用完整服务

：
，
，
，
，
，
，
，
，
，
，
，
，
。

视频
小程序
赞
，轻点两下取消赞
在看
，轻点两下取消在看
分享
留言
收藏
听过