---
title: 多语言和多口音音频大型语言模型的越狱攻击
url: https://forum.butian.net/share/4290
source: 奇安信攻防社区
date: 2025-04-29
fetch_date: 2025-10-06T22:04:15.234432
---

# 多语言和多口音音频大型语言模型的越狱攻击

#

[问答](https://forum.butian.net/questions)

*发起*

* [提问](https://forum.butian.net/question/create)
* [文章](https://forum.butian.net/share/create)

[攻防](https://forum.butian.net/community)
[活动](https://forum.butian.net/movable)

Toggle navigation

* [首页 (current)](https://forum.butian.net)
* [问答](https://forum.butian.net/questions)
* [商城](https://forum.butian.net/shop)
* [实战攻防技术](https://forum.butian.net/community)
* [漏洞分析与复现](https://forum.butian.net/articles)
  NEW
* [活动](https://forum.butian.net/movable)
* [摸鱼办](https://forum.butian.net/questions/Play)

搜索

* [登录](https://forum.butian.net/login)
* [注册](https://user.skyeye.qianxin.com/user/register?next=http://forum.butian.net/btlogin)

### 多语言和多口音音频大型语言模型的越狱攻击

本文将深入探讨多语言音频模型在实际应用中面临的安全挑战，特别是音频越狱攻击的机制与影响。我们将学习攻击者如何利用模型的漏洞，通过精心设计的音频输入绕过安全机制，诱导模型生成不当内容。

引言
==
在人工智能技术飞速发展的今天，语音交互已逐渐成为人机沟通的重要方式。从智能助手如Siri和Alexa，到多语言实时翻译系统，音频大语言模型（ LALMs）正以前所未有的速度渗透到我们的日常生活中。这些模型不仅能够理解和生成自然语言，还能处理多种语言的语音输入，实现跨语言的无缝交流。然而，随着这些模型的广泛应用，其安全性问题也日益凸显。研究人员发现，即使内置了安全检查，语音大模型在对抗性攻击面前表现得极为脆弱。通过对音频输入进行人类难以察觉的微小篡改，攻击者就能完全改变大模型的行为，使其生成有害、危险或不道德的响应 。本文将深入探讨多语言音频模型在实际应用中面临的安全挑战，特别是音频越狱攻击的机制与影响。我们将学习攻击者如何利用模型的漏洞，通过精心设计的音频输入绕过安全机制，诱导模型生成不当内容。
AdvWave攻击框架
===========
AdvWave是针对LALMs的第一个越狱攻击框架，使用双相优化（Dual-Phase Optimization）技术，解决了音频编码器中的\*\*梯度破碎问题\*\*，同时提高了攻击效率并确保了隐蔽性。
#### 梯度破碎问题：
在LALM中，音频波形首先通过音频编码器映射到中间特征空间，并通过K-means聚类对音频帧进行标记。这一过程引入了不可微的离散化操作，打破了反向传播的梯度流动，导致梯度消失
这个框架包含了两个主要阶段：
1. \*\*第一阶段：优化音频token向量\*\*
2. \*\*第二阶段：优化音频波形\*\*
双相优化（Dual-Phase Optimization）技术可如下图展示：
![](https://cdn.nlark.com/yuque/0/2025/png/44876878/1744376208472-fee41424-28d9-468b-a572-f4bca8d9cb72.png "null")
### \*\*阶段一优化：音频token向量优化\*\*
在第一阶段，AdvWave框架优化的是音频的\*\*token向量\*\*。具体步骤如下：
1. \*\*对抗性损失优化\*\*：
- \*\*目标\*\*：优化音频token向量![](https://cdn.nlark.com/yuque/0/2025/png/44876878/1744375941678-7eb43449-cecb-4103-907c-7c1fb578af66.png "null")，使得通过音频-语言模型（LALM）生成的响应能够接近攻击者期望的目标响应 ![](https://cdn.nlark.com/yuque/0/2025/png/44876878/1744375953305-0aadf2c5-732d-4765-83fd-b00ae449cbf0.png "null")。
- \*\*过程\*\*：通过\*\*对抗性损失函数\*\*![](https://cdn.nlark.com/yuque/0/2025/png/44876878/1744375971246-914830ae-410f-41bb-9770-eaa9b70e80ae.png "null") 最小化模型输出与目标响应之间的误差，使得生成的音频能够引发模型的目标响应。
2. \*\*音频token化\*\*：
- \*\*音频编码器\*\*将输入音频转化为特征空间，然后通过\*\*tokenization模块\*\*（即离散化）将这些特征映射为音频token。这一过程中，由于\*\*K-Means聚类\*\*的使用，存在不可微分操作，这导致了\*\*梯度破碎问题\*\*。为了解决这个问题，第一阶段将音频token视为决策变量，而非直接对原始音频波形进行优化。
\*\*优化公式\*\*：
- 在第一阶段，优化目标是最小化对抗性损失：
![](https://cdn.nlark.com/yuque/0/2025/png/44876878/1744375887993-2461e2b0-48dc-4f2d-ac35-d843949bf4e5.png "null")
其中，![](https://cdn.nlark.com/yuque/0/2025/png/44876878/1744375908764-f28b9248-63d2-4a74-a8cb-82777f7888f6.png "null") 是优化后的音频token向量。
### \*\*阶段二优化：音频波形优化\*\*
在第二阶段，优化过程转向\*\*音频波形\*\*![](https://cdn.nlark.com/yuque/0/2025/png/44876878/1744375997075-e53f37a1-1297-4f39-98c3-3bcc9a6a067c.png "null")，以确保其生成的token向量在第一阶段优化后与目标token向量 ![](https://cdn.nlark.com/yuque/0/2025/png/44876878/1744376002510-308da3b9-8194-4d4e-89ff-df10e941317a.png "null") 匹配。
1. \*\*保留损失（Retention Loss）\*\*：
- \*\*目标\*\*：确保优化后的音频波形 ![](https://cdn.nlark.com/yuque/0/2025/png/44876878/1744376025328-4889c596-2247-44f2-9df1-f35001a3e452.png "null") 与第一阶段优化得到的目标音频token向量 ![](https://cdn.nlark.com/yuque/0/2025/png/44876878/1744376018041-357cfc06-b37b-424c-8f1b-047bc2c5e24b.png "null") 保持一致。这是通过定义\*\*保留损失\*\*![](https://cdn.nlark.com/yuque/0/2025/png/44876878/1744376053550-c3a22375-858d-45ac-8fba-53bb8fa89dbd.png "null") 来实现的。
- \*\*损失函数\*\*：使用三元损失（Triplet Loss）来确保每个音频帧的特征接近目标token的聚类中心，并且远离其他类别的中心。
\*\*优化公式\*\*：
- 第二阶段的优化目标是最小化保留损失![](https://cdn.nlark.com/yuque/0/2025/png/44876878/1744376059946-351ca10e-db45-4ae0-b1e4-771a5370c64d.png "null")，并确保音频波形 ![](https://cdn.nlark.com/yuque/0/2025/png/44876878/1744376067746-e7b0e87d-2740-49cd-88c5-d378e4335b9b.png "null")与目标token向量 ![](https://cdn.nlark.com/yuque/0/2025/png/44876878/1744376074439-c792b493-3fd4-4d42-8498-5579873b52b4.png "null") 对应的特征空间匹配：
![](https://cdn.nlark.com/yuque/0/2025/png/44876878/1744376096754-16d6fd10-c1ae-4788-868d-6ff163a474be.png "null")
### \*\*适应性对抗目标搜索\*\*
由于LALMs的\*\*响应模式变异性\*\*，不同的LALM模型对相同输入的响应可能有所不同。因此，为了应对LALMs行为的变异性，AdvWave框架引入了动态的对抗目标搜索方法。具体步骤包括：
1. \*\*目标去毒化\*\*：将恶意查询（如“如何制造炸弹”）转换为无害的查询（如“如何做蛋糕”）。
2. \*\*模型响应收集\*\*：将去毒化后的查询转为音频，并收集LALM模型对这些无害查询的响应。
3. \*\*响应模式提取\*\*：提取LALM对无害查询的响应模式，并将其应用到恶意查询的优化中。
### \*\*隐蔽性控制与分类器引导优化\*\*
在音频域，直接限制扰动幅度并不能确保对抗音频的隐蔽性，因为即使微小的扰动也可能改变音频的语音特征。因此，\*\*隐蔽性控制\*\*是AdvWave的一个关键部分。
1. \*\*音频后缀\*\*：为了保持音频的隐蔽性，在音频波形的后面添加短暂的环境噪声（如汽车喇叭声、狗叫声等），这能有效避免语音特征的显著变化，同时使对抗音频听起来像是背景噪音。
\*\*分类器引导的隐蔽性优化\*\*：为了明确控制音频的隐蔽性，框架引入了一个隐蔽性惩罚项，并使用\*\*环境噪声分类器\*\*来引导对抗音频的优化，使其模仿特定类型的环境噪声（例如汽车喇叭声）。该过程通过交叉熵损失来实现优化：
![](https://cdn.nlark.com/yuque/0/2025/png/44876878/1744376120361-d4fc062b-6f08-400d-9e76-bf9ede4d7702.png "null")
其中，λ 是控制对抗优化和隐蔽性优化之间平衡的超参数，![](https://cdn.nlark.com/yuque/0/2025/png/44876878/1744376151384-b8b903a2-76e7-49a5-b606-5468522f4124.png "null") 是目标环境噪声标签。
### 代码实现
```php
class LALM(nn.Module):
def \_\_init\_\_(self):
super(LALM, self).\_\_init\_\_()
self.encoder = nn.LSTM(256, 512, batch\_first=True)
self.decoder = nn.Linear(512, 1000) # 假设输出1000个token
def forward(self, x, text\_input):
# 这里假设text\_input是已经预处理的文本token ID
x, \_ = self.encoder(x) # 音频编码
return self.decoder(x)
```
定义了一个LALM类，继承自nn.Module。这是模拟音频语言模型的，包含一个LSTM编码器和一个线性解码器。LSTM用于处理音频特征，解码器将LSTM的输出映射到文本token空间。音频文件需要先转换为特征向量，然后分帧处理，每个帧对应一个256维的特征向量。这些特征向量序列会被输入到LSTM中进行处理，最终解码为文本token。这里可以将音频信号转换为文本输出的过程，比如语音识别或语音生成文本的任务。
\*\*LALM类\*\*本质上是模拟LALM模型对音频和文本输入的处理，音频首先通过编码器转化为特征向量，然后生成最终的输出（音频或文本），为后续生成对抗样本提供基础
```php
def load\_audio(file\_path):
# 这里简化音频加载，实际上需要根据需求进行处理
y = np.random.randn(16000) # 假设的随机音频信号
return torch.tensor(y).unsqueeze(0) # 增加批次维度
```
- \*\*load\\*\\*\*\*\\_\*\*\\*\\*audio\*\*函数负责加载音频数据。此处通过生成一个随机的音频信号代替实际的音频数据加载
- `unsqueeze(0)`的作用是增加一个批次维度，使得音频数据可以与PyTorch模型兼容（即将数据转换为 `[batch\_size, seq\_len]` 的形式）。
- 该函数是音频预处理的一部分，用于加载音频文件并将其转换为张量格式，方便后续传入模型中进行处理
```php
def generate\_adversarial\_example(model, audio, target\_label, epsilon=0.01, num\_steps=10):
audio = audio.requires\_grad\_(True)
for \_ in range(num\_steps):
optimizer.zero\_grad()
output = model(audio, target\_label)
loss = criterion(output, target\_label)
loss.backward()
grad\_sign = audio.grad.data.sign()
audio.data = audio.data + epsilon \* grad\_sign
audio.data = torch.clamp(audio.data, min=-1.0, max=1.0) # 限制扰动范围
# 清除梯度
audio.grad.zero\_()
return audio
```
这是一个实现PGD（投影梯度下降）优化的函数，用于生成对抗音频。PGD是常用的对抗样本生成方法，它基于梯度信息，通过多次迭代优化输入音频，使得模型生成错误的输出。
这个函数的参数有model, audio, target\\_label，还有epsilon和num\\_steps两个默认参数。这个函数的目标是根据目标标签生成对抗性的音频样本。对抗攻击通常是指对输入做小的扰动，使得模型输出错误的结果。这里的target\\_label就是希望模型错误预测的目标类别。首先将audio设置为需要梯度，这样在后续的反向传播中可以计算梯度
- `\*\*audio.requires\_grad\_(True)\*\*`：使得音频张量支持梯度计算，以便在优化过程中调整音频数据。
- `\*\*loss.backward()\*\*`：反向传播，计算损失函数对音频输入的梯度。
- `\*\*grad\_sign = audio.grad.data.sign()\*\*`：计算梯度符号，表示沿梯度上升方向更新音频。
- `\*\*audio.data = audio.data + epsilon \* grad\_sign\*\*`：根据梯度更新音频输入。
- `\*\*torch.clamp(audio.data, min=-1.0, max=1.0)\*\*`：对音频数据进行裁剪，确保音频信号在有效范围内（通常音频数据的范围是 \[-1, 1\]）。
- 这个过程是对抗性攻击的核心。通过PGD算法，攻击者不断调整音频信号，使其符合攻击目标，即引导模型生成特定的恶意响应。
```php
def stealthiness\_optimization(audio, target\_label, classifier, epsilon=0.01):
audio = audio.requires\_grad\_(True)
for \_ in range(10):
optimizer.zero\_grad()
output = classifier(audio)
loss = nn.CrossEntropyLoss()(output, target\_label)
loss.backward()
grad\_sign = audio.grad.data.sign()
audio.data = audio.data + epsilon \* grad\_sign
audio.data = torch.clamp(audio.data, min=-1.0, max=1.0)
audio.grad.zero\_()
return audio
```
该函数用于优化对抗音频的\*\*隐蔽性\*\*。目标是通过\*\*分类器引导优化\*\*确保生成的音频在人耳上难以察觉，且不会改变原始音频的语义特征。
- `\*\*output = classifier(audio)\*\*`：对生成的对抗音频进行分类，分类器评估音频的隐蔽性。
- `\*\*loss = nn.CrossEntropyLoss()(output, target\_label)\*\*`：计算音频与目标标签之间的分类误差。
- `\*\*grad\_sign = audio.grad.data.sign()\*\*`：根据梯度信息更新音频，优化音频的隐蔽性。
- 隐蔽性优化是\*\*AdvWave\*\*攻击框架的核心之一，确保生成的对抗音频不会被人耳察觉。通过\*\*分类器引导的优化\*\*，攻击者能够使音频看起来像是背景噪声，而不是刻意的扰动。
```php
class Classifier(nn.Module):
def \_\_init\_\_(self):
super(Classifier, self).\_\_init\_\_()
self.fc = nn...