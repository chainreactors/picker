---
title: GitLab Duo Vulnerability Enabled Attackers to Hijack AI Responses with Hidden Prompts
url: https://thehackernews.com/2025/05/gitlab-duo-vulnerability-enabled.html
source: The Hacker News
date: 2025-05-24
fetch_date: 2025-10-06T22:31:24.159642
---

# GitLab Duo Vulnerability Enabled Attackers to Hijack AI Responses with Hidden Prompts

#1 Trusted Cybersecurity News Platform

Followed by 5.20+ million[**](https://twitter.com/thehackersnews)
[**](https://www.linkedin.com/company/thehackernews/)
[**](https://www.facebook.com/thehackernews)

[![The Hacker News Logo](data:image/png;base64...)](/)

**

**

[** Subscribe – Get Latest News](#email-outer)

* [** Home](/)
* [** Newsletter](#email-outer)
* [** Webinars](/p/upcoming-hacker-news-webinars.html)

* [Home](/)
* [Data Breaches](/search/label/data%20breach)
* [Cyber Attacks](/search/label/Cyber%20Attack)
* [Vulnerabilities](/search/label/Vulnerability)
* [Webinars](/p/upcoming-hacker-news-webinars.html)
* [Expert Insights](https://thehackernews.com/expert-insights/)
* [Contact](/p/submit-news.html)

**

**

**

Resources

* [Webinars](/p/upcoming-hacker-news-webinars.html)
* [Free eBooks](https://thehackernews.tradepub.com)

About Site

* [About THN](/p/about-us.html)
* [Jobs](/p/careers-technical-writer-designer-and.html)
* [Advertise with us](/p/advertising-with-hacker-news.html)

Contact/Tip Us

[**

Reach out to get featured—contact us to send your exclusive story idea, research, hacks, or ask us a question or leave a comment/feedback!](/p/submit-news.html)

Follow Us On Social Media

[**](https://www.facebook.com/thehackernews)
[**](https://twitter.com/thehackersnews)
[**](https://www.linkedin.com/company/thehackernews/)
[**](https://www.youtube.com/c/thehackernews?sub_confirmation=1)
[**](https://www.instagram.com/thehackernews/)

[** RSS Feeds](https://feeds.feedburner.com/TheHackersNews)
[** Email Alerts](#email-outer)

[![Salesforce Security Handbook](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjWa8tsMNqlevi1HGF1ALQRGIq7hROPFAbHd3R1RTEOe73T8_Q2xW_-91t2jSGjU5peiPb8QYblGp4igNW-u2Qmlxbp2BKzTVMSvyXDZJmC-BYpiiJHrcnG5drmSP97iZ9PVIf1DeEr7U-7vWpe4HXwfMjt8FGNgq5mOycOJluYr9wF7YOKrQY9MfArwgjt/s728-e100/ai-agent-security-d.png)](https://thehackernews.uk/ai-agent-security-d)

# [GitLab Duo Vulnerability Enabled Attackers to Hijack AI Responses with Hidden Prompts](https://thehackernews.com/2025/05/gitlab-duo-vulnerability-enabled.html)

**May 23, 2025**Ravie LakshmananArtificial Intelligence / Vulnerability

[![GitLab Duo Vulnerability](data:image/png;base64... "GitLab Duo Vulnerability")](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi6rLz8E8y35sHM8TWfaLGk239gaYvBBKdIcdL9BuZvls9_VuE6SdzrpAUD3R8Up1Z4NeixlG__CpnoDmrLsH0ITHCiU_Fv45yZXKI76_NjsPb90Fnj5gbXQsJY7I_u7GpTAGIbHFLjPNMFh7BbHYIH06q92FsNRtv9jeuEMoAXYGBhG1i1XsyaeGTut7Kx/s790-rw-e365/prompt.jpg)

Cybersecurity researchers have discovered an indirect prompt injection flaw in GitLab's artificial intelligence (AI) assistant Duo that could have allowed attackers to steal source code and inject untrusted HTML into its responses, which could then be used to direct victims to malicious websites.

[GitLab Duo](https://about.gitlab.com/gitlab-duo/) is an artificial intelligence (AI)-powered [coding assistant](https://about.gitlab.com/blog/2024/01/16/gitlab-uses-anthropic-for-smart-safe-ai-assisted-code-generation/) that enables users to write, review, and edit code. Built using Anthropic's Claude models, the service was first launched in June 2023.

But as Legit Security [found](https://www.legitsecurity.com/blog/remote-prompt-injection-in-gitlab-duo), GitLab Duo Chat has been susceptible to an indirect prompt injection flaw that permits attackers to "steal source code from private projects, manipulate code suggestions shown to other users, and even exfiltrate confidential, undisclosed zero-day vulnerabilities."

Prompt injection refers to a [class of vulnerabilities](https://thehackernews.com/2024/09/chatgpt-macos-flaw-couldve-enabled-long.html) common in AI systems that enable threat actors to weaponize large language models (LLMs) to [manipulate responses](https://www.paloaltonetworks.com/cyberpedia/what-is-a-prompt-injection-attack) to users' prompts and result in undesirable behavior.

[Indirect prompt injections](https://securelist.com/indirect-prompt-injection-in-the-wild/113295/) are a [lot more trickier](https://www.reversinglabs.com/blog/indirect-prompt-injections-target-llm-data) in that instead of providing an AI-crafted input directly, the rogue instructions are embedded within another context, such as a document or a web page, which the model is designed to process.

[![DFIR Retainer Services](data:image/png;base64...)](https://thehackernews.uk/cloud-insight-d)

Recent studies have shown that LLMs are also vulnerable to [jailbreak attack techniques](https://www.arxiv.org/abs/2505.10066) that make it [possible](https://hiddenlayer.com/innovation-hub/prompt-injection-attacks-on-llms/) to trick AI-driven chatbots into generating harmful and illegal information that [disregards their ethical and safety guardrails](https://news.microsoft.com/source/features/ai/safeguarding-ai-against-jailbreaks-and-other-prompt-attacks/), effectively obviating the need for carefully crafted prompts.

What's more, Prompt Leakage (PLeak) methods could be used to inadvertently reveal the preset system prompts or instructions that are meant to be followed by the model.

"For organizations, this means that private information such as internal rules, functionalities, filtering criteria, permissions, and user roles can be leaked," Trend Micro [said](https://www.trendmicro.com/en_us/research/25/e/exploring-pleak.html) in a report published earlier this month. "This could give attackers opportunities to exploit system weaknesses, potentially leading to data breaches, disclosure of trade secrets, regulatory violations, and other unfavorable outcomes."

|  |
| --- |
| [![GitLab Duo Vulnerability](data:image/png;base64... "GitLab Duo Vulnerability")](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjbtRCgv4Q5HTi7BPRbCpJvDk5HSbXmoGN-Mn3TeMCLgJDKl906lUvdYMwKWQ3jdsWo4ynnC5If68Lj9cIt-MzNgjOhit36gmCJ6qtKRG0V5Fk-kCF0gt2FIePzyy-mM0T21zUbgVX1tfDz-IsBCCzan5w00iT7J9Yv1fcb_JR2BBB4CmusMBuApiyi6Mt0/s790-rw-e365/pleak.png) |
| PLeak attack demonstration - Credential Excess / Exposure of Sensitive Functionality |

The latest findings from the Israeli software supply chain security firm show that a hidden comment placed anywhere within merge requests, commit messages, issue descriptions or comments, and source code was enough to leak sensitive data or inject HTML into GitLab Duo's responses.

These prompts could be concealed further using encoding tricks like Base16-encoding, Unicode smuggling, and KaTeX rendering in white text in order to make them less detectable. The lack of input sanitization and the fact that GitLab did not treat any of these scenarios with any more scrutiny than it did source code could have enabled a bad actor to plant the prompts across the site.

[![GitLab Duo Vulnerability](data:image/png;base64... "GitLab Duo Vulnerability")](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgOBgMr0QmL4W0wJoBektLsH34wz6HTtc23RTylr5exvG9HFK1t1NnhbUk9kWKDOd968TACLD8kSOvsGZmW95lyu63K68_uK7YGU7EbftBWkyMhUHo-8Wq8M5rROT0avhBFrNULQiU63z2NA8aesYgpmyxW1g5tuiFYehcWkHnaFPB7DcVV2LN9hUKCPBdw/s790-rw-e365/gitlab.jpg)

"Duo analyzes the entire context of the page, including comments, descriptions, and the source code — making it vulnerable to injected instructions hidden anywhere in that context," security researcher Omer Mayraz said.

This also means that an attacker could deceive the AI system into including a malicious JavaScript package in a piece of synthesized code, or present a malicious URL as safe, causing the victim to be redirected to a fake login page that harvests their credentials.

On top of that, by taking advantage of GitLab Duo Chat's ability to access information about specific merge requests and the code changes inside of them, Legit Security found that it's possible to insert a hidden prompt in a merge request description for a project that, when processed by Duo, causes the private source code to be exfiltrated to an attacker-controlled serve...