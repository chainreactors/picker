---
title: 提前曝光 Llama 3.1，Meta 为什么想做「大模型界 Linux」？
url: https://mp.weixin.qq.com/s?__biz=MTMwNDMwODQ0MQ==&mid=2653048352&idx=1&sn=dc18c776cd7375cc03de759f8ec13937&chksm=7e5733964920ba80455391efa077fc4b49043c84a8c1dbf4775e43feb6f555eb3466705629df&scene=58&subscene=0#rd
source: 极客公园
date: 2024-07-26
fetch_date: 2025-10-06T17:43:32.241373
---

# 提前曝光 Llama 3.1，Meta 为什么想做「大模型界 Linux」？

![cover_image](https://mmbiz.qpic.cn/mmbiz_jpg/8cu01Kavc5ZFNw8tmZRRgSFFwSLNib972EbuVV7IeCO1ibvKUGR8SoRQzzbrwxexYT0mv0Fc5Xg1Kn6A4luQPnTg/0?wx_fmt=jpeg)

# 提前曝光 Llama 3.1，Meta 为什么想做「大模型界 Linux」？

原创

宛辰

极客公园

![](https://mmbiz.qpic.cn/mmbiz_jpg/8cu01Kavc5ZFNw8tmZRRgSFFwSLNib972HsAVNXjR8xlQkChgXdg01bBQPeIp8acJvz355WzYVuOspia2dxBy21Q/640?wx_fmt=jpeg&from=appmsg)

扎克伯格期待 Llama 3.1 成为「老师」，用来微调小模型。

**作者 | 宛辰****编辑**| 靖宇****

当地时间 7 月 23 日早上，Meta 开源了外界期待已久的大参数模型——Llama 3 405B。

Meta 发文称，该模型在多项基准测试中优于 GPT-4o 和 Anthropic 的 Claude 3.5 Sonnet。并且，扎克伯格预计，由 Llama3 支持的 Meta AI（Meta 的人工智能助手）使用量将在未来几个月内超过 ChatGPT。

比肩世界上最强大模型的 Llama3.1 开源，社交平台 X 上，很多人将这一事件视为历史、拐点、史诗级时刻，这意味开源、闭源之间的差距进一步缩小乃至反超，还意味着开发者从此有了一个免费的最强基座模型在手。

在扎克伯格看来，这个拐点时刻则意味着**「Llama 有机会成为开源****AI****的行业标准」，就像 Linux 之于移动互联网一样**。

但与之相反，不少从业者指出一个问题，4000 亿参数量级的密集模型，即便开源，很多人可能也用不起来，尤其是考虑到运行如此规模模型的算力集群的复杂程度，再加上比较高的运行、推理成本，真正能用得上、用得转的开发者并不多。

去年 Llama2 开源时，外界原本期待 Meta 逐渐开源最强模型后，难望项背的 GPT-4 能力的可以瞬间免费地加持所有人，直接拿来探索 AI 应用。但现在似乎不同，从最强模型中蒸馏小模型，成为了 Llama 3 405B 新的产业意义吗？

**01**

****Llama3.1：****

****比肩 GPT-4o，********非 MOE 架构，****

****但多模态能力仍是期货****

早在今年四月，Meta 先开源了 Llama3 系列的两个小参数版本的模型，8B 和 70B。比起几个月前的 Llama 3，现在推出的 Llama 3.1 升级了先前的 8B 和 70B 模型，还发布了迄今为止最大的开源模型 Llama 3 405B——后者拥有 4050 亿个模型参数，采用了密集 Transformer 架构，具有 128K 的上下文窗口。

![](https://mmbiz.qpic.cn/mmbiz_png/8cu01Kavc5ZFNw8tmZRRgSFFwSLNib9729Y1ibPazx4yibzwlSPpOxaY5JVAO3x6aibic8F691WMoDdjFOjsQ5kxsag/640?wx_fmt=png&from=appmsg)

相比 Meta 去年 7 月发布的 Llama2，迄今为止最大、最好的开源模型 Llama3.1 在众多方面做了升级。

* **数据：**使用了约 15T 的多语言 token，相较于 Llama 2 的 1.8T 有显著提升。
* **规模：**Llama 3 的训练规模是 Llama 2 的 50 倍，模型参数和训练计算量均大幅增加。
* **复杂性管理：**选择标准的密集 Transformer 架构，而非混合专家模型，以确保训练的稳定性。

![](https://mmbiz.qpic.cn/mmbiz_png/8cu01Kavc5ZFNw8tmZRRgSFFwSLNib972BGdT5YDFCuGaasrSRbHmPMpgGFLPTPR6Xgrsic4Tl3XoeGehgyAFChA/640?wx_fmt=png&from=appmsg)截图来源：Meet Llama 3.1

与行业水平相比，Llama 3 在多项任务上有着与领先模型（如 GPT-4）相当的性能，其在多个基准测试中表现优异，包括：

* 通用：在 MMLU、GSM8K 等基准上表现突出。
* 编程能力：在 HumanEval 和 MBPP 等编程基准上取得高分。
* 多语言能力：支持多种语言，尤其在德语、法语等语言上表现良好。

值得注意的是，去年 3 月 OpenAI 推出的 GPT-4 是拥有 1.8 万亿参数的 MOE 架构（混合专家模型），自那以来，海内外大模型厂商大都采用或者迁移至这一架构，但今天发布的 Llama3.1 并没有采用这一架构。

在目前火热的技术路线——多模态融合上，Llama3 目前也并不支持。官方论文介绍称，Llama 3.1 支持多语言、编程、推理和工具使用，但目前还无法处理图像、视频或语音。论文中提到，Meta 正在致力于为该模型添加图像识别、视频识别和语音理解功能，但具有这些功能的版本「仍在积极开发中，尚未准备好发布」。

**02**

****Meta 的星辰大海****

****是 AI 生态系统****

今年 4 月的一档播客访谈节目中，扎克伯格透露今年年末才会推出 Llama 3 405B，并且这个模型开源与否要视情况而定。显然，这个时间表被提前了，在其尚不支持多模态、模型能力也尚不完美时，现在就开源可获得。这是为什么？

在 Meta 官网，扎克伯格写了一封「开源 AI 是未来之路」（Open Source AI Is the Path Forward）的信，或许可以回答这个问题。

在他看来，**人工智能会以类似 Linux 的方式发展，而 Meta 有机会做大模型时代的 Linux，成为开源****AI****的行业标准**。

在高性能计算早期，主要科技公司都投入巨资开发自己的 Unix 闭源版本，当时也很难想象任何其他方法来开发软件。但最终，开源 Linux 获得了普及——最初是因为它允许开发人员随心所欲地修改其代码，而且价格更便宜，随着时间的推移，它变得更先进、更安全，并且拥有比任何封闭式 Unix 更广泛的生态系统，支持更多功能。如今，Linux 已成为云计算和运行大多数移动设备的操作系统的行业标准基础。

扎克伯格认为，**尽管多家公司正在开发领先的闭源模型，但开源正在迅速缩小差距**。以 Meta 为例，去年 Llama 2 只能与第一梯队玩家的旧版模型相媲美，今年，Llama 3 与最先进的模型竞争，并在某些方面处于领先地位。Meta 预计，未来的几代 Llama 将成为业内最先进的模型。

从这一代模型开始，Meta 还将通过建立广泛、开放的生态系统，致力于使开源 AI 成为行业标准，使 Llama 成为行业标准。比如像这次伴随 Llama3.1 的发布，与生态伙伴的「嵌合」也更加紧密：Amazon、Databricks 和英伟达推出全套服务来支持开发人员微调和「蒸馏」自己的模型。

像 Groq 这样的创新者已经为所有新模型构建了低延迟、低成本的推理。云厂商已经准备好云上部署 Llama3.1，包括 AWS、Azure、Google、Oracle 等。Scale.AI、戴尔、德勤等公司已准备好帮助企业采用 Llama 并使用自己的数据训练自定义模型。

![](https://mmbiz.qpic.cn/mmbiz_png/8cu01Kavc5ZFNw8tmZRRgSFFwSLNib972bta0taluTtHEY8ibQUPeV9Gic7LU8WVia0CLtxxMQ88evkqIN2SusS22Q/640?wx_fmt=png&from=appmsg)截图来源：Meet Llama 3.1

Meta 大力投资开源的根本原因，当然是希望确保其可以获得领先的模型。

但扎克伯格称，在 Llama-3.1 之前，他本能地认为，如果 Llama 开源，就会有一个社区自发地围绕它成长。或许是考虑到模型的部署不同于其他开源项目，还需要很多动手操作的环节、也需要很多资源支持，扎克伯格决定在扩展生态系统上更积极。

「我相信 Llama 3.1 版本将成为**行业的一个转折点，大多数开发人员开始主要使用开源**，并且我预计这种方法只会从这里开始发展。」

OpenAI 的愿景是构建一个大 AI，Anthropic 和谷歌也有类似的愿景。但 Meta 的愿景是有很多不同的模型。每个创业公司、每个企业、每个政府都希望拥有自己的定制模型。而当闭源生态系统比开源系统好得多时，使用现成的闭源模型是更好的选择，但现在不同了。

现在，开源基本上弥合了这一差距，人们现在有动力去定制和构建并训练适合他们需求的模型，将他们的数据训练到模型中。

**03**

****谁能用上 Llama 3.1？****

官方报告指出，Llama 3.1 使用了超过 1.6 万个英伟达 H100 GPU 训练而来，The Verge 根据其所用英伟达芯片的成本估计，其训练成本为数亿美元。

能省去这么一大笔钱，还有一个最强的基座模型，这是对开源最强模型的本能期待。但把模型落地到场景里，还有一个迫在眉睫的现实问题——到底有多少开发者有能力把 4050 亿参数的密集模型用起来。

![](https://mmbiz.qpic.cn/mmbiz_png/8cu01Kavc5ZFNw8tmZRRgSFFwSLNib9727NtvSIUCJxEuibktOqVbtWsMr6NsMNxu4ZPICzZ8bsfHasaDibTUVP8g/640?wx_fmt=png&from=appmsg)深度学习框架 PyTorch 的联合创始人、Facebook AI Research (FAIR) 的研究员 Soumith Chintala 发推称 Meta 调度 1.6 万 H100 GPU 算力集群的有效训练时间达到 90%。｜图片来源：X.com

Llama3 论文中，有很长的篇幅在讲基础设施，1.6 万张 H100 集群在训练过程中会如何失败，包括如何并行化、保持集群可靠等。对此，英伟达高级科学家 Jim Fan 转发点评，「基础设施工作是人工智能领域最被低估的工作，我能从这张表中的数字感受到内脏的疼痛和折磨」。

就运行 Llama 的开源模型而言，The Information 此前报道，应用程序开发者已经能够使用一组八个连接的 AI 服务器芯片（称为节点）来运行开源模型。Llama 3 的较小版本可以正常运行，但较大的模型可能无法适应单个节点，而是需要多个节点。

帮助开发人员运行开源模型的推理提供商表示，这会带来很多复杂性。为大模型提供支持的节点必须能够协同工作，或者相互「交谈」，而这并不容易设置。在某些情况下，这意味着节点在物理上必须彼此靠近。

通常，对于较小的模型，推理提供商可以使用相同的节点来处理不同客户的请求，只要他们使用相同的 LLM。然而，对于较大的模型变得更加困难，因为它们需要同时协调多个节点（多节点推理）。

有推理供应商称，可能需要几周甚至几个月的时间来重新设计他们的系统，以便能够处理来自 Meta 的 4050 亿个参数模型。在一日千里的大模型领域，这是很多时间。

同时，这些多节点配置也会提高运行模型的成本，**尽管模型是免费提供的，但运行成本有时已经高于闭源模型**。

Meta 当然意识到这个问题，与最大开源模型一同推出的，还有生态伙伴的合作方案，可以帮助任何开发者部署 Llama3.1 和各种工程化调优任务。但它仍然可能成为开发者使用 Llama3「超大杯」的一个挑战。

**04**

****扎克伯格：乐于看到人们****

****拿 Llama3.1 蒸馏小模型****

在 Meta 看来，Llama 开源「除了相对于闭源模型具有明显更好的性价比之外，405B 模型的开放性这一事实将使其成为**微调和蒸馏较小模型的最佳选择**」。

此前，OpenAI 发现字节跳动通过大量与 GPT-4 对话、蒸馏其高质量数据后，第一时间封号、禁止了这种做法。现在，Meta 却主动提出让大家蒸馏。更值得玩味的是，开源一个最强模型后的使用场景不是免费拿它去做 AI 应用，而是蒸馏自己的小模型。

ChatGPT 发布一年半以来，真实的市场需求下，很多企业并不会大规模使用大模型 API，而是基于开源模型做微调、从最强模型中蒸馏出企业自己可用的小模型，因为用户和企业都非常关心他们的私人数据，以及关键模型的「自主可控」。

其中，微调（Fine-tuning）指的是利用已有的预训练模型，在新的数据集上继续训练，对模型的参数进行少量的调整和优化，以使其适应特定的任务或领域。

蒸馏（Distillation）则是一种将大型复杂模型的知识压缩并传递给较小、较简单模型的技术。能在保持一定性能的前提下，降低模型的计算量和参数规模，提高模型的部署效率和运行速度。

![](https://mmbiz.qpic.cn/mmbiz_png/8cu01Kavc5ZFNw8tmZRRgSFFwSLNib972Dy24l0ArENeOTaBZ8sdEA27ibLiattJGdqTEZrQp7Dc5ZEz1YkvruNVA/640?wx_fmt=png&from=appmsg)扎克伯格接受 AI 博主采访时谈到对 Llama3「超大杯」的使用场景期待｜截图来源：X.com@rowancheung

扎克伯格在一档采访节目中重申了这一点，「我最感兴趣的是看到人们用它来蒸馏和微调自己的模型。我非常期待看到人们如何使用它，特别是现在我们制定了社区政策，允许人们将其用作教师模型来进行蒸馏和微调，基本上可以创建他们想要的任何其他模型」。

他认为，人们会希望直接在 4050 亿参数的模型上进行推理，因为据 Meta 估计，这样做的成本将比 GPT-4 低 50% 左右。人们可以将模型蒸馏到任何他们想要的大小，用于合成数据生成，作为教师模型使用。

**05**

****「Meta AI 将超过 ChatGPT」****

在大模型上，拥有最多 Super App 的 Meta，必须确保始终能够获得最好的 AI 技术。为了实现这一目标，开源是 Meta 的手段之一，策略则是建立一个强大的、开放的 AI 生态系统。

但这也带来一个质疑，Meta 没有像亚马逊、谷歌和微软那样拥有能够利用大模型推动业务的云计算，这就意味着 Meta 将其如此巨大的投入转化为收入的能力更加有限。

扎克伯格反而将这一质疑视为优势，他称，「出售大模型的访问权限不是我们的商业模式。这意味着公开发布 Llama 不会像闭源模型厂商那样削弱收入、可持续性或研究、投资能力。」

Meta 的 AI 商业化，**目前仍是改进其广告业务、使其新的 AI 助手（Meta AI）成为杀手级 AI 用例**。

Llama 3.1 现在为 Meta AI 提供支持，Meta AI 是 Meta 应用程序和雷朋智能眼镜中提供的 AI 助手，它被定位为像 ChatGPT 这样的通用聊天机器人，几乎可以在 Instagram、Facebook 和 WhatsApp 的任何地方找到。

![](https://mmbiz.qpic.cn/mmbiz_gif/8cu01Kavc5ZFNw8tmZRRgSFFwSLNib9724YcbibxoFcaJic5CB18mCWia5O73mE5Vibk5q3nHLvicHWfKjNtH87IMOvQ/640?wx_fmt=gif)

可选 Llama 3.1 支持 Meta AI｜图片来源：Meta 官网

从本周开始，Llama 3.1 将首先通过美国的 WhatsApp 和 Meta AI 网站访问，随后在接下来的几周内通过 Instagram 和 Facebook 访问。它正在更新以支持新语言，包括法语、德语、印地语、意大利语和西班牙语。

![](https://mmbiz.qpic.cn/mmbiz_gif/8cu01Kavc5ZFNw8tmZRRgSFFwSLNib972ZCzLNgOBZiaMyd0Ce6MHiaQn68HEJdBjgdzz8fDJptSpriaAA0Ih0njNQ/640?wx_fmt=gif)

伴随 Llama 3.1 的发布，Meta AI 添加了一项新的「想象我」功能，可以根据用户的特定肖像生成图像的功能。通过以这种方式而不是通过个人资料中的照片捕捉用户肖像，Meta 有望避免创建深度伪造（Deepfake）机器。

Meta AI 也将在未来几周内出现在 Quest 耳机中，取代其语音命令界面。就像它在 Meta Ray-Ban 眼镜中的实现一样，用户能够在 Quest 上使用 Meta AI 来识别和了解耳机直通模式下正在查看的内容，该模式通过显示屏显示现实世界。

扎克伯格在 Instagram 上发帖称，数亿人已经使用了 Meta AI。他预测，到今年年底，Meta AI 将超过 ChatGPT（ChatGPT 拥有超过 1 亿用户），成为使用最广泛被使用的 AI 助手。

对于未来的 AI 应用图景，扎克伯格称，Meta 的愿景是，应该有许多不同的 AI 及其 AI 服务，而不仅仅是单一的 AI，这一看法也影响了 Meta 的开源方法和产品路线图。

「我们的重点是让每个创作者和每个小企业都能创建自己的 AI Agent，使每个人都能在我们的平台上创建他们想要的 AI Agent，这些都是巨大的市场。世界上有数亿的小企业，一个企业可以通过几次点击就能创建一个 AI Agent 来进行客户支持、销售，并与所有客户沟通。未来每个企业都会像现在有电子邮件地址、网站和社交媒体一样，拥有一个他们的客户可以交流的 AI Agent。我们将生活在一个拥有数亿甚至数十亿不同 AI Agent 的世界里，可能最终 AI Agent 的数量会超过世界上的人口，人们将以各种不同的方式与它们互动。这是产品愿景的一部分，其中有很多商业机会，这是我们希望赚钱的地方。」

最后，他还剧透，Llama-4 已经在路上了，甚至不止 Llama4。「规划计算集群和数据轨迹不仅仅是针对 Llama-4，而是未来四五个版本的 Llama，这确实是件有趣的事情，因为这些都是需要长期投资的事情，建设数据中心、配套的电力、芯片架构和网络架构等」。

\*头图来源：视觉中国

本文为极客公园原创文章，转载请联系极客君微信 geekparkGO

**极客一问**

**你认为 Meta AI 在今年年底**

**能成为使用最广泛的 AI 助手吗****？**

![](https://mmbiz.qpic.cn/mmbiz_png/8cu01Kavc5YTxYGib55rt...