---
title: AI 2025 的硅谷答案：60 条关键洞察
url: https://mp.weixin.qq.com/s?__biz=MTMwNDMwODQ0MQ==&mid=2653072853&idx=1&sn=264541a441694d5b98b8c1fd4c2e741c&chksm=7e57d063492059755041e560b50e916fa65df25e081a78c7cf689a694849dbbbf5147f212ab2&scene=58&subscene=0#rd
source: 极客公园
date: 2025-01-27
fetch_date: 2025-10-06T20:08:48.194335
---

# AI 2025 的硅谷答案：60 条关键洞察

![cover_image](https://mmbiz.qpic.cn/mmbiz_jpg/8cu01Kavc5bmvQ29Z6ytObkMicZSURplCS6JCXt7qsDTSTmH1SXMIiaXxzG9lsOhsfq0oyGUrwDxvC2aWazR7J1g/0?wx_fmt=jpeg)

# AI 2025 的硅谷答案：60 条关键洞察

极客公园

![](https://mmbiz.qpic.cn/mmbiz_png/8cu01Kavc5bmvQ29Z6ytObkMicZSURplCVzIiby4dicANKLBiaia7UhbyyPnNCQMnySwlzWgz8iaQS30HtiaahsUIDrYQ/640?wx_fmt=png&from=appmsg)

重塑世界的力量不在硅谷，而在一代中国从业者的努力中。

来源：石头学习笔记(ID:notes2024)

原标题：AI 2025的硅谷答案：60条关键洞察

**编者按：**

2024 年末国内大模型公司的组团推新品，让人们看到了 AI 依旧火热。在硅谷，AI 从业者们在热烈讨论后，总结出了 2025 年，AI 行业的一些共识，以及不少「非共识」。例如，硅谷的投资人，认为 AI 公司是「新物种」，而 AI 应用，则是 2025 年的投资热点。

1.11-15 日，锦秋基金在硅谷举办了「Scale with AI」的活动，邀约了 A16Z、Pear VC 、Soma Capital、Leonis Capital 、Old Friendship Capital、OpenAI、xAI 、Anthropic、Google、Meta、Microsoft、Apple、Tesla、Nvidia、ScaleAI、Perplexity、Character.ai 、Midjourney、Augment、Replit、Codiuem、Limitless、Luma、Runway 这些公司的专家一起交流。

在交流后，我们也汇总了这些专家的观点，形成了这 60 个洞察。

***01***

**模型篇**

**1、****LLM 的 pre-training 阶段已经接近瓶颈**

**但 post-training 还有很多机会**

Pre-training 阶段，Scaling 是变慢的，离饱和还有一定时间。

放缓的原因：结构>算力>数据（Single-Model）。

但是在 Multi-model 上：数据=算力>结构。

对于 MultiModel 而言，需要在多个模态上选择组合，Pre-training 在现有架构下可以认为已经结束了，但是可以改新的架构。

现在在 Pre-training 投入少的原因更多是在于资源度有限，做 Post-training 的边际效益会更高。

**2、****Pre-training 和 RL 关系**

Pre-training 不太在乎数据质量。

Post-training 对数据质量要求较高，但是由于算力限制，到最后几个部分给高质量的数据，

Pre-training 是 imitation，只能做到模仿的事情。

RL 是创造，可以做到不同的事情

先有 Pre-training，才有 Post-training 中的 RL，模型得有基础能力，RL 才能有的放矢。

RL 不改变模型的智力，更多是思考的模式。比如，在 C.AI 用 RL 优化 Engagement 效果很好。

**3、大模型优化会影响产品的能力**

一般主要在 post training 部分，帮助做很多 Safety，比如解决 C.AI 在儿童自杀的问题上，会根据不同人群不同岁数的情况下，用不同的模型来服务。

其次是 Multiagent 的 framework。模型会思考为了解决这个问题要怎么做，然后分给不同 agent 去做，每个 agent 做完后，再服务 task，最后结果优化。

**4、一些非共识明年可能实现共识**

有没有必要所有都要上大模型，之前有很多很好的小模型，可能没有必要再要做一个模型。

现在的大模型，1 年后就变成小模型。

Model 架构可能变化。Sacling law 已经到了，未来要讨论的问题，知识模型解耦，可能速度会比较快。

**5、LLM 领域随着 Scaling law 到头，闭源和开源差距缩小。**

**6、****视频生成还在 GPT1 和 2 的时间点**

现在视频的水平接近 SD1.4 的版本，未来视频会有一个和商用性能差不多的开源版本。

当前的难点是数据集，图像是靠 LIAON 数据集，大家可以去清洗，视频上因为版权等问题没有那么大的公用数据集，每一家如何获取、处理、清洗数据会产生很多不同，导致模型能力不同，开源版本的难度也不同。

DiT 方案下一个比较难的点在于如何提升物理规律的遵循，而不只是统计概率。

视频生成的效率是卡点。目前要在高端显卡上跑挺久，是商业化的障碍，也是学术界在探讨的方向。

类似 LLM 虽然模型迭代速度在放缓，但应用没有放缓。从产品角度，只做文生视频不是一个好的方向，相关的偏剪辑、创意的产品，会层出不穷，短期内不会有瓶颈。

**7、面向不同场景选择不同的技术栈会是一个趋势**

Sora 刚出来大家都认为会收敛到 DiT，但实际上还有很多技术路径在做，例如 based on GAN 的路径，以及 AutoRegressive 的实时生成，比如最近很火项目 Oasis，还有把 CG 和 CV 结合去实现更好的一致性和控制，每一家都有不同的选择，未来面向不同场景选择不同的技术栈会是一个趋势。

**8、视频的 Scaling Law 远达不到 LLM 的级别**

视频的 scaling law，在一定范围内有，但远达不到 llm 的级别。现在最大级别的模型参数也就是 30b，30b 以内蓓证明是有效的；但 300b 这个量级，就没有成功案例。

现在技术方案是收敛的，做法没有大不同。不同最主要是数据上、包括数据配比。

会有 1-2 年才能达到 DiT 技术路线的饱和。DiT 路线很多可以优化的地方。更高效的模型架构，是非常重要的。以 LLM 为例，一开始大家都在往大了做，后面发现加 MOE 和优化数据分布后，可以不用那么大的模型去做。

需要投入更多研究，一味 scale up DiT 非常不高效。视频数据如果把 YouTube、TikTok 都算上，数量非常大，不可能都用于模型训练。

现阶段开源方面的工作还比较少，尤其是数据准备方面的开源工作，各家的清洗方式都有很大的差异性，而数据准备过程对最终效果有很大的影响，所以其中可优化的点还很多。

**9、提升视频生成的速度的方法**

最简单的就是生成低分辨率、低帧率的画面。最常用的是步数蒸馏，diffusion 推理的时候是有步数的，目前图像生成至少还需要 2 步，如果能蒸馏到 1 步推理，就会快很多。最近也有一个论文，做一步生成视频，虽然现在只是 poc，但值得关注。

**10、视频模型迭代的优先级**

其实清晰度、一致性、可控性等都没有达到其他饱和，还没有到提高一部分牺牲另一部分。是目前在 Pre-training 阶段同步提高的阶段。

**11、长视频生成提速的技术方案**

能看到 DiT 能力极限在哪，模型越大、数据越好，生成的清晰度更高、时间更长、成功率更高。

DiT 模型能 scale 到多大，是目前没有答案的。如果到一定尺寸出现瓶颈，可能会有新的模型架构出现。从算法角度，DiT 做出一个新的推理算法，来支持快速。比较难得是怎么在训练的时候把这些加上。

现在模型对物理规律的理解是统计意义上的，数据集看到过的现象能够一定程度上模拟，不是真的懂物理。学术界有一些探讨，例如通过一些物理规则到视频生成里去。

**12、视频模型和其他模态的融合**

会有两个方面的统一：一是多模态的统一，二是生成和理解的统一。对于前者，表征要先统一。对于后者，文本和语音都是可以统一的，VLM 和 diffusion 的统一目前认为效果是 1+1<2。这个工作会比较难，不一定是因为模型不够聪明，而是这两个任务本身就是矛盾的，如何达成精巧的平衡是一个复杂的问题。

最简单的想法是都 tokenize 之后放到 transformer 模型里，最后统一输入输出。但自己的个人经验是做单个特定的模态比把所有的融合在一起效果会更好。

工业实践上大家不会放在一起去做。MIT 最新的论文潜在说明如果把多模态都统一的话效果有可能会更好。

**13、视频模态的训练数据其实还有很多**

视频数据其实很多，怎么样高效的选择出高质量数据比较重要。

数量取决于对版权的理解。但算力同样是瓶颈，即便有那么多数据，也不一定有算力去做，尤其是高清的数据。有时候需要基于手头有的算力去反推需要的高质量数据集。

高质量数据一直都是缺的，但即便有数据，很大的问题是大家不知道什么样的图像描述是对的，图像描述要有哪些关键词。

**14、长视频生成的未来在于故事性**

现在的视频生成是素材的。未来是故事的，视频生成是带有目的的。长视频不是时间有多长，而是故事性。以任务的形式。

视频编辑的话，速度会高一些。因为现在一个卡点是速度太慢。现在都是分钟级（生成几秒）。这样即使有好算法，也不可用。（编辑不是指剪辑，而是 image 的编辑，比如换个人，动作，这样的技术是有的，问题就是速度慢，不可用。）

**15、视频生成的美学提升主要是靠 post training**

主要是靠 post training 阶段，比如海螺，大量用影视数据。真实度的话是基模能力

**16、视频理解两个难点是 Long context 和 Latency。**

**17、视觉模态可能不是更好的通向 AGI 的最好的模态**

文字的模态——也可以把文字改成图片，然后变成视频

文字是通往智能的捷径，视频和文字之间的效率差距是几百倍

**18、****语音模型上端到端是很大的进步**

不需要人为对数据做标注和判断，可以做到精细的情感理解和输出

**19、多模态模型还在很早期阶段**

多模态模型还在很早期阶段，给前 1 秒视频 predict 后面 5 秒已经很难了，后面加入 text 可能会更难。

理论上视频和文字一起训是最好的，但是整体做起来是很难的。

多模态目前不能提升智力，但是未来也许是可以的，压缩算法可以学习数据集的关系，只需要纯文字和纯图片的数据，出来之后就可以做视频和文字相互理解。

**20、多模态的技术路径还没有完全收敛**

Diffsion model 质量好，目前的模型结构还在不断再改；

Alter agreesive 逻辑好。

**21、不同模态的对齐，现在还没有形成共识**

video 是离散还是连续的 tokens 都没定下来。

现在高质量对齐的还没有很多。

目前也不知道是科学问题和工程问题。

**22、大模型生成数据然后训练小的模型是可行的，反过来比较难**

合成数据和真实数据的区别主要是质量问题。

也可以用各类数据拼凑用来合成，效果也很好。pretraining 阶段可用，因为对数据质量要求不高。

**23、****对 LLM 来说 pre training 的时代已经基本结束了**

现在大家都在谈 Post training，对数据质量要求高

**24、Post training 团队建设**

理论上团队规模：5 人足够（不一定全职）。

一人搭建 pipeline（infrastructure）。

一人管数据（数据效果）。

一人负责模型本身 SFT（科学家/读 Paper）。

一人负责产品对模型编排做判断，收集用户数据。

AI 时代产品和 UI，Post training 优势，AI 弥补产品和 UI 了解，开发丰富，不被 AI 带偏。

**25、数据 pipeline 构建**

数据循环：数据进入 pipeline，生成新数据回流。

高效迭代：数据标注结合 pipeline 和 AB testing，结构化数据仓库。

数据输入：高效标注和丰富用户反馈，构建护城河。

初始阶段：SFT（不断重新 Loop 到这个阶段）。

后续阶段：RL（分化出来比较重的 RLFH），打分指导 RL，DPO 方法易崩，SFT 简化版 RL。

***02***

**具身篇**

**1、****具身机器人尚未迎来类似 ChatGPT 的「关键时刻」**

一个核心原因在于，机器人需要在物理世界中完成任务，而不仅仅是通过虚拟语言生成文本。

机器人智能的突破需要解决「具身智能」（Embodied Intelligence）的核心问题，即如何在动态、复杂的物理环境中完成任务。

机器人的「关键时刻」需要满足以下几个条件：通用性：能够适应不同任务和环境。可靠性：在真实世界中具有较高的成功率。可扩展性：能通过数据和任务不断迭代和优化。

**2、****这一代机器学习解决的最核心的问题就是泛化**

泛化是 AI 系统从训练数据中学习规律，并应用到未见过的数据上的能力。

泛化有两种模式：

* 插值（Interpolation）：测试数据在训练数据分布范围内。
* 外推（Extrapolation）的难点在于训练数据是否能够很好地覆盖测试数据，以及测试数据的分布范围和成本。这里「cover」或「coverage」是关键概念，指的是训练数据能否有效涵盖测试数据的多样性。

**3、****视觉任务（如人脸识别、物体检测）多半属于插值问题**

机器视觉的工作主要是模仿生物的感知能力，理解和感知环境。

机器视觉模型在某些任务上（如猫狗识别）已经非常成熟，因为有大量相关数据支持。然而，对于更复杂或动态的任务，数据的多样性和覆盖范围仍是瓶颈。

视觉任务（如人脸识别、物体检测）多半属于插值问题，模型通过训练数据覆盖大多数测试场景。

但在外推问题上（如全新角度或光照条件），模型能力仍有限。

**4、这一代机器人泛化的难点：大部分情况属于 extrapolation 情形**

环境复杂性：家庭环境、工业环境的多样性和动态变化。

物理交互问题：例如门的重量、角度差异、磨损等物理特性。

人机交互的不确定性：人类行为的不可预测性对机器人提出了更高的要求。

**5、完全具备人类般泛化能力的机器人在当前乃至未来的一代人中可能无法实现**

机器人要在现实世界中应对复杂性和多样性，难度极高。现实环境中的动态变化（如家庭中的宠物、小孩、家具摆放等）使得机器人很难做到完全泛化。

人类本身并不是全能的个体，而是通过分工合作在社会中完成复杂任务。机器人同样不一定追求「人类级别」的泛化能力，而是更专注于某些特定任务，甚至实现「超越人类」的表现（如工业生产中的效率和精度）。

即使是看似简单的任务（如扫地或做饭），由于环境的复杂性和动态性，其泛化要求也非常高。比如扫地机器人需要应对千家万户不同的布局、障碍物、地面材质等，这些都增加了泛化的难度。

那么，机器人是否需要任务聚焦（Pick Your Task）。比如，机器人需要专注于特定任务，而不是追求全面的人类能力。

**6、斯坦福实验室的选择：聚焦家庭场景**

斯坦福的机器人实验室主要聚焦于家庭场景中的任务，尤其是与老龄化社会相关的家务机器人。例如，机器人可以帮助完成叠被子、拾取物品、开瓶盖等日常任务。

关注原因：美国、西欧以及中国等国家都面临严重的老龄化问题。老龄化带来的主要挑战包括：认知功能退化：阿尔茨海默症（老年痴呆）是一个广泛存在的问题，95 岁以上人群中约有一半患有此病。运动功能退化：例如帕金森症、ALS 等疾病导致老年人难以完成基本的日常操作。

**7、基于特定场景定义泛化条件**

明确机器人需要处理的环境和场景，例如家庭、餐厅或养老院。

明确场景后，可以更好地定义任务范围，并确保在这些场景中涵盖可能出现的物品状态变化和环境动态。

场景调试的重要性：机器人产品的调试不仅仅是解决技术问题，而是要涵盖所有可能出现的情况。例如在养老院中，机器人需要处理多种复杂情况（如老年人行动缓慢、物品摆放不固定等）。通过与领域专家合作（如养老院管理者、护理人员），可以更好地定义任务需求并收集相关数据。

现实世界中的环境不像工业流水线那样完全可控，但可以通过调试使其「已知」（known）。比如，定义家庭环境中常见的物体种类、摆放位置、动态变化等，在仿真和真实环境中覆盖关键。

**8、泛化与专用的矛盾**

通用模型与特定任务模型的冲突：用模型需要具备强大的泛化能力，能够适应多样化的任务和环境；但这通常需要大量的数据和计算资源。

特定任务模型更容易实现商业化，但其能力受限，难以扩展到其他领域。

未来的机器人智能需要在通用性和专用性之间找到平衡。例如，通过模块化设计，让通用模型成为基础，再通过特定任务的微调实现快速适配。

**9、具身多模态模型的潜力**

多模态数据的整合：多模态模型能够同时处理视觉、触觉、语言等多种输入，提升机器人对复杂场景的理解和决策能力。例如，在抓取任务中，视觉数据可以帮助机器人识别物体的位置和形状，而触觉数据可以提供额外的反馈，确保抓取的稳定性。

难点在于如何让多模态数据在模型中实现高效融合。如何通过多模态数据提升机器人在动态环境中的适应能力。

触觉数据的重要性：触觉数据可以为机器人提供额外的信息，帮助其在复杂环境中完成任务。例如，在抓取柔性物体时，触觉数据可以帮助机器人感知物体的形变和受力情况。

**10、机器人数据闭环难实现**

机器人领域目前缺乏类似 ImageNet 这样的标志性数据集，导致研究难以形成统一的评估标准。

数据采集的成本高昂，尤其是涉及真实世界的交互数据。例如，采集触觉、视觉、动力学等多模态数据需要复杂的硬件和环境支持。

仿真器被认为是解决数据闭环问题的一种重要工具，但仿真与真实世界之间的「模拟-真实差距（Sim-to-Real Gap）」仍然显著。

**11、Sim-to-Real Gap 的挑战**

仿真器在视觉渲染、物理建模（如摩擦力、材质特性）等方面与真实世界存在差距。器人在仿真环境中表现良好，但在真实环境中可能失败。这种差距限制了仿真数据的直接应用。

**12、真实数据的优势与挑战**

真实数据能够更准确地反映物理世界的复杂性，但其采集成本高昂。数据标注是一个瓶颈，尤其是涉及多模态数据（如触觉、视觉、动力学）的标注。

工业环境更规范，任务目标更明确，适合机器人技术的早期部署。例如，在太阳能发电厂的建设中，机器人可以完成打桩、装板、拧螺丝等重复性任务。工业机器人可以通过特定任务的数据收集，逐步提升模型能力，并形成数据的闭环。

**13、在机器人操作中，触觉和力觉数据可以提供关键的反馈信息**

在机器人操作中，触觉和力觉数据可以提供关键的反馈信息，尤其是在连续任务（如抓取和放置）中。

触觉数据的形式：触觉数据通常是时间序列数据，可以反映机器人与物体接触时的力学变化。

最新的研究工作是把触觉也加入到大模型里。

**14、仿真数据...