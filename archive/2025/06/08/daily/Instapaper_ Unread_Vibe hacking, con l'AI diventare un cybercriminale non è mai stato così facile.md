---
title: Vibe hacking, con l'AI diventare un cybercriminale non è mai stato così facile
url: https://www.wired.it/article/vibe-hacking-ai-cybecriminali-sicurezza-informatica/
source: Instapaper: Unread
date: 2025-06-08
fetch_date: 2025-10-06T22:53:42.627804
---

# Vibe hacking, con l'AI diventare un cybercriminale non è mai stato così facile

[Skip to main content](#main-content)

Apri il menu di navigazione

Menu

[![Wired Italia](/verso/static/wired-us/assets/logo-header.svg)](/)

Diventare un cybercriminale non è mai stato così facile, ed è colpa dell’AI

* [Scienza](/scienza/)
* [Economia](/economia/)
* [Cultura](/cultura/)
* [Gadget](/gadget/)
* [Security](/security/)
* [Diritti](/diritti/)
* [Idee](/idee/)
* [Video](/video/)
* [Podcast](/podcast-wired/)
* [Wired Consiglia](/wired-consiglia/)

More*Chevron*

[Cerca

Cerca](/search/)

* [Scienza](/scienza/)
* [Economia](/economia/)
* [Cultura](/cultura/)
* [Gadget](/gadget/)
* [Security](/security/)
* [Diritti](/diritti/)
* [Idee](/idee/)
* [Video](/video/)
* [Podcast](/podcast-wired/)
* [Wired Consiglia](/wired-consiglia/)

[Matthew Gault](/contributor/matthew-gault/)

[Security](/security/)

05.06.2025

# Diventare un cybercriminale non è mai stato così facile, ed è colpa dell’AI

La tecnologia ormai permette anche a persone senza competenze specifiche di sferrare attacchi informatici, e rischia di aumentare esponenzialmente la pericolosità degli attori più esperti

Play/Pause Button

Pause

ANIMATION: STEFANY UZOH

Stiamo per entrare nell'**era del *vibe hacking***. Nel prossimo futuro un **cybercriminale** potrebbe essere in grado di sferrare contemporaneamente 20 attacchi [*zero-day*](https://www.wired.it/article/cybersecurity-attacchi-zero-day/) contro diversi sistemi in giro per il mondo. I cosiddetti **malware polimorfici** potrebbero devastare il *codebase* di un programma **sfruttando un sistema di [intelligenza artificiale generativa](https://www.wired.it/article/claude-4-test-ricatto-intelligenza-artificiale-coscienza/) creato su misura** e capace di riscrivere se stesso via via che impara nuove cose e si adatta. Eserciti di *script kiddies* – come vengono definiti gli aggressori alle prime armi che si affidano a strumenti sviluppati da altri – potrebbero ricorrere a [grandi modelli linguistici](https://www.wired.it/article/chatgpt-llm-fine-internet/) (llm) costruiti ad hoc per lanciare un'ondata di codice dannoso **con un solo clic**.

Attualmente, ai primi posti di [diverse classifiche di HackerOne](https://hackerone.com/leaderboard?year=2025&quarter=2&owasp=a1&country=US&assetType=WEB_APP&tab=vdp), un servizio di *bug bounty* aziendale, c'è un'intelligenza artificiale, [**Xbow**](https://hackerone.com/xbow/hacktivity?type=user). Si tratta di un'AI pensata per chi si occupa di *penetration test* (gli attacchi simulati che servono a verificare la sicurezza di un sistema), capace di **"*trovare e sfruttare in autonomia le vulnerabilità nel 75% dei benchmark web"***, come si legge sul sito web dell'azienda.

Anche se non hanno ancora sprigionato tutto il loro potenziale, **i criminali informatici assistiti dall'intelligenza artificiale sono uno dei principali spauracchi del settore della cybersicurezza**. "*Lo paragono a un atterraggio d'emergenza di un aereo, dove qualcuno continua a dire di prepararsi a un impatto che però non è ancora arrivato* – spiega a *Wired US* Hayden Smith, cofondatore della società di sicurezza Hunted labs –*. Stiamo ancora aspettando di assistere a quell'evento*".

## L'ascesa del *vibe hacking*

**Grazie all'AI generativa [programmare è diventato più facile per tutti](https://www.wired.it/article/vibecoding-creare-software-senza-saper-programmare/)**. Gli llm migliorano di giorno in giorno, le intelligenze artificiali generano codice sempre più efficiente e aziende come Microsoft [dichiarano di usare agenti AI](https://techcrunch.com/2025/04/29/microsoft-ceo-says-up-to-30-of-the-companys-code-was-written-by-ai/) che contribuiscono a scrivere il loro *codebase*. Oggi chiunque può produrre uno script Python usando [ChatGPT](https://www.wired.it/article/accedi-con-chatgpt-login-altre-app/). Il cosiddetto *vibe coding* – ovvero usare un'AI per programmare quando non si ha la minima idea di come farlo – è diventato molto popolare. Ma ora c'è anche il ***vibe hacking***. "*Le persone senza conoscenze pregresse o approfondite potranno dire all'AI cosa vogliono creare*", spiega a *Wired* Katie Moussouris, fondatrice e amministratrice delegata di Luta security.

**Le interfacce per il *vibe hacking* esistono dal 2023**, quando un llm sviluppato appositamente per generare codice malevolo, [**WormGPT**](https://www.wired.it/article/wormgpt-come-funziona/), ha iniziato a diffondersi su gruppi Discord, server Telegram e forum del darknet. Una volta scoperto dagli esperti di sicurezza e dai media, il sistema è stato [disattivato dai suoi creatori](https://dfi.kaspersky.com/blog/ai-in-darknet).

WormGPT è scomparso, ma è stato sostituito da altri servizi che [si presentano](https://slashnext.com/blog/wormgpt-the-generative-ai-tool-cybercriminals-are-using-to-launch-business-email-compromise-attacks/) come llm [*blackhat*](https://www.wired.it/internet/regole/2018/12/15/hacker-white-hat-black-grey-hacktivist/) e si rivolgono ai cybercriminali, come [FraudGPT](https://hackernoon.com/what-is-fraudgpt). **Questi sistemi però avevano dei problemi**. Come osserva la società di sicurezza Abnormal AI, è possibile che molte di queste applicazioni fossero **semplicemente [versioni "craccate" di ChatGPT](https://abnormal.ai/blog/ghostgpt-uncensored-ai-chatbot)**, con del codice aggiuntivo per dare l'impressione che si trattasse di prodotti a sé stanti.

Oggi i malintenzionati preferiscono **andare direttamente alla fonte**. Effettuare il cosiddetto *jailbreaking* di ChatGPT, [Gemini](https://www.wired.it/article/android-16-novita-gemini/) e [Claude](https://www.wired.it/article/claude-4-test-ricatto-intelligenza-artificiale-coscienza/) non è difficile: nonostante la maggior parte degli llm incorpora protezioni che impediscono di generare codice dannoso, online ci sono intere comunità [dedicate alle strategie per bypassare queste difese](https://www.reddit.com/r/ChatGPTJailbreak/). E c'è chi come Anthropic [offre](https://www.anthropic.com/news/model-safety-bug-bounty) addirittura una ricompensa a chi riesce a identificarne di nuove.

"*Per noi è molto importante **sviluppare i nostri modelli in modo sicuro*** – spiega a *Wired* un portavoce di OpenAI –*. Adottiamo precauzioni per ridurre il rischio di un uso dannoso e miglioriamo continuamente le misure di salvaguardia per rendere i nostri modelli più robusti contro exploit come il jailbreak. Potete leggere la nostra ricerca e il nostro approccio ai jailbreak nella [scheda di sistema GPT-4.5](https://cdn.openai.com/gpt-4-5-system-card-2272025.pdf), o in [quella di OpenAI o3 e o4-mini](https://cdn.openai.com/pdf/2221c875-02dc-4789-800b-e7758f3722c1/o3-and-o4-mini-system-card.pdf)*". Google non ha risposto alla richiesta di commento di *Wired*.

Nel 2023 i ricercatori di sicurezza di Trend Micro sono riusciti a **indurre ChatGPT a generare codice dannoso chiedendo all'AI di mettersi nei panni di un ricercatore di sicurezza**. "*È possibile utilizzarlo per creare malware* – afferma Moussouris –. *Il modo più semplice per aggirare le protezioni inserite dai creatori dei modelli di intelligenza artificiale è scrivere all'AI che state partecipando a un ‘capture the flag’* [un [esercizio di sicurezza informatica](https://it.wikipedia.org/wiki/Capture_the_flag_%28sicurezza_informatica%29), simile a una gara, ndr] *e il sistema genererà volentieri codice maligno per voi*".

## L'AI nelle mani dei cybercriminali esperti

Gli attori con poca esperienza come gli *script kiddies* sono un problema annoso nel mondo della sicurezza informatica e oggi l'AI rischia di amplificarne il profilo. Come dichiara a *Wired* l'analista Benedict, che lavora per la società di gestione del rischio e cybersicurezza Rane, la tecnologia **"*abbassa la barriera di accesso al crimine informatico*"**.

La **vera minaccia potrebbe però essere rappresentata dai gruppi di aggressori già affermati**, che utilizzeranno l'intelligenza artificiale per migliorare ulteriormente le loro già temibili capacità, "*es...