---
title: 上下文感知的聚合页广告优化实践
url: https://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&mid=2651779932&idx=1&sn=0da4221704c0cff8b8dabe083db9fb00&chksm=bd122a118a65a307614f01eeb5eb83ff3b89dca179e6732078c801d7c639ad948a878fb47e4b&scene=58&subscene=0#rd
source: 美团技术团队
date: 2025-02-28
fetch_date: 2025-10-06T20:39:00.653534
---

# 上下文感知的聚合页广告优化实践

![cover_image](https://mmbiz.qpic.cn/sz_mmbiz_jpg/hEx03cFgUsXXxJMIuaJ8lFBdRb1Y7E1LPcPq4qCvKicn7KkOREGGY1YNDuPPnianyHz0deQuchrL4y9m6xOajLDw/0?wx_fmt=jpeg)

# 上下文感知的聚合页广告优化实践

原创

商业增值技术部

美团技术团队

![](https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVsE4Nicq51WdnKEhcaEEYDS4h6jA6JOZ3fnENgFV1B6ianDTqaQ3nzNOjvHUB79ocldrVj4YlkAW6g/640?wx_fmt=png)

**总第610****篇 |****2025年第007篇**

聚合页广告将商家和优惠信息以多种形式聚合展示给用户，是美团广告业务中一个重要的业务场景。本文从最能影响用户决策的“发券”和“排序”两个方向出发，介绍了上下文感知建模在广告场景的落地方案，证明了聚合页上下文感知的收益空间。希望能对从事相关研究的同学带来一些启发或帮助。

* 1 聚合页广告
* 2 实践一：上下文增强的全链路Uplift建模方法（ECUP）

+ 2.1 背景
+ 2.2 链路偏差分析
+ 2.3 方法
+ 2.4 效果

* 3 实践二：利用邻域列表的重排方法（NLGR）

+ 3.1 背景
+ 3.2 方法
+ 3.3 效果

* 4 总结与展望

## **1 聚合页广告**

聚合页广告是美团一个重要的业务场景，我们将商家和多种优惠以聚合的形式展示给用户。如下图1所示，聚合页通过多种发券模式吸引用户下单。上下文信息建模是聚合页实现精准个性化匹配的重要途径，我们从上下文信息中选择了最能影响用户决策心智的“发券”和“排序”两个方向进行了深入探索：

* 对于发券，聚合页下券预算有限，因此如何在“有限的券预算下最大化发券效率”是算法核心要解决的问题。为此，我们建设了一套基于Uplift的智能配券策略，并针对Uplift建模中遇到的链路偏差等技术问题，提出了一种上下文增强的全链路Uplift建模方法（ECUP，收录于WWW2024｜[Entire Chain Uplift Modeling with Context-Enhanced Learning for Intelligent Marketing](https://arxiv.org/pdf/2402.03379)）。
* 对于排序，在预估中除了要考虑广告本身的信息还需要考虑相邻展示的其它广告对其的影响，而精排中的Point Wise预估无法建模此类上下文信息。同时，福利1和常规自选券两个模块各自优化较难实现整个列表的效果最优。在该问题上，我们搭建了跨模块重排链路，提出了利用邻域列表的重排方法（NLGR，收录于WWW2025｜[NLGR: Utilizing Neighbor Lists for Generative Rerank in Personalized Recommendation Systems](https://arxiv.org/pdf/2502.06097)）进行List Wise预估实现对上下文信息和页面级最优的建模。

下文实践一和实践二将具体介绍我们在这两项工作中面临的技术挑战和创新性解法。

![图1 站外聚合页广告形态](https://mmbiz.qpic.cn/sz_mmbiz_png/hEx03cFgUsXXxJMIuaJ8lFBdRb1Y7E1LNhDsyLzMzyqOILfCwzkx4nxKIick4gqjEviafEVrsEa3ehOgZkVTOAAw/640?wx_fmt=png&from=appmsg)

图1 聚合页广告形态

## **2 实践一：上下文增强的全链路Uplift建模方法（ECUP）**

### | 2.1 背景

在电子商务平台的精准营销实践中，营销干预策略（Treatment）的设计与效果评估是提升用户参与度和商业价值的关键环节。常见的干预手段包括定向广告、限时折扣和智能优惠券发放等，这些策略通过影响用户行为实现商业目标。作为因果推断在营销领域的核心应用，Uplift模型通过预测个体处理效应（Individual Treatment Effect, ITE）来解决策略效果异质性问题——即量化特定干预（如某类优惠券）对目标用户的增量转化效果，从而构建"零资源浪费"的精准营销系统。

与传统监督学习不同，Uplift建模本质上是反事实推理问题：需要同时估计用户在干预组（T）和对照组（C）的潜在结果。现有主流方法采用多响应建模框架，典型代表包括：构建单一特征映射函数估计各干预下的条件平均结果的S-learner，以及在此基础上的几个变体，例如X-learner、T-learner等，各种深度学习方法以其卓越的特征提取能力作为Uplift框架的基本模型。然而这些方法仍然存在两个问题：

* **链路偏差问题**：现有的方法在全链路建模方面存在不足。在电子商务场景中，用户行为通常遵循一个顺序模式：曝光 → 点击 → 转化。制定营销策略时，通常需要整合整个链路中多个用户行为的Uplift效果。然而，目前的研究大多仅关注链内单个任务的Uplift得分，忽略了不同任务之间的相互影响。这种片面性会导致结果产生偏差，因为不同的处理方式对每个任务的影响程度是不同的。如下图所示，在某种特定Treatment下，用户可能会表现出点击率（CTR）提高，但转化率（CVR）下降的情况，然而最终的点击到转化率（CTCVR）仍然是正向的。如果仅依赖于在点击集合上训练的CVR模型，可能会得出完全相反的结论，从而对后续的营销决策产生严重的误导。此外，后链路任务中的数据稀疏性问题会进一步损害模型的泛化能力。

![图2 链路偏差](https://mmbiz.qpic.cn/sz_mmbiz_png/hEx03cFgUsXXxJMIuaJ8lFBdRb1Y7E1Lico8wuLd7fmcIo2bVSaibwPy05mR0BpEtbanXEzpeMR8VTUAteicJq3tQ/640?wx_fmt=png&from=appmsg)

图2 链路偏差

* **Treatment不适应问题**：Treatment对用户反应有着显著的影响，个体在不同的Treatment下会表现出不同的行为。例如，我们观察到在外卖平台上，人群1在获得高价值优惠券时更倾向于下单，但这一趋势在人群2中并不普遍。然而，以往的方法通常学习每个特征的静态表示，忽略了在不同Treatment下对相同特征的适应性。这种适应性的缺失使得在多种Treatment方法中捕捉个体行为差异变得极具挑战性。尽管一些研究者尝试利用注意力机制来模拟Treatment特征与非Treatment特征之间的相互作用，但他们主要通过标准化的注意力权重来调整这两种特征类型。这种基于向量级的交互方法缺乏灵活性，难以在不同Treatment下准确捕捉每个特征的动态变化及其意义。

为了解决上述问题，我们提出了一种上下文增强的全链路Uplift建模方法（ECUP），旨在提升Uplift建模的准确性。

### | 2.2 链路偏差分析

为研究营销链路中每个阶段的Uplift关系，本文分析了公共数据集CRITEO-UPLIFT和美团的MT-LIFT数据集。我们随机分割数据，并绘制了若干随机选定段的Uplift图（如下图所示），定义和为第k段treatmeant组和control组转化的样本数，和分别表示总样本，则实际的uplift值为：

据此，我们计算了CTCVR（曝光空间）和CVR（点击空间）的实际Uplift值。如下图所示，CTCVR和CVR在不同段的变化趋势并不完全一致，这表明不能仅通过点击集上的CVR提升来推断全链路的实际Uplift。这种现象的主要原因是用户在不同阶段的行为关注点不同，导致Treatment对行为的影响在链路各阶段存在差异。因此，我们提出在全链路空间中构建Uplift模型，并引入任务先验信息，以精准捕捉Treatment对不同任务的影响，从而解决链路偏差问题。

![图3 随机分段的CVR和CTCVR的实际Uplift值](https://mmbiz.qpic.cn/sz_mmbiz_png/hEx03cFgUsXXxJMIuaJ8lFBdRb1Y7E1LZ4gCq50t6dwdzkIFexmS5d1plFCxL2IAFMVTYIKd1obbKBicJSf9SVw/640?wx_fmt=png&from=appmsg)

图3 随机分段的CVR和CTCVR的实际Uplift值

### | 2.3 方法

ECUP模型整体结构如下图所示，主要由两部分组成：1. 全链路增强网络（ECENet），使用用户的序列模式来估计整个链路空间中每个任务的结果，并使用任务增强网络（TAENet）注入任务先验信息以实现上下文表征，捕捉每个任务上的不同uplift，以避免链路偏差的负面影响。2. Treatment增强网络（TENet），旨在引导初始特征的Treatment感知细化，并实现不同Treatment下embedding表征的bit级别自适应调整，以解决Treatment不适应问题。

![图4 ECUP架构](https://mmbiz.qpic.cn/sz_mmbiz_png/hEx03cFgUsXXxJMIuaJ8lFBdRb1Y7E1LPhfcof0ACfpXibqic0lsck6op4tVwWxkWRskTNJiacAIyq1QlkIXceLLQ/640?wx_fmt=png&from=appmsg)

图4 ECUP架构

**全链路增强网络（ECENet）**

在特定Treatment中，个体对不同任务的响应存在差异。此部分的目标是在捕获任务感知特征表达，传统方法通过多个塔来学习多任务目标的方法表达能力有限，无法捕捉Treatment对不同任务的不同影响。为此，本文提出任务增强网络（TAENet, Task-Enhanced Network），以深度融合任务先验与Treatment增强表示（TENet的输出），实现上下文增强的参数学习。TAENet通过个性化选择和调整DNN参数，平衡不同上下文中特征的稀疏性。

具体而言，TAENet使用门控机制结合任务先验信息，自适应地获取DNN每层的参数。任务信息作为先验输入，通过多头注意力网络建模为Treatment增强的Embedding表征。为保证初始特征和Treatment Embedding的稳定性，训练时仅更新任务表征。在此过程中，任务信息作为注意力网络中的Query，而Treatment增强表征作为Key和Value，用于捕获上下文增强的先验信息。

接着，将先验信息注入到MLP结构的门控机制中，门控机制的输出结果和每个DNN塔的每层（最后一层除外）结果点乘，实现自适应参数选择。

我们共享除了各任务最后一层的所有参数。我们在模型训练中使用pCTR和pCTCVR来计算整个样本空间的损失，损失函数为交叉熵：

参数共享机制显著降低了数据稀疏性对后续任务的影响，而TAEGate模块则确保模型在共享参数的同时，能够精准捕捉Treatment对每个任务的差异化影响。

**Treatment增强网络（TENet）**

![图5 TENet架构](https://mmbiz.qpic.cn/sz_mmbiz_png/hEx03cFgUsXXxJMIuaJ8lFBdRb1Y7E1LhSak6fLeHYtPicc6Gv8PmBAwT093PeUskHvwia5KjDR0XibABYUgmlAyw/640?wx_fmt=png&from=appmsg)

图5 TENet架构

如图所示，TENet由两部分组成：Treatment感知单元（TAU）和Treatment增强门控（TEGate），TENet使用bit级的加权来实现细粒度的Treatment增强特征细化。Treatment感知单元（TAU）由两部分组成，自注意力机制和MLP搭建的Treatment信息提取器。自注意力机制输入为，捕获所有特征对之间的交叉表征关系，以获得个体在其自然状态下的精细化表示，得到输出结果：

Treatment信息提取器处理用户在不同Treatment下的适应性，对于输入的Treatment表征，通过MLP得到bit级输出，TAU最终输出为点乘结果：

进一步使用两个独立的TAU获得Treatment感知表征和bit级权重：

初始特征反映了实例的自然状态，忽略这些特征会导致有价值信息的丢失。因此，在获得Treatment感知表征和bit级权重后，我们通过门控机制在bit级别融合这两部分，从而生成最终的Treatment增强表征：

为了显示地表达Treatment，在此基础上拼接原始Treatment表征：

与传统基于注意力权重的特征交互方法相比，TENet具有以下两大优势：1.平衡初始特征与Treatment感知表征，以适应不同Treatment场景下的变化；2.采用bit-level特征交互，以更细粒度的方式实现Treatment增强。

### | 2.4 效果

为了全面评估所提出的方法，我们收集了聚合页在为期两个月的优惠券营销场景中的数据，并按一定比例随机抽取形成了最终的数据集。该数据集包含多种Treatment方法和全链路标签信息，通过随机对照实验收集，以确保Treatment组和对照组之间的潜在分布一致，从而消除混杂因子对Uplift建模的影响。数据集包含近550万个实例、99个特征、Treatment信息以及两个标签：点击和转化。

![表1 数据集的统计](https://mmbiz.qpic.cn/sz_mmbiz_png/hEx03cFgUsXXxJMIuaJ8lFBdRb1Y7E1LPjnTuZ5ThCXd4QkFRiaZSicIzf7cVVwaeo64icXNcrNrNpSWjibEHksRvA/640?wx_fmt=png&from=appmsg)

表1 数据集的统计

我们在公开数据集和美团数据集上分别做了实验，用AUUC和QINI衡量uplift模型效果。

![表2 整体性能对比](https://mmbiz.qpic.cn/sz_mmbiz_png/hEx03cFgUsXXxJMIuaJ8lFBdRb1Y7E1LXibskFnz3r4WVaRbkveaDBa6KSr7aFLaFvaa019m9W2FjUTdRibVsdaQ/640?wx_fmt=png&from=appmsg)

表2 整体性能对比

此外，通过消融实验证明各板块重要性。

![表3 消融实验](https://mmbiz.qpic.cn/sz_mmbiz_png/hEx03cFgUsXXxJMIuaJ8lFBdRb1Y7E1LdrwKvmsDShrd1WAwAWO8OxAAGTqC5vRCzCcULlxiazDVGh09OLeuX9A/640?wx_fmt=png&from=appmsg)

最后，我们在业务上进行了A/B实验，取得了较为显著的收益。

![表4 在线AB实验](https://mmbiz.qpic.cn/sz_mmbiz_png/hEx03cFgUsXXxJMIuaJ8lFBdRb1Y7E1LkhD9QXBnaqUNXWawYoZiaWnicRpRO4zwsJ4jNlbZibemIXcicLDlIefQJA/640?wx_fmt=png&from=appmsg)

表4 在线AB实验

## **3 实践二：利用邻域列表的重排方法（NLGR）**

### | 3.1 背景

重排通过重新排列初始排名列表，在现代多阶段推荐系统中发挥着至关重要的作用。由于组合搜索空间这样的固有挑战，当前的一些研究采用了评估器-生成器范式，生成器生成可行的序列，评估器评估并选择最佳的序列。然而这些方法仍然存在两个问题：

1. 由于生成器和评估器之间的目标不一致问题，生成器倾向于拟合曝光分布的局部最优解而非排列空间最优。评估器被训练拟合项目的List-Wise评分，而生成器被期望能将排序列表转换成最优列表。评估器和生成器之间的目的差距导致它们之间的知识传输很难，并且在极端情况下导致生成器仅能拟合曝光分布。
2. 由于忽略了后续项目的信息一一生成目标项目的生成策略难以达到最优。我们的业务特点是包含一键领券和常规自选券两个模块。这两个模块共享候选和预算，极易发生跷跷板效应。并且两个模块有着迥异的用户行为模式，其中一键领券的CTR极高，自选券则接近一般的列表推荐。两个模块的差别加剧了联合建模的难度（但我们认为联合建模的收益空间更大），也加大了主流的自回归生成模型的生成难度。

为了解决这些问题，我们提出了一个利用邻域列表的重排方法（NLGR），旨在提高生成器在组合空间中的生成效果。

### | 3.2 方法

NLGR遵循评估器-生成器范式，并改进了生成器的训练方式和生成方式。具体来说，我们使用组合空间中的邻居列表去增强生成器的训练过程，使生成器能感知相对分数并找到优化方向。进一步，我们提出了一种新颖的基于采样的非自回归生成方法，它可以使生成器灵活地从当前列表跳转至任意邻居列表。模型结构如下图所示，左侧是评估器，中间是生成器，右侧是细节结构。

![图6 NLGR架构](https://mmbiz.qpic.cn/sz_mmbiz_png/hEx03cFgUsXXxJMIuaJ8lFBdRb1Y7E1LcGkJA0A1nlIjEFtWrXF6Nr1528wJFO4tPM0Uo1TMIeDI0XdRqTQhTw/640?wx_fmt=png&from=appmsg)

图6 NLGR架构

**评估器**

生成器评估任意一个候选列表。输入主要包括候选列表和用户历史session-level的行为（其他的特征没有列出来），然后经过特征提取后送入预估层（MLP）进行预估，预估层的输入包括四部分：j-th项目的emb、候选列表的emb、从用户历史行为提取出来的用户emb和j-th的位置emb。

**生成器**

生成器将任意一个候选列表生成为排列空间中的最优列表。生成过程分为2步，先从候选列表中决定要替换的位置（PDU），再从剩余候选项目中挑选出一个项目放入候选列表中（CDU）。

* 位置决策单元（PDU）输出每个位置应该被替换的概率。输入和评估器预估层的输入一样，也包括四部分：j-th项目的emb、候选列表的emb、从用户历史行为提取出来的用户emb 和 j-th的位置emb。

在训练时为了保证梯度传播，用gumbel-softmax采样，得到要替换的位置：

* 候选召回单元（CDU）输出每个候选被召回的概率。输入仍然和评估器预估层的输入一样，也包括四部分：k-th候选的emb、mask掉j-th个位置后的候选列表的emb、从用户历史行为提取出来的用户emb和j-th的位置emb。

同样的，在训练时为了保证梯度传播，用gumbel-softmax采样，得到要插入的候选：

*...