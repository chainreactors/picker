---
title: 专家观点 | 法律监管+技术人工审核：提升AI内容输出可控性
url: https://mp.weixin.qq.com/s?__biz=MzA5MzE5MDAzOA==&mid=2664230517&idx=6&sn=e0cdeffeaef945346749b2786816d35d&chksm=8b59ec8cbc2e659ad1f79be0768fefcdce5f72358f6b283ffcdefaa017380c1e422413a7e745&scene=58&subscene=0#rd
source: 中国信息安全
date: 2024-11-26
fetch_date: 2025-10-06T19:20:50.866826
---

# 专家观点 | 法律监管+技术人工审核：提升AI内容输出可控性

![cover_image](https://mmbiz.qpic.cn/sz_mmbiz_jpg/1brjUjbpg5y9ZeHyLibvbLrKia0KIsWd2icj7riaI9Pv69eP0Rn03AelUttfEaYX3oD3Y3mjukcbfWRRqZwQMcAgUw/0?wx_fmt=jpeg)

# 专家观点 | 法律监管+技术人工审核：提升AI内容输出可控性

范永开

中国信息安全

![](https://mmbiz.qpic.cn/sz_mmbiz_gif/1brjUjbpg5y9ZeHyLibvbLrKia0KIsWd2icMf0FMibDmookrUWUYEwdegRJtTG8QvVb8icVFb8UtsickypZnNj9eu3LQ/640?wx_fmt=gif&from=appmsg)

![](https://mmbiz.qpic.cn/sz_mmbiz_png/1brjUjbpg5y9ZeHyLibvbLrKia0KIsWd2icpI82zr4n8Yiao1Gq2SJJMs6TIWZgzj857zL9HIZdlEAQYNibssQicJhtg/640?wx_fmt=png&from=appmsg)

![](https://mmbiz.qpic.cn/sz_mmbiz_gif/1brjUjbpg5y9ZeHyLibvbLrKia0KIsWd2icMf0FMibDmookrUWUYEwdegRJtTG8QvVb8icVFb8UtsickypZnNj9eu3LQ/640?wx_fmt=gif&from=appmsg)

**扫码订阅《中国信息安全》**

邮发代号 2-786

征订热线：010-82341063

文 | 中国传媒大学媒体融合与传播国家重点实验室、计算机与网络空间安全学院教授 范永开

AI聊天角色在回答中可能出现色情擦边、暴力对话等情况，主要与“数据来源的混杂性、商业模式的诱导性、监管机制的滞后性”这三大关键因素有关。

**从数据来源维度剖析，**AI剧情聊天软件背后的大语言模型，其训练数据主要来源于对话式小说或提取自小说的文本内容。然而，网络小说数量巨大且质量参差不齐，其中不乏包含色情、擦边以及暴力的内容。如果这些内容没有被有效过滤，模型在输出时就容易出现问题。

**从商业模式视角审视，**部分AI剧情聊天软件为吸引用户，即便在青少年模式中，仍存在允许“擦边对话”的现象。例如通过设定极富想象力的剧情和风格迥异的人物角色来打动用户，这种商业模式不仅推动了用户黏性增长，但也容易诱导用户实施不适当行为。

**从监管角度考量，**目前针对AI生成内容的监管机制尚不完善，许多平台也可能缺乏有效的内容过滤技术措施，导致一些含有色情、暴力等不当内容的对话能够顺利输出给用户。

虽然相关企业通常会实施内容修订流程等操作，甚至建立用户反馈机制，根据用户的年龄段、身份特征等因素，限制未成年用户访问包含敏感或禁止内容在内的数据源，但实际上，受制于商业利益、技术不足等因素，全面的内容审查与控制难以实现。

为了应对这种情况，可进一步优化大语言模型的筛选机制，以降低甚至杜绝涉黄、暴力或侮辱性内容的输出。比如对于隐蔽或隐喻等内容，可通过开发长记忆链技术来更好地捕捉语言中的长距离依赖关系，提高模型对不当内容的识别和过滤能力；或者利用词嵌入、序列模型与注意力机制等技术，来增强模型对文本内容的深度剖析能力。通过强化技术手段，模型能够更精确地理解文本中的上下文关系，从而更准确地判别文本是否包含不当内容。

但需明确的是，技术不能解决所有的问题，还需要法律及人工介入等多种方式协同解决内容输出控制的问题。从法律角度，对用于训练大语言模型的数据进行严格的筛选与分类，确保数据源合法且内容健康，坚决剔除包含色情、暴力等不当元素的文本数据。对于现有的模型，可运用数据遗忘等技术手段，消除已有模型的不当内容输出或在干净数据上的重新训练，生成优质大模型。此外，引入人工审核机制是一种必要的手段，对自动化系统标记为敏感或禁止的内容进行人工复核，推动开放研究、社区合作、线索举报等多种措施，进一步优化大语言模型的筛选机制，最大限度减少或消除不良内容的输出。

不良内容的输出，会对受众的思想行为产生较为严重的负面影响。更深远的影响在于，通过AI大模型的使用去改变受众的认知，影响认知安全。

维护认知安全，需要从多个层面入手加强防护措施：首先，在技术研发阶段就应充分考虑伦理道德因素，并建立健全配套的监管机制；其次，加大对网络空间中各类信息的审核力度，及时发现并清除有害内容；再次，提升公众的信息素养教育水平，增强其辨别真伪信息的能力；最后，构建一个开放透明且富有责任感的AI生态系统，鼓励各方积极参与、共同维护良好的数字环境。

（来源：法治日报）

**分享网络安全知识 强化网络安全意识**

**欢迎关注《中国信息安全》杂志官方抖音号**

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/1brjUjbpg5y9ZeHyLibvbLrKia0KIsWd2icRyIGb4E4aDUD97pWzO7afictJBxGI09pTOQrWA7PpwcsLBHm9CazFcg/640?wx_fmt=jpeg&from=appmsg)

**《中国信息安全》杂志倾力推荐**

**“企业成长计划”**

**点击下图 了解详情**

[![](https://mmbiz.qpic.cn/sz_mmbiz_png/1brjUjbpg5y9ZeHyLibvbLrKia0KIsWd2ic33Y9eHiblWViaic0uAaicU6vq2YEE69K9BC0ViaVIrUictW2V9J5ebcNSzaA/640?wx_fmt=png&from=appmsg)](http://mp.weixin.qq.com/s?__biz=MzA5MzE5MDAzOA==&mid=2664162643&idx=1&sn=fcc4f3a6047a0c2f4e4cc0181243ee18&chksm=8b5ee7aabc296ebc7c8c9b145f16e6a5cf8316143db3edce69f2a312214d50a00f65d775198d&scene=21#wechat_redirect)

预览时标签不可点

阅读原文

![]()

微信扫一扫
关注该公众号

继续滑动看下一个

轻触阅读原文

![](http://mmbiz.qpic.cn/sz_mmbiz_png/1brjUjbpg5xcg6pmGiagMsJTqnHObJGHSj6TEe6InbwlHLIxFVhPohvicQibAcuia5wDEoRISsAkUyYPUB06cU9mibw/0?wx_fmt=png)

中国信息安全

向上滑动看下一个

知道了

![]()
微信扫一扫
使用小程序

取消
允许

取消
允许

取消
允许

×
分析

![跳转二维码]()

![作者头像](http://mmbiz.qpic.cn/sz_mmbiz_png/1brjUjbpg5xcg6pmGiagMsJTqnHObJGHSj6TEe6InbwlHLIxFVhPohvicQibAcuia5wDEoRISsAkUyYPUB06cU9mibw/0?wx_fmt=png)

微信扫一扫可打开此内容，
使用完整服务

：
，
，
，
，
，
，
，
，
，
，
，
，
。

视频
小程序
赞
，轻点两下取消赞
在看
，轻点两下取消在看
分享
留言
收藏
听过