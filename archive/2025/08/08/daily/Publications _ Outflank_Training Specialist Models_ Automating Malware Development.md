---
title: Training Specialist Models: Automating Malware Development
url: https://www.outflank.nl/blog/2025/08/07/training-specialist-models/
source: Publications | Outflank
date: 2025-08-08
fetch_date: 2025-10-07T00:17:01.910755
---

# Training Specialist Models: Automating Malware Development

[Skip to the content](#content)

[logo](https://www.outflank.nl)
Experts in red teaming

* [Red Team Tools](/products/)
  + [Outflank Security Tooling](/products/outflank-security-tooling/)
    - [Outflank C2](https://www.outflank.nl/products/outflank-security-tooling/outflank-c2/)
    - [Payload Generator](/products/outflank-security-tooling/pe-payload-generator/)
    - [Tooling](/products/outflank-security-tooling/ost-tool-list/)
    - [Tradecraft](/products/outflank-security-tooling/tradecraft/)
    - [Demo Videos](/videos/ost-demo-videos/)
  + [Cobalt Strike](/products/cobalt-strike/)
  + [Red Team Bundle](/datasheets/red-team-bundle/)
  + [Advanced Red Team Bundle](/datasheets/advanced-red-team-bundle/)
* [Red Team Services](/services/red-teaming/)
* Blog & Resources
  + [Outflank Blog](/blog/)
  + [Community](/products/outflank-security-tooling/ost-community/)
  + [Datasheets](/datasheets/)
  + [OST Demo Videos](/videos/ost-demo-videos/)
  + [OST Releases](/services/outflank-security-tooling/releases/)
  + [Upcoming Events](https://www.outflank.nl/upcoming-events/)
* [About Us](/company/)
  + [Our Company](/company/)
  + [OST Testimonials](/company/outflank-security-tooling-testimonials/)
  + [Contact Us](/contact/)
* [Schedule a Demo](/demo-request/)
* [REQUEST QUOTEREQUEST QUOTE](/request-a-quote/)

# Publications

# [Training Specialist Models: Automating Malware Development](https://www.outflank.nl/blog/2025/08/07/training-specialist-models/ "Training Specialist Models: Automating Malware Development")

[Kyle Avery](https://www.outflank.nl/blog/author/kyleavery/ "Posts by Kyle Avery")
 |
August 7, 2025

*This post complements the [presentation](https://www.blackhat.com/us-25/briefings/schedule/#training-specialist-models-automating-malware-development-46238) I gave at Black Hat USA 2025.*

**Can a small, self-hosted LLM outperform state-of-the-art models at evasive malware development?**
In this technical deep dive, we explore how reinforcement learning with verifiable rewards (RLVR) enables training compact specialist models that rival large generalists in domain-specific tasks.

In the first half of this post, we’ll break down the LLM training process and recent opportunities created by RLVR. The second half details our training methodology for *Dante-7B*, a 7 billion parameter model that generates functional, evasive Cobalt Strike shellcode loaders capable of bypassing Microsoft Defender for Endpoint (MDE). We’ve released Dante-7B on Hugging Face, complete with a demo app so anyone can experiment with the model.

## Introduction

The best models from OpenAI, Google, DeepSeek, etc. are useful for many tasks, but they’re far from ideal. Most importantly to me, many closed-source models censor topics like red teaming and malware development. Sure, there are jailbreaks and simple tricks to convince a model to help, but I don’t want to worry about this every time I use a chatbot, and I certainly can’t rely on them for fully automated tooling. Some models are more lenient in this regard, but still raise concerns about privacy and cost, especially for larger commercial use cases.

There are numerous reasons one might prefer to self-host a model, especially a more affordable, small model. That said, small open-source models just don’t cut it for technical work today. In my experience, at least, they lack the knowledge or reasoning capabilities needed for offensive security research and development. That’s not to say we haven’t found use cases for LLMs of all sizes, but there is a missing category of self-hosted yet technically adept models.

Intuitively, it makes sense to me that bigger models outperform smaller models. What exactly makes them better, though? Consider the Meta Llama 3.1 LLMs. There are three different models in the series, each with a different number of “parameters”. Parameters, collectively, give a model its capacity to encode knowledge and perform complex tasks. A greater number of parameters increases this capacity.

Another critical factor is the composition of a model’s training dataset. Developers train most LLMs on many topics to create a jack-of-all-trades. All three Llama 3.1 models can create recipes, write Python code, or tell you about history. I propose a simple conceptual framework that, although not technically robust, provides a sufficient overview for this post.

![](https://www.outflank.nl/wp-content/uploads/2025/08/image-2-1024x579.png)

In this framework, both the parameter count and the number of skills represented in training datasets impact the model’s final strength. The open-source models I’ve seen all train models of various sizes on a similar number of skills, which explains the difference in quality between big and small models.

I hypothesized that reducing the number of skills expected of a small model could result in a high-quality specialist LLM that is small enough to run locally. My understanding of LLM size suggests that it may be possible to surpass large generalist models in some tasks, provided the smaller model is sufficiently large to learn the requirements of those tasks.

## Intro to Training LLMs

To understand the opportunities for specialized models, I first investigated current LLM training methodologies. Researchers generally train LLMs in two phases: pre-training and post-training. There is also a fuzzy concept called “mid-training” that I won’t discuss here, but may show up in newer papers.

### LLM Pre-Training

Pre-training focuses on compressing information into the model. This process uses a technique called “[next-token prediction](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)“. AI labs collect [as much data as possible](https://www.wired.com/story/new-documents-unredacted-meta-copyright-ai-lawsuit/) from sources like books, Wikipedia, GitHub, and Reddit. The training process shows the model part of a sentence or paragraph and expects it to complete the original data. Initially, it struggles with this task, but each time the model fails, its parameters are updated, making it more likely to output the correct response next time.

The result of pre-training is a “base model”. Base models are not typically available in applications like ChatGPT, as they do not behave like a chatbot. Instead, base models act more like a sophisticated auto-completion model. Many open-source LLM releases will include a base model alongside the chatbot variant. You can try out [Llama 3.1 405B (base) on Hyperbolic](https://app.hyperbolic.ai/models/llama31-405b-base-bf-16) to get an idea of how these models function. Here are some examples I generated:

![](https://www.outflank.nl/wp-content/uploads/2025/08/image-17-1024x256.png)

I started by asking the model a simple math question. While the model did answer my question, responding “Isn’t it 4?” is a bit odd. Then, it continues asking more questions and answering them endlessly until it hits the context limit or I manually stop sampling the model. Similarly, the model does a good job of completing “The sky is”, but then it starts talking about a professor I never mentioned. If ChatGPT behaved like this, it would be much less popular than it is today. Base models are still quite useful; they’re just more challenging to prompt compared to a post-trained LLM.

### LLM Post-Training

The next phase of training aims to develop a base model into a helpful assistant. LLM post-training varies significantly, but it generally has (at least) two steps:

***Supervised Fine-Tuning***

[Supervised fine-tuning (SFT)](https://arxiv.org/pdf/2203.02155) teaches a model to follow instructions and format answers. The model is still trained using next-token prediction in this step, but the dataset is quite different. In the following example, I asked the same math question from before, but this time my prompt is surrounded by so-called “special tokens” meant to indicate the beginning and end of each “turn” in a convers...