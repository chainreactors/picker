---
title: 人工智能幻觉及其对网络安全运营的风险
url: https://www.anquanke.com/post/id/307558
source: 安全客-有思想的安全新媒体
date: 2025-05-21
fetch_date: 2025-10-06T22:25:34.393035
---

# 人工智能幻觉及其对网络安全运营的风险

首页

阅读

* [安全资讯](https://www.anquanke.com/news)
* [安全知识](https://www.anquanke.com/knowledge)
* [安全工具](https://www.anquanke.com/tool)

活动

社区

学院

安全导航

内容精选

* [专栏](/column/index.html)
* [精选专题](https://www.anquanke.com/subject-list)
* [安全KER季刊](https://www.anquanke.com/discovery)
* [360网络安全周报](https://www.anquanke.com/week-list)

# 人工智能幻觉及其对网络安全运营的风险

阅读量**47693**

发布时间 : 2025-05-20 14:43:05

**x**

##### 译文声明

本文是翻译文章，文章原作者 Mirko Zorz，文章来源：helpnetsecurity

原文地址：<https://www.helpnetsecurity.com/2025/05/19/ai-hallucinations-risk-cybersecurity-operations/>

译文仅供参考，具体内容表达以及含义原文为准。

人工智能系统有时会产生不正确或误导的输出,这种现象被称为幻觉。这些错误的范围可以从轻微的不准确性到可能误导决策过程的虚假陈述。

![AI hallucinations]( "AI幻觉")

###

### 现实世界的影响

如果公司的人工智能代理利用过时或不准确的数据,人工智能幻觉可能会制造不存在的漏洞或误解威胁情报,导致不必要的警报或被忽视的风险。这些错误可能会从真正的威胁中转移资源,产生新的漏洞并浪费已经受到限制的SecOps团队资源,“Tanium人工智能副总裁Harman Kaur告诉Help Net Security。

一个新出现的担忧是包幻觉现象[package hallucinations](https://www.helpnetsecurity.com/2025/04/14/package-hallucination-slopsquatting-malicious-code/),其中AI模型表明不存在的软件包。这个问题已被确定为供应链攻击的潜在载体,称为“斜蹲”。攻击者可以通过创建带有建议名称的恶意软件包来利用这些幻觉,导致开发人员无意中将有害代码整合到他们的系统中。

如果在没有彻底验证和手动验证的情况下使用,AI生成的代码可能会带来巨大的风险和复杂性。初级开发人员特别容易受到错误代码或配置文件的风险,因为他们缺乏足够的技能来正确审核代码。至于高级开发人员,他们可能会及时发现错误,但是,越来越多的人过度依赖GenAI,盲目信任其输出,“ImmuniWeb首席执行官Ilia Kolochenko说。

另一个担忧是人工智能有可能产生虚假的威胁情报。这些报告如果从表面上看,可能会转移人们对实际威胁的注意力,使实际漏洞得不到解决。当人工智能输出没有与可靠来源进行交叉验证时,风险会加剧。

### 缓解AI幻觉的策略

“人工智能幻觉是概率模型的预期副产品,”Qwiet AI首席技术官Chetan Conikee解释说,他强调重点不应该完全消除它们,而应该放在最小化操作中断上。“CISO的首要任务应该是通过设计、监控和政策来限制运营影响。

从有意的架构开始。Conikee建议围绕AI系统实施结构化的信任框架,这种方法包括实用的中间件,通过确定性检查和特定领域的过滤器来审查输入和输出。这一步确保模型不会孤立地运行,而是在反映企业需求和安全状态的明确范围内运行。

可追溯性是另一个基石。“所有AI生成的响应都必须携带元数据,包括源上下文,模型版本,提示结构和时间戳,”Conikee指出。此类元数据可以在发生不准确时进行更快的审计和根本原因分析,这是将AI输出集成到业务运营或面向客户的工具中时的关键保护措施。

对于部署LLM的企业,Conikee建议除非必要,否则避开开放式发电。相反,组织应该依靠基于精心策划的内部知识库的RAG。“这确保了模型从经过验证的信息中吸取信息,并保持与内部标准的一致性,”Conikee解释说。

测试严谨也很重要。“幻觉检测工具应该在测试阶段纳入,”Conikee说。在模型触及实时环境之前,安全领导者应该为可接受的风险和故障模式定义阈值。“目标不是完美的准确性,而是对生成式AI使用地点和方式的可衡量和可审计的控制。

通过将信任、可追溯性和控制嵌入到人工智能部署中,CISO可以平衡创新与问责制,在不减缓进度的情况下控制幻觉:

1.实现检索增强生成(RAG):RAG将AI的生成功能与从验证数据源中提取信息的检索系统相结合。这种方法将人工智能输出置于事实数据中,从而降低了幻觉的可能性。

**2.**使用自动化推理工具:像亚马逊这样的公司正在开发使用数学证明来验证人工智能输出的工具,确保它们符合既定的规则和政策。这些工具可以提供一层保证,特别是在关键应用中。
WSJ

**3.**定期更新训练数据:确保人工智能系统在当前和准确的数据上进行训练,可以最大限度地减少幻觉的风险。过时或有偏差的数据可能导致AI产生不正确的输出。

**4.**纳入人类监督:人类专家应该审查人工智能生成的输出,特别是在高风险场景中。这种疏忽可能会捕捉到人工智能可能遗漏的错误,并提供人工智能缺乏的背景。

**5.**教育用户对AI限制:训练用户了解AI的能力和局限性可以培养对AI输出的健康怀疑。鼓励用户验证AI生成的信息可以防止不准确的传播。

GuidePoint Security 的突击安全高级副总裁 Victor Wieczorek 解释说:“我们需要实用的护栏。这意味着将人工智能响应直接与记录在案的策略联系起来,标记或记录高风险输出,并确保人类在到达客户之前对其进行任何重大审查。把模型当作一个新的实习生来对待:它可以帮助起草想法和处理常规问题,但不应该对任何敏感的事情进行最终调用。

本文翻译自helpnetsecurity [原文链接](https://www.helpnetsecurity.com/2025/05/19/ai-hallucinations-risk-cybersecurity-operations/)。如若转载请注明出处。

商务合作，文章发布请联系 anquanke@360.cn

本文由**安全客**原创发布

转载，请参考[转载声明](https://www.anquanke.com/note/repost)，注明出处： [https://www.anquanke.com/post/id/307558](/post/id/307558)

安全KER - 有思想的安全新媒体

本文转载自: [helpnetsecurity](https://www.helpnetsecurity.com/2025/05/19/ai-hallucinations-risk-cybersecurity-operations/)

如若转载,请注明出处： <https://www.helpnetsecurity.com/2025/05/19/ai-hallucinations-risk-cybersecurity-operations/>

安全KER - 有思想的安全新媒体

分享到：![微信](https://p0.ssl.qhimg.com/sdm/28_28_100/t01e29062a5dcd13c10.png)

* [安全热点](/tag/%E5%AE%89%E5%85%A8%E7%83%AD%E7%82%B9)
* [每日安全热点](/tag/%E6%AF%8F%E6%97%A5%E5%AE%89%E5%85%A8%E7%83%AD%E7%82%B9)

**+1**3赞

收藏

![](https://p2.ssl.qhimg.com/t010857340ce46bb672.jpg)安全客

分享到：![微信](https://p0.ssl.qhimg.com/sdm/28_28_100/t01e29062a5dcd13c10.png)

## 发表评论

您还未登录，请先登录。

[登录](/login/index.html)

![](https://p3.ssl.qhimg.com/t014757b72460d855bf.png)

[![](https://p2.ssl.qhimg.com/t010857340ce46bb672.jpg)](/member.html?memberId=170061)

[安全客](/member.html?memberId=170061)

这个人太懒了，签名都懒得写一个

* 文章
* **2096**

* 粉丝
* **6**

### TA的文章

* ##### [英国通过数据访问和使用监管法案](/post/id/308719)

  2025-06-20 17:11:10
* ##### [CISA警告：严重缺陷（CVE-2025-5310）暴露加油站设备](/post/id/308715)

  2025-06-20 17:09:03
* ##### [大多数公司高估了AI治理，因为隐私风险激增](/post/id/308708)

  2025-06-20 17:05:02
* ##### [研究人员发现了有史以来最大的数据泄露事件，暴露了160亿个登录凭证](/post/id/308704)

  2025-06-20 17:02:15
* ##### [CVE-2025-6018和CVE-2025-6019漏洞利用：链接本地特权升级缺陷让攻击者获得大多数Linux发行版的根访问权限](/post/id/308701)

  2025-06-20 16:59:36

### 相关文章

* ##### [ISC.AI 2025创新独角兽沙盒大赛开启，政产学研共举创新势力](/post/id/308810)

  2025-06-23 17:47:17
* ##### [与“AI”同行，和ISC.AI共启新篇](/post/id/308800)

  2025-06-23 17:37:20
* ##### [手慢无！ISC.AI 2025 早鸟票100张限时6折，赠泡泡玛特乐园门票](/post/id/308736)

  2025-06-20 18:22:35
* ##### [航空公司向国土安全局出售乘客数据](/post/id/308408)

  2025-06-12 15:39:51
* ##### [美国政府疫苗网站被人工智能生成的内容污损](/post/id/308404)

  2025-06-12 15:36:04
* ##### [美国CISA警告 SinoTrack GPS 跟踪器存在远程控制漏洞](/post/id/308398)

  2025-06-12 15:15:38
* ##### [安全行动： 国际刑警组织在打击网络犯罪的重大行动中摧毁了 20,000 多个恶意 IP](/post/id/308395)

  2025-06-12 14:43:06

### 热门推荐

文章目录

![](https://p0.qhimg.com/t11098f6bcd5614af4bf21ef9b5.png)

安全KER

* [关于我们](/about)
* [联系我们](/note/contact)
* [用户协议](/note/protocol)
* [隐私协议](/note/privacy)

商务合作

* [合作内容](/note/business)
* [联系方式](/note/contact)
* [友情链接](/link)

内容需知

* [投稿须知](https://www.anquanke.com/contribute/tips)
* [转载须知](/note/repost)
* 官网QQ群：568681302

合作单位

* [![安全KER](https://p0.ssl.qhimg.com/t01592a959354157bc0.png)](http://www.cert.org.cn/)
* [![安全KER](https://p0.ssl.qhimg.com/t014f76fcea94035e47.png)](http://www.cnnvd.org.cn/)

Copyright © 北京奇虎科技有限公司 三六零数字安全科技集团有限公司 安全KER All Rights Reserved [京ICP备08010314号-66](https://beian.miit.gov.cn/)[![](https://icon.cnzz.com/img/pic.gif)](https://www.cnzz.com/stat/website.php?web_id=1271278035 "站长统计")

微信二维码

**X**![安全KER](https://p0.ssl.qhimg.com/t0151209205b47f2270.jpg)