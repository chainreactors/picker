---
title: Algocrazia, sicurezza e protezione dati: tra black box e sorveglianza di massa, avanza il bisogno dell’Algoretica
url: https://www.ictsecuritymagazine.com/articoli/algocrazia-sicurezza-e-protezione-dati-tra-black-box-e-sorveglianza-di-massa-avanza-il-bisogno-dellalgoretica/
source: ICT Security Magazine
date: 2023-05-06
fetch_date: 2025-10-04T11:42:48.242770
---

# Algocrazia, sicurezza e protezione dati: tra black box e sorveglianza di massa, avanza il bisogno dell’Algoretica

[Salta al contenuto](#main)

[![ICT Security Magazine](https://www.ictsecuritymagazine.com/wp-content/uploads/2016/01/logo-ict-security.jpg)](https://www.ictsecuritymagazine.com/)

* [Home](https://www.ictsecuritymagazine.com/)
* [Articoli](https://www.ictsecuritymagazine.com/argomenti/articoli/)
* RubricheEspandi
  + [Cyber Security](https://www.ictsecuritymagazine.com/argomenti/cyber-security/)
  + [Cyber Crime](https://www.ictsecuritymagazine.com/argomenti/cyber-crime/)
  + [Cyber Risk](https://www.ictsecuritymagazine.com/argomenti/cyber-risk/)
  + [Cyber Law](https://www.ictsecuritymagazine.com/argomenti/cyber-law/)
  + [Digital Forensic](https://www.ictsecuritymagazine.com/argomenti/digital-forensic/)
  + [Digital ID Security](https://www.ictsecuritymagazine.com/argomenti/digital-id-security/)
  + [Business Continuity](https://www.ictsecuritymagazine.com/argomenti/business-continuity/)
  + [Digital Transformation](https://www.ictsecuritymagazine.com/argomenti/digital-transformation/)
  + [Cyber Warfare](https://www.ictsecuritymagazine.com/argomenti/cyber-warfare/)
  + [Ethical Hacking](https://www.ictsecuritymagazine.com/argomenti/ethical-hacking/)
  + [GDPR e Privacy](https://www.ictsecuritymagazine.com/argomenti/gdpr-e-privacy/)
  + [IoT Security](https://www.ictsecuritymagazine.com/argomenti/iot-security/)
  + [Industrial Cyber Security](https://www.ictsecuritymagazine.com/argomenti/industrial-cyber-security/)
  + [Blockchain e Criptovalute](https://www.ictsecuritymagazine.com/argomenti/blockchain-e-criptovalute/)
  + [Intelligenza Artificiale](https://www.ictsecuritymagazine.com/argomenti/intelligenza-artificiale/)
  + [Geopolitica e Cyberspazio](https://www.ictsecuritymagazine.com/argomenti/geopolitica-cyberspazio/)
  + [Interviste](https://www.ictsecuritymagazine.com/argomenti/interviste/)
* [Notizie](https://www.ictsecuritymagazine.com/argomenti/notizie/)
* [Pubblicazioni](https://www.ictsecuritymagazine.com/pubblicazioni/)
* [Cybersecurity Video](https://www.ictsecuritymagazine.com/argomenti/cybersecurity-video/)
* [Eventi](https://www.ictsecuritymagazine.com/eventi/)
* [Newsletter](https://www.ictsecuritymagazine.com/newsletter/)

[Linkedin](https://www.linkedin.com/company/ict-security-magazine/) [YouTube](https://www.youtube.com/%40ictsecuritymagazine1403) [RSS](https://www.ictsecuritymagazine.com/feed/)

[![ICT Security Magazine](https://www.ictsecuritymagazine.com/wp-content/uploads/2016/01/logo-ict-security.jpg)](https://www.ictsecuritymagazine.com/)

Attiva/disattiva menu

[![Forum ICT Security 2025](https://www.ictsecuritymagazine.com/wp-content/uploads/banner-header-2025.jpg)](https://www.ictsecuritymagazine.com/eventi/forumictsecurity2025)

![](https://www.ictsecuritymagazine.com/wp-content/uploads/Algocrazia.jpg)

# Algocrazia, sicurezza e protezione dati: tra black box e sorveglianza di massa, avanza il bisogno dell’Algoretica

A cura di:[Redazione](#molongui-disabled-link)  Ore 5 Maggio 2023

La parola “algocrazia”, nota già dalla fine degli anni Novanta, negli ultimi tempi ha iniziato a farsi strada nel dibattito tecno-politico globale animando numerosi interrogativi rispetto ai profili etici, giuridici e di cybersecurity che la accompagnano.

Il termine è stato coniato dal sociologo della globalizzazione Aneesh Aneesh, che nel paper del 2002 [*”Technologically Coded Authority”*](https://www.researchgate.net/publication/254843955_Technologically_Coded_Authority_The_Post-Industrial_Decline_in_Bureaucratic_Hierarchies) lo utilizza nel senso di *«rules of the code (or of an algorithm) as an organizational model capable of replacing the rules of an office»*, anticipando il profilarsi di un sistema di *governance* in cui l’autorità è sempre più incorporata nella tecnologia.

Oggi indica *“il crescente utilizzo degli algoritmi informatici e dell’intelligenza artificiale al fine di esercitare il controllo su qualsiasi aspetto della vita quotidiana”* (dal [vocabolario Treccani](https://www.treccani.it/vocabolario/algocrazia_%28Neologismi%29/)). Nell’arco di vent’anni il concetto di algocrazia ha quindi assunto – tanto sul piano semantico quanto nella percezione sociale – una connotazione via via più negativa, finendo per coincidere con l’ipotesi distopica di un abuso della tecnologia in danno dei diritti e della sicurezza delle persone.

### Algoritmi ovunque: sorveglianza di massa, giustizia predittiva e risvolti etici delle tecnologie AI

L’idea di una crescente “onnipresenza” degli algoritmi non è certamente una cospirazione infondata. Di fatto la capacità di elaborare in tempi rapidissimi enormi quantità di dati ha reso questo strumento la base fondante di innumerevoli tecnologie di uso quotidiano, prime fra tutte le piattaforme social su cui ogni giorno miliardi di persone lavorano, si informano e comunicano tra di loro.

Dalla sanità alla giustizia, dall’istruzione al controllo delle frontiere, sono poi moltissimi gli ambiti in cui governi, istituzioni pubbliche e organizzazioni sovranazionali delegano importanti scelte a una o più *“rules of the code”.*

Ciò permette di ottimizzare flussi di lavoro e servizi di ogni tipo, anche grazie alle sempre più sofisticate capacità di “autoapprendimento” che caratterizzano i sistemi AI/ML. Ma è evidente come questa tendenza legittimi molte riserve: specie rispetto al concreto rischio che tali sistemi, [riproducendo i](https://www.ictsecuritymagazine.com/articoli/il-problema-del-bias-nei-dataset-e-della-xai-explainable-artificial-intelligence/) [*bias*](https://www.ictsecuritymagazine.com/articoli/il-problema-del-bias-nei-dataset-e-della-xai-explainable-artificial-intelligence/) che potrebbero caratterizzare i dati con cui sono alimentati, finiscano per replicare discriminazioni di varia natura ovvero per facilitare pratiche di [sorveglianza digitale](https://economics.mit.edu/sites/default/files/inline-files/Exporting-the-surveillance-state-via-trade-in-AI_FINAL-1.pdf) su oppositori politici o giornalisti (non solo negli Stati autoritari, come dimostra il recente caso dello [*spyware*](https://euractiv.it/section/capitali/news/esclusivo-il-procuratore-dellue-indaga-sul-predatorgate-greco/?utm_source=substack&utm_medium=email) [Predator in Grecia](https://euractiv.it/section/capitali/news/esclusivo-il-procuratore-dellue-indaga-sul-predatorgate-greco/?utm_source=substack&utm_medium=email) su cui attualmente indaga la Procura Europea).

Per comprendere quanto tali sistemi possano avere impatti rilevanti anche su persone comuni basti pensare alle misure adottate durante la pandemia da Covid-19, quando molti Paesi hanno scelto di [affidarsi agli algoritmi per mappare i contagi](https://unric.org/it/covid-19-mappatura-globale-di-applicazioni-di-ai-per-la-lotta-al-virus/) e contenere la diffusione del virus, suscitando diverse critiche in termini di privacy individuale; o alla gestione dei flussi migratori diretti verso gli Stati occidentali, dove l’automazione dei controlli e la raccolta massiccia di dati biometrici [minacciano i diritti fondamentali](https://protecht.hermescenter.org/) delle persone coinvolte.

Ulteriori e delicati ambiti applicativi dei sistemi AI sono l’[*E-justice*](https://www.researchgate.net/publication/257244648_Risk_factors_in_e-justice_information_systems) e il cosiddetto [*predictive policing*](https://www.technologyreview.com/2020/07/17/1005396/predictive-policing-algorithms-racist-dismantled-machine-learning-bias-criminal-justice/), nei quali i dubbi circa l’eticità di scelte sganciate da ogni valutazione umana – per sua natura incline a cogliere sfumature impossibili per una macchina – si sommano alle ormai solide ricerche che espongono la scarsa affidabilità e il potenziale gravemente discriminatorio di [d](https://www.ictsecuritymagazine.com/articoli/decisioni-automatizzate-su-algoritmi-il-quadro-giuridico/)[ecisioni automatizzate](https://www.ictsecuritymagazine.com/articoli/decisioni-automatizzate-su-algoritmi-il-quadro-giuridico/) ammesse in settori così...