---
title: Guerre di Rete - AI, effetto Bruxelles
url: https://guerredirete.substack.com/p/guerre-di-rete-ai-effetto-bruxelles
source: Over Security - Cybersecurity news aggregator
date: 2023-06-26
fetch_date: 2025-10-04T11:47:42.474354
---

# Guerre di Rete - AI, effetto Bruxelles

[![Guerre di Rete](https://substackcdn.com/image/fetch/$s_!JKxa!,w_80,h_80,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9c3cbe9e-1c39-4535-99d8-940270e03588_1010x1010.png)](/)

# [Guerre di Rete](/)

IscrivitiAccedi

# Guerre di Rete - AI, effetto Bruxelles

### Poi la piattaforma per la raccolta firme referendum. Anonymous Sudan.

[![Avatar di Carola Frediani](https://substackcdn.com/image/fetch/$s_!tOoV!,w_36,h_36,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9403bb00-3959-45dc-afb5-ac7994d708b8_750x741.jpeg)](https://substack.com/%40guerredirete)

[Carola Frediani](https://substack.com/%40guerredirete)

giu 25, 2023

13

1

Condividi

[![](https://substackcdn.com/image/fetch/$s_!3I4M!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e3d2633-ffd2-4890-8a2e-306bc3fda8de_2225x1654.jpeg)](https://substackcdn.com/image/fetch/%24s_%213I4M%21%2Cf_auto%2Cq_auto%3Agood%2Cfl_progressive%3Asteep/https%3A//substack-post-media.s3.amazonaws.com/public/images/3e3d2633-ffd2-4890-8a2e-306bc3fda8de_2225x1654.jpeg)

Immagine da [Wikimedia](https://commons.wikimedia.org/wiki/File%3A00_Bruxelles_-_Mont_des_Arts.jpg)

**Guerre di Rete - una newsletter di notizie cyber
a cura di Carola Frediani
N.164 - 25 giugno 2023

In questo numero:
- AI Act, effetto Bruxelles
- AI: Biden accelera, ascolta i rischi, cerca finanziatori
- Se infermiera e AI non sono d’accordo
- Microsoft e Anonymous Sudan
- Che fine ha fatto la piattaforma per il Referendum digitale?
- Altro**

**AI ACT
L’effetto Bruxelles sui modelli di AI**
Ora che l’AI Act, il regolamento Ue sull’intelligenza artificiale, è più vicino ed ha assunto una prima forma (la bozza approvata il 14 giugno dall’Europarlamento che però dovrà ancora passare per il campo minato delle negoziazioni tra Parlamento, Consiglio e Commissione note come triloghi, come [spiegato nella scorsa newslette](https://guerredirete.substack.com/p/guerre-di-rete-ai-act-leuroparlamento)r), come si pongono i modelli di base (foundation models, come quelli che hanno dato vita a ChatGPT) rispetto agli obblighi e requisiti previsti dalla prossima legislazione europea?
Se lo chiedono dei **ricercatori dell’americana Stanford University e la [risposta](https://crfm.stanford.edu/2023/06/15/eu-ai-act.html) è (**in sintesi) la seguente.
 **Quanto sono conformi all’AI Act gli attuali modelli di base?**
I principali fornitori di modelli di base attualmente **non sono conformi** ai requisiti preliminari previsti. Raramente forniscono informazioni adeguate sui dati usati, sulle risorse di calcolo così come sulle caratteristiche chiave dei modelli. In particolare non danno informazioni sull'uso di dati di addestramento protetti da copyright, sull'hardware utilizzato, sulle emissioni prodotte durante l'addestramento, e su come valutano e testano i modelli. E tuttavia questi stessi fornitori di modelli di base possono in realtà adeguarsi all'AI Act, e anzi **il fatto di doverlo fare migliorerà la trasparenza in tutto l'ecosistema.**

Scrivono i ricercatori: “I modelli di base sono al centro del discorso globale sull'AI: il paradigma tecnologico emergente ha un impatto concreto e crescente sull'economia, sulla politica e sulla società. Parallelamente, la legge europea sull'AI è la più importante iniziativa normativa sull'intelligenza artificiale al mondo. La legge non solo imporrà requisiti per l'AI nell'UE (...) **ma creerà anche un precedente per la regolamentazione della stessa in tutto il mondo (l'effetto Bruxelles)**. I politici di tutto il pianeta si stanno già ispirando a questa legge e le aziende multinazionali potrebbero modificare le loro pratiche globali per mantenere un unico processo di sviluppo”.

In conclusione, aggiungono, “la conformità dei fornitori di modelli di base ai requisiti in materia di copyright, energia, rischio e valutazione [previsti dall’AI Act, ndr] è particolarmente scarsa e indica le aree in cui possono migliorare. La nostra valutazione mostra **un netto divario tra i modelli aperti e chiusi:** riteniamo in ogni caso che tutti i fornitori possano migliorare la loro condotta”.

A corredo di questa valutazione c’è **una bella tabella in cui sono valutati tutti i maggiori fornitori di modelli di base** rispetto ai parametri previsti dall’AI Act: trasparenza sull’origine dei dati, la loro governance, la presenza di materiali soggetti a copyright, il consumo di energia e risorse di calcolo, rischi e mitigazioni, valutazioni, testing ecc. Chi ne esce meglio è BLOOM, il modello linguistico di grandi dimensioni e open source lanciato dalla startup Hugging Face insieme ad altri ricercatori. Seguito da un altro modello open, GPT-NeoX. Ma potete guardare voi stessi [la scheda qua.](https://crfm.stanford.edu/2023/06/15/eu-ai-act.html)

**AI Act, partono i triloghi**
Tornando dunque all’AI Act, il primo trilogo sotto la presidenza spagnola si terrà il 18 luglio, [nota](https://twitter.com/BertuzLuca/status/1670691216663429120) il giornalista Luca Bertuzzi. Proprio in quell'occasione verrà discussa la proposta del correlatore della legge, Brando Benifei, di anticipare l'entrata in vigore per i modelli di base e di AI generativa (ne avevo scritto nella [scorsa newsletter](https://guerredirete.substack.com/p/guerre-di-rete-ai-act-leuroparlamento)). Seguiranno le date del 26 settembre e del 26 ottobre. “L'idea è di chiudere Art30-55 sulle procedure amministrative, gli standard, la valutazione della conformità, la trasparenza e l'innovazione prima della pausa estiva”, [twitta](https://twitter.com/BertuzLuca/status/1671764769869647872) ancora Bertuzzi.

**Le pressioni di OpenAI (e altre aziende tech)**
E già da questo primo appuntamento a luglio ci potremo aspettare un notevole dispiegamento di lobbying, anche considerato quello che è già avvenuto. Nei giorni scorsi la rivista TIME ha infatti [pubblicato](https://time.com/6288245/openai-eu-lobbying-ai-act/) un documento di OpenAI, un white paper che fu mandato nel settembre 2022 dalla società americana a rappresentanti della Commissione e del Consiglio europei. Il documento, insieme a una serie di incontri a porte chiuse - scrive TIME - mostrerebbe lo sforzo dei fornitori di ChatGPT e DALL-E per non far classificare le AI general purpose, che possono eseguire una serie disparata di funzioni (come GPT-3, stando alla definizione contenuta in [documenti europei](https://www.europarl.europa.eu/RegData/etudes/ATAG/2023/745708/EPRS_ATA%282023%29745708_EN.pdf)) come sistemi ad alto rischio, soggetti a maggiori restrizioni. E, sempre secondo TIME, il fatto che nell’attuale formulazione dell’AI Act i modelli di base stiano in una categoria a parte sembrerebbe un successo degli sforzi lobbistici (anche se l’AI Act impone comunque una serie di obblighi di trasparenza e di altri requisiti ai fornitori di modelli di base, requisiti che come spiegato nella parte iniziale dello studio di Stanford costringeranno le aziende a prendere una serie di misure).

**USA
Biden accelera, ascolta i rischi, cerca finanziatori**
Mentre l’Europa, nel bene o nel male, viene guardata con attenzione dal resto del mondo sulla regolamentazione dell’AI, anche l’amministrazione Usa cerca di accelerare.
In settimana il presidente Biden ha incontrato a San Francisco un gruppo di esperti di AI e di accademici (alcuni dei quali piuttosto critici sull’andamento attuale del business dell’AI) per avere una prospettiva non industriale sui rischi e le opportunità di questa tecnologia.
Fonti governative - [riporta](https://edition.cnn.com/2023/06/20/politics/joe-biden-artificial-intelligence/) CNN -  sostengono di aver gettato le basi **per diverse azioni politiche che saranno presentate quest'estate - tra cui degli ordini esecutivi** - per massimizzare l'effetto delle normative esistenti sul...