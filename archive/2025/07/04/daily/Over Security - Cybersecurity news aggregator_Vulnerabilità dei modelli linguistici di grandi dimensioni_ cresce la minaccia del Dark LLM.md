---
title: Vulnerabilità dei modelli linguistici di grandi dimensioni: cresce la minaccia del Dark LLM
url: https://www.cybersecurity360.it/nuove-minacce/vulnerabilita-dei-modelli-linguistici-di-grandi-dimensioni-cresce-la-minaccia-del-dark-llm/
source: Over Security - Cybersecurity news aggregator
date: 2025-07-04
fetch_date: 2025-10-06T23:55:00.684441
---

# Vulnerabilità dei modelli linguistici di grandi dimensioni: cresce la minaccia del Dark LLM

[Vai al contenuto principale](#main-content)
[Vai al footer](#footer-content)

![logo](data:image/png;base64...)![logo](https://cdnd360.it/networkdigital360/nd360-neg.svg)

[I NOSTRI SERVIZI](https://www.cybersecurity360.it/about-network)

Menu

[![Vai alla homepage di CyberSecurity](data:image/png;base64...)![Vai alla homepage di CyberSecurity](https://dnewpydm90vfx.cloudfront.net/wp-content/uploads/2024/03/cybersecurity_logo-768x55.png)](https://www.cybersecurity360.it)

## Vulnerabilità dei modelli linguistici di grandi dimensioni: cresce la minaccia del Dark LLM

* [Cybersecurity Nazionale](https://www.cybersecurity360.it/cybersecurity-nazionale/)
* Malware e attacchi
  + [Malware e attacchi](https://www.cybersecurity360.it/nuove-minacce/)
  + [Ransomware](https://www.cybersecurity360.it/nuove-minacce/ransomware/)
* Norme e adeguamenti
  + [Norme e adeguamenti](https://www.cybersecurity360.it/legal/)
  + [Privacy e Dati personali](https://www.cybersecurity360.it/legal/privacy-dati-personali/)
* [Soluzioni aziendali](https://www.cybersecurity360.it/soluzioni-aziendali/)
* [Cultura cyber](https://www.cybersecurity360.it/cultura-cyber/)
* [News, attualità e analisi Cyber sicurezza e privacy](https://www.cybersecurity360.it/news/)
* [Corsi cybersecurity](https://www.cybersecurity360.it/corsi-cybersecurity/)
* [Chi siamo](https://www.cybersecurity360.it/about/)

* [![Vai alla homepage di CyberSecurity](data:image/png;base64...)![Vai alla homepage di CyberSecurity](https://dnewpydm90vfx.cloudfront.net/wp-content/uploads/2024/03/cybersecurity_neg_logo-768x55.png)](https://www.cybersecurity360.it)
* Seguici
* + [twitter](https://twitter.com/Cybersec360)
  + [linkedin](https://www.linkedin.com/company/cybersecurity360/)
  + [Newsletter](https://www.cybersecurity360.it/newsletter-signin/)
  + [Rss Feed](#rssModal)
  + [Chi siamo](https://www.cybersecurity360.it/about)
* AREA PREMIUM
* [Whitepaper](https://www.cybersecurity360.it/whitepaper/)
* [Eventi](https://www.cybersecurity360.it/eventi/)
* [Webinar](https://www.cybersecurity360.it/webinar/)
* CANALI
* [Cybersecurity nazionale](https://www.cybersecurity360.it/cybersecurity-nazionale/)
* [Malware e attacchi](https://www.cybersecurity360.it/nuove-minacce/)
* + [Ransomware](https://www.cybersecurity360.it/nuove-minacce/ransomware/)* [Norme e adeguamenti](https://www.cybersecurity360.it/legal/)
  * + [Privacy e Dati personali](https://www.cybersecurity360.it/legal/privacy-dati-personali/)* [Soluzioni aziendali](https://www.cybersecurity360.it/soluzioni-aziendali/)
    * [Cultura cyber](https://www.cybersecurity360.it/cultura-cyber/)
    * [L'esperto risponde](https://www.cybersecurity360.it/esperto-risponde/)
    * [News, attualità e analisi Cyber sicurezza e privacy](https://www.cybersecurity360.it/news/)
    * [Corsi cybersecurity](https://www.cybersecurity360.it/corsi-cybersecurity/)
    * [Chi siamo](https://www.cybersecurity360.it/about/)

[Cybersecurity nazionale](https://www.cybersecurity360.it/cybersecurity-nazionale/)
[Malware e attacchi](https://www.cybersecurity360.it/nuove-minacce/)
[Norme e adeguamenti](https://www.cybersecurity360.it/legal/)
[Soluzioni aziendali](https://www.cybersecurity360.it/soluzioni-aziendali/)
[Cultura cyber](https://www.cybersecurity360.it/cultura-cyber/)
[L'esperto risponde](https://www.cybersecurity360.it/esperto-risponde/)
[News, attualità e analisi Cyber sicurezza e privacy](https://www.cybersecurity360.it/news/)
[Corsi cybersecurity](https://www.cybersecurity360.it/corsi-cybersecurity/)
[Chi siamo](https://www.cybersecurity360.it/about/)

lo studio

# Vulnerabilità dei modelli linguistici di grandi dimensioni: cresce la minaccia del Dark LLM

---

[Home](https://www.cybersecurity360.it)

[Attacchi hacker e Malware: le ultime news in tempo reale e gli approfondimenti](https://www.cybersecurity360.it/nuove-minacce/)

---

Indirizzo copiato

---

I ricercatori dell’Università Ben Gurion hanno dimostrato che molti LLM possono essere manipolati per eludere i controlli di sicurezza integrati e per ottenere istruzioni dettagliate su attività illegali. Ecco quali sono i principali rischi cyber, mentre si diffondono WormGPT e FraudGPT

Pubblicato il 3 lug 2025

---

[Laura Teodonno](https://www.cybersecurity360.it/giornalista/laura-teodonno/)

Senior Security & Osint Analyst, Hermes Bay

[Ginevra Detti](https://www.cybersecurity360.it/giornalista/ginevra-detti/)

analista Hermes Bay

---

---

![Le vulnerabilità dei modelli linguistici di grandi dimensioni (LLM)](data:image/png;base64...)![Le vulnerabilità dei modelli linguistici di grandi dimensioni (LLM)](https://dnewpydm90vfx.cloudfront.net/wp-content/uploads/2024/09/Rischi-nascosti-negli-LLM.jpg)

---

I **[modelli linguistici di grandi dimensioni (LLM)](https://www.cybersecurity360.it/nuove-minacce/llm-per-la-cyber-security-suggerimenti-per-un-uso-corretto-dei-large-language-model/)** hanno trasformato in pochi anni numerosi settori, dall’assistenza sanitaria all’istruzione, imponendosi come una delle innovazioni più significative dell’era moderna.

Proprio in forza della loro importanza, le vulnerabilità a cui sono esposti devono essere valutate con attenzione.

In particolare, un recente studio condotto dai ricercatori dell’**Università Ben Gurion del Negev**, Michael Fire, Yitzhak Elbazis, Adi Wasenstein e Lior Rokach, ha evidenziato la **vulnerabilità** dei modelli alle tecniche di “**jailbreaking**“.

> [La prima mappa dei rischi nascosti nei Large Language Model](https://www.cybersecurity360.it/outlook/la-prima-mappa-dei-rischi-nascosti-negli-assistenti-virtuali/)

Indice degli argomenti

* [Le vulnerabilità dei modelli LLM: i rischi](#Le_vulnerabilita_dei_modelli_LLM_i_rischi)
  + [Restrizioni etiche e legali in fase di addestramento degli LLM](#Restrizioni_etiche_e_legali_in_fase_di_addestramento_degli_LLM)
* [Un jailbreak universale per mitigare i rischi](#Un_jailbreak_universale_per_mitigare_i_rischi)
* [La crescente minaccia del Dark LLM](#La_crescente_minaccia_del_Dark_LLM)
* [Servono strategie di difesa più solide](#Servono_strategie_di_difesa_piu_solide)
* [Prospettive future](#Prospettive_future)

## Le vulnerabilità dei modelli LLM: i rischi

Se la capacità di comprendere e generare linguaggio naturale dei LLM ha rivoluzionato l’interazione uomo-macchina, ha fatto anche emergere dei **rischi** da non ignorare, come la possibilità di **manipolare i modelli forzandoli a superare le restrizioni etiche e legali imposte durante l’addestramento**.

L’addestramento di un modello linguistico di grandi dimensioni consiste, infatti, nell’esposizione a vasti insiemi di dati testuali, tra i quali possono comparire **bias**, **informazioni sensibili o contenuti inappropriati** che devono essere limitati per evitare la generazione di output dannosi o fuorvianti.

Le **restrizioni etiche e legali** imposte durante l’addestramento dei modelli linguistici di grandi dimensioni sono fondamentali per garantire che questi sistemi operino in modo sicuro e conforme alle normative vigenti.

Le restrizioni etiche includono:

* selezione dei dati per rimuovere odio, discriminazione e violenza;
* rimozione di informazioni personali per proteggere la riservatezza e la privacy degli utenti;
* identificazione e riduzione dei pregiudizi presenti nei dati per evitare che il modello li perpetui.

Sul fronte legale, l’addestramento degli LLM deve rispettare diverse norme, tra cui quelle sui **diritti di autore e la protezione dei dati**.

### Restrizioni etiche e legali in fase di addestramento degli LLM

Implementare restrizioni etiche e legali durante l’addestramento degli LLM è cruciale per sviluppare sistemi affidabili e responsabili, tuttavia, i ricercatori dell’Università Ben Gurion hanno dimostrato che **molti LLM possono essere manipolati per eludere i controlli di sicurezza integrati** e che, utilizzando **prompt appositamente progettati** o formulando le **richieste in modo creativo** come se fossero parte di una sceneggiat...