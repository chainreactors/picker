---
title: 专题·人工智能安全治理 | 凝聚安全风险治理共识 促进人工智能创新发展
url: https://mp.weixin.qq.com/s?__biz=MzA5MzE5MDAzOA==&mid=2664236606&idx=1&sn=63856aedc18708ebeb00c3c398593e3a&chksm=8b5804c7bc2f8dd1af572659ff2378d1cb302f80dbeadd26d7fc67c743eafab8cdd5c8986df4&scene=58&subscene=0#rd
source: 中国信息安全
date: 2025-02-14
fetch_date: 2025-10-06T20:37:07.557670
---

# 专题·人工智能安全治理 | 凝聚安全风险治理共识 促进人工智能创新发展

![cover_image](https://mmbiz.qpic.cn/sz_mmbiz_jpg/1brjUjbpg5xl2QVo1SEudt2tYUbsnNmzAkibicabib8aHnGHNv5v60eJSmriaFV8fniaWe0DyiabHG02IibWkPAj561Eg/0?wx_fmt=jpeg)

# 专题·人工智能安全治理 | 凝聚安全风险治理共识 促进人工智能创新发展

原创

刘金瑞

中国信息安全

![](https://mmbiz.qpic.cn/sz_mmbiz_gif/1brjUjbpg5y7Kia8T67ffDGEg7bnuTKCkl1KFCHPXpG73xqKywXNNALqhPMv9UG5KcpZCicICmSVluScjicRDN52w/640?wx_fmt=gif&from=appmsg)

![](https://mmbiz.qpic.cn/sz_mmbiz_png/1brjUjbpg5y7Kia8T67ffDGEg7bnuTKCkXn3CSbXxhOE7mXSn4eVkHibgyiaSHbKuYMzFR9LjVcHTd0U2V7xNp8lA/640?wx_fmt=png&from=appmsg)

![](https://mmbiz.qpic.cn/sz_mmbiz_gif/1brjUjbpg5y7Kia8T67ffDGEg7bnuTKCkl1KFCHPXpG73xqKywXNNALqhPMv9UG5KcpZCicICmSVluScjicRDN52w/640?wx_fmt=gif&from=appmsg)

**扫码订阅《中国信息安全》**

邮发代号 2-786

征订热线：010-82341063

文 | 中国法学会法治研究所研究员 刘金瑞

2022 年底，ChatGPT 的横空出世重新点燃了人们对人工智能的热情，国内外科技巨头和初创公司纷纷投身于研发其背后的大模型技术。大模型又称通用模型或基础模型，是指在大规模数据上训练，具有海量模型参数，能够适应广泛下游任务的模型。大模型技术的新突破，掀起了生成式人工智能发展的新浪潮，开启了迈向通用人工智能的新路径。这波人工智能发展的狂飙突进，正在对经济发展、社会治理和人民生活产生重大而深刻的影响，给世界带来巨大机遇。

但与此同时，人工智能技术的发展和应用也带来日益严峻和复杂的风险挑战，既包括传统的人工智能系统本身的安全问题，也包括大模型训练开发和部署应用引发的产生有害内容、泄露敏感数据、生成错误信息、滥用实施违法活动、可能危害环境和经济、向下游应用传导风险等新的挑战。如何防范和应对人工智能发展带来的安全风险，如何平衡好人工智能发展与安全的关系，引导生成式人工智能健康发展，已成为人类社会面临的共同挑战。

对此，主要大国都在积极研究应对之策，我国在探索专门治理方案方面走在了前列。我国 2023 年 5 月将“人工智能法草案”列入国务院年度立法工作计划，揭开了人工智能专门立法的序幕；2023 年 7 月，发布了《生成式人工智能服务管理暂行办法》（以下简称《暂行办法》），着重防范和规制生成式人工智能服务引发的信息内容安全风险；2023 年 10 月，提出了《全球人工智能治理倡议》（以下简称《倡议》），围绕人工智能发展、安全、治理三方面，系统阐述了人工智能治理的中国方案，其中明确提出各国应推动“形成具有广泛共识的人工智能治理框架和标准规范，不断提升人工智能技术的安全性、可靠性、可控性、公平性”。

为了贯彻落实《倡议》主张，2024 年 9 月 9 日，全国网络安全标准化技术委员会在 2024 年国家网络安全宣传周主论坛上发布了《人工智能安全治理框架》1.0 版（以下简称《框架》）。《框架》基于风险管理理念，针对人工智能技术的新发展和新特性，识别分析了当前人工智能风险的来源和类型，从内生安全和应用安全两个维度提出了应对这些风险的技术措施和管理措施，并在此基础上对人工智能研发应用给出了安全指引。这是我国推动人工智能治理从原则走向实践、促进人工智能创新发展的又一有力举措。主要体现在以下几个方面。

**一、明确安全治理的目标和原则，坚持发展和安全并重**

对于人工智能安全治理来说，首先应该明确治理的基本目标和基本原则，因为它们代表了确保人工智能安全的基本立场和价值追求。《框架》贯彻《全球人工智能治理倡议》，遵循“以人为本、智能向善”的理念宗旨，秉持共同、综合、合作、可持续的安全观，坚持发展和安全并重，以促进人工智能创新发展为第一要务，以有效防范化解人工智能安全风险为出发点和落脚点，系统阐述了我国人工智能安全治理的基本目标和基本原则。其中，安全治理目标在于构建各方共同参与、技管结合、分工协作的治理机制，压实相关主体安全责任，打造全过程全要素治理链条，培育安全、可靠、公平、透明的人工智能技术研发和应用生态，推动人工智能健康发展和规范应用，进而实现“切实维护国家主权、安全和发展利益，保障公民、法人和其他组织的合法权益，确保人工智能技术造福于人类”。

为了实现上述目标，《框架》明确了人工智能安全治理的四项基本原则：一是包容审慎、确保安全。这是治理的基本立场，强调既鼓励发展创新，又严守安全底线，及时对危害国家安全、社会公共利益和公众合法权益的风险采取措施。包容审慎原则延续了《暂行办法》的既有规定。二是风险导向、敏捷治理。这是治理的基本思路，强调密切跟踪技术发展趋势，动态精准调整治理措施，以快速响应安全风险的发展变化。三是技管结合、协同应对。这是治理的基本手段，强调综合运用技术和管理措施，明确人工智能研发应用生态链各参与方的安全责任，形成政府监管、行业自律、社会监督的协同治理机制。四是开放合作、共治共享。这是治理的国际策略，强调推动国际合作，共享最佳实践，建立开放性平台，通过跨学科、跨领域、跨地区、跨国界的对话和合作，推动形成具有广泛共识的全球人工智能治理体系。

基于上述基本目标和基本原则，《框架》明确了人工智能安全治理框架的构成：第一部分是安全风险的类型化，这是贯彻风险导向、敏捷治理原则的前提基础；第二部分和第三部分分别是技术应对措施和综合治理措施，这是落实技管结合、协同应对原则的必然要求；第四部分是安全开发应用指引，是上述治理原则和治理措施应用于人工智能研发应用生态链各参与方的具体细化，有利于压实相关主体的安全责任。从风险管理的视角看，《框架》的第一部分属于风险评估，后三个部分属于风险应对。

**二、识别安全风险的来源和类型，聚焦技术发展新挑战**

相较于之前的人工智能技术，大模型技术有着不同的技术特性：基于深度学习架构，首先以大规模无标注数据进行无监督的模型“预训练”，然后再用有标注数据等进行有监督的模型“微调”，以更好地适配下游任务。因此，大模型的生命周期可以分为以数据训练为主的模型训练研发阶段和以模型适配为主的模型部署应用阶段。要认识大模型技术所驱动的生成式人工智能的新风险和新挑战，需从大模型技术的训练研发和部署应用两方面着手。

在这一技术背景下，《框架》在借鉴国内外相关研究成果基础上，将人工智能系统研发应用全生命周期的风险，识别区分为人工智能技术本身缺陷不足引发的风险与人工智能技术应用滥用引发的风险，并将前者称为“人工智能内生安全风险”，将后者称为“人工智能应用安全风险”。《框架》在梳理这两大方面风险时，聚焦了近期生成式人工智能技术的新发展和新特性，尤其是大模型的训练研发和部署应用带来的新威胁和新挑战。

**对于人工智能内生安全风险，**《框架》围绕人工智能技术自身核心构成要素，概括为三个方面，除了包括传统的系统本身的安全风险外，尤其着重分析了模型算法本身的安全风险以及模型数据训练存在的风险。一是模型算法安全风险，包括可解释性差；存在偏见、歧视；鲁棒性弱；被窃取、篡改；输出不可靠；对抗攻击等。二是数据安全风险，涉及违规收集使用数据；训练数据含不当内容、被“投毒”；训练数据标注不规范；数据泄露等。三是系统安全风险，包括缺陷、后门被攻击利用；算力安全风险；供应链安全风险等。

**对于人工智能应用安全风险，**《框架》围绕人工智能技术应用的主要影响领域，列举了四个方面，既涉及了对人类物质世界的影响，也涉及了对人类精神世界的影响。一是网络域安全风险，包括信息内容安全风险；混淆事实、误导用户、绕过鉴权；不当使用引发信息泄露；滥用于网络攻击；模型复用的缺陷传导等。二是现实域安全风险，涉及诱发传统经济社会安全风险；用于违法犯罪活动；两用物项和技术滥用等。三是认知域安全风险，包括加剧“信息茧房”效应、用于开展认知战等。四是伦理域安全风险，包括加剧社会歧视偏见、扩大智能鸿沟；挑战传统社会秩序；未来脱离控制等。需要指出的是，这些影响领域并不是截然区分的，往往存在一定交叉，例如“信息茧房”问题往往也是网络域常见的信息内容安全风险。《框架》概括了较为常见和突出的应用风险问题，提出了一种分析框架，这种概括分析是对人工智能应用重点影响领域的不完全列举。

**三、基于风险制定防范应对措施，技术与管理双管齐下**

针对上述模型算法安全、数据安全和系统安全等内生安全风险以及网络域、现实域、认知域、伦理域等应用安全风险，《框架》提出了技术措施与管理措施双管齐下的综合防治举措。当然，技术措施与管理措施并非截然割裂，而是相辅相成的：技术措施往往是为了落实管理措施，很多管理措施需要以技术可行为前提，二者都是为了实现安全治理的目标。鉴于此，以下按“先管理措施后技术措施”的顺序对《框架》列出的风险防治措施进行梳理。

就应对人工智能内生安全风险而言。对于模型算法安全风险，管理措施包括两个方面：一是推进人工智能可解释性研究，二是构建以负责任的人工智能研发应用体系。而落实这两方面的技术措施就需要：一是为人工智能系统内部构造、推理逻辑、技术接口、输出结果提供明确说明；二是建立并实施安全开发规范，尽可能消除模型算法存在的安全缺陷、歧视性倾向，提高鲁棒性。

**对于数据安全风险，**管理措施主要是完善人工智能数据安全和个人信息保护规范。而落实的技术措施主要是要确保所涉数据的可控性和正当性：一方面要确保不包含核生化导武器等高危领域敏感数据，对训练数据中的敏感个人信息和重要数据加强管理，向境外提供模型算法应符合出口管制要求；另一方面要使用正当合法的训练数据，防止侵犯知识产权等。

**对于系统安全风险，**管理措施包括两个方面：一是强化人工智能供应链安全保障，二是构建人工智能安全风险威胁信息共享和应急处置机制。而落实这两方面的技术措施就需要：一是提高人工智能系统的透明性；二是多模型或系统聚合平台的防护；三是加强算力平台和系统服务的安全建设、管理、运维能力；四是高度关注芯片、软件、工具、算力和数据资源的供应链安全。

就应对人工智能应用安全风险而言，共通的管理措施包括五个方面：一是实施人工智能应用分类分级管理；二是建立人工智能服务可追溯管理制度；三是加大人工智能安全人才培养力度；四是建立健全人工智能安全宣传教育、行业自律、社会监督机制；五是促进人工智能安全治理国际交流合作。考虑到不同应用领域的风险特点，需要采取针对性的技术措施，例如对网络域风险应建立安全防护机制和数据护栏，对现实域风险应根据实际应用场景设置服务提供边界，对认知域风险判别不正当的输出结果，对伦理域风险应防范产生地域、性别等方面歧视。

**四、围绕研发应用提出安全指引，推动全链条风险共治**

鉴于目前人工智能法治仍在发展健全之中，监管侧讨论的很多治理原则和框架举措对实践的指导尚不够具体，投身人工智能研发应用生态链的各参与方包括社会公众在内，往往对其应如何行为存在较大困惑。为此，《框架》在上述技术措施和管理措施基础上，还就安全开发应用人工智能技术对模型算法研发者、服务提供者、重点领域使用者和社会公众作出了明确指引，以推动人工智能研发应用生态链各参与方实现风险共治。这些指引除了重申前述要求和举措外，还提出了一些更为具体的要求，简要概括如下。

**对于模型算法研发者，**要求在关键环节践行科技伦理规范，采取科技伦理审查、听取公众意见、与潜在目标用户沟通交流、加强员工安全教育培训等措施；重视数据安全和个人信息保护，尊重知识产权和版权，确保数据来源清晰、途径合规；确保模型算法训练环境的安全性，评估模型算法潜在偏见，设计有效、可靠的对齐算法，确保价值观风险、伦理风险等可控；结合目标市场适用法律要求和风险管理要求，定期开展安全评估测试，生成测试报告并提出改进方案。

**对于人工智能服务提供者，**要求公开人工智能产品和服务的能力、局限性、适用人群、场景，支持使用者行使监督和控制责任；应检查研发者的责任说明文件，确保责任链条可以追溯到递归采用的人工智能模型；提高风险防范意识，建立健全实时风险监控管理机制；发现安全事故、安全漏洞等及时向主管部门报告，确保异常条件下最低限度有效功能；发现误用滥用时要进行纠正或终止服务，防范对使用者造成危害。

**对于政府部门、关键信息基础设施以及直接影响公共安全和公民生命健康安全的领域等重点领域使用者，**要求审慎评估人工智能技术应用的影响，定期进行系统审计，提高风险防范意识与应对处置能力；应增强网络安全、供应链安全等方面的能力，合理限制人工智能系统对数据的访问权限，制定数据备份和恢复计划，确保操作符合保密规定；确保人的有效监督，避免完全依赖人工智能的决策，在遭遇事故时及时切换到人工或传统系统。

**对于社会公众，**要求提高对人工智能产品安全风险的认识，准确认知所用产品做出判断决策的局限性；提高个人信息保护意识，避免在不必要时输入敏感信息，避免使用不符合隐私保护原则的产品，关注人工智能产品使用的网络安全风险；注意人工智能产品对儿童和青少年的影响，预防沉迷及过度使用。

总的来看，《框架》最大程度凝聚了风险治理共识，为人工智能安全风险治理提供了基础性、框架性指南，有利于在严守安全底线的前提下培育安全、可靠、公平、透明的人工智能产业生态，进而切实促进人工智能规范应用和创新发展。同时，《框架》也有利于进一步推动人工智能安全治理国际合作，进而有助于在全球范围推动形成具有广泛共识的人工智能治理体系，确保人工智能技术真正造福于人类。

（本文刊登于《中国信息安全》杂志2024年第10期）

**分享网络安全知识 强化网络安全意识**

**欢迎关注《中国信息安全》杂志官方抖音号**

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/1brjUjbpg5y7Kia8T67ffDGEg7bnuTKCkUOkdfx1VzjgSRTKm1NUkvichczQibaOvdAUVZTicPicZXbskyTjXBacepQ/640?wx_fmt=jpeg&from=appmsg)

**《中国信息安全》杂志倾力推荐**

**“企业成长计划”**

**点击下图 了解详情**

[![](https://mmbiz.qpic.cn/sz_mmbiz_png/1brjUjbpg5y7Kia8T67ffDGEg7bnuTKCkibkibpYicNuuibKodkOxiafYGdtAzm3FOvk9gAg7gd50zlytl7tHFxrJgGQ/640?wx_fmt=png&from=appmsg)](https://mp.weixin.qq.com/s?__biz=MzA5MzE5MDAzOA==&mid=2664162643&idx=1&sn=fcc4f3a6047a0c2f4e4cc0181243ee18&scene=21#wechat_redirect)

预览时标签不可点

![]()

微信扫一扫
关注该公众号

继续滑动看下一个

轻触阅读原文

![](http://mmbiz.qpic.cn/sz_mmbiz_png/1brjUjbpg5xcg6pmGiagMsJTqnHObJGHSj6TEe6InbwlHLIxFVhPohvicQibAcuia5wDEoRISsAkUyYPUB06cU9mibw/0?wx_fmt=png)

中国信息安全

向上滑动看下一个

知道了

![]()
微信扫一扫
使用小程序

取消
允许

取消
允许

取消
允许

×
分析

![跳转二维码]()

![作者头像](http://mmbiz.qpic.cn/sz_mmbiz_png/1brjUjbpg5xcg6pmGiagMsJTqnHObJGHSj6TEe6InbwlHLIxFVhPohvicQibAcuia5wDEoRISsAkUyYPUB06cU9mibw/0?wx_fmt=png)

微信扫一扫可打开此内容，
使用完整服务

：
，
，
，
，
，
，
，
，
，
，
，
，
。

视频
小程序
赞
，轻点两下取消赞
在看
，轻点两下取消在看
分享
留言
收藏
听过