---
title: 因配置不当，约5000个AI模型与数据集在公网暴露
url: https://mp.weixin.qq.com/s?__biz=MzI4NDY2MDMwMw==&mid=2247512766&idx=2&sn=ab5f99c9ac50424a9a154d9063c8a762&chksm=ebfaf59edc8d7c883d9dc93f15e9399b189c2ce46c9ce55b35f74f42cc0ea3ea48b2338479ba&scene=58&subscene=0#rd
source: 安全内参
date: 2024-10-11
fetch_date: 2025-10-06T18:52:47.967421
---

# 因配置不当，约5000个AI模型与数据集在公网暴露

![cover_image](https://mmbiz.qpic.cn/sz_mmbiz_jpg/FzZb53e8g7vDRyFxHQTciceZrVgrPibdkIHHLGvCfMCcZvwISl6GXWribFaUMNO0jPtSCbYLmeY5dIJU1WRaFiadtw/0?wx_fmt=jpeg)

# 因配置不当，约5000个AI模型与数据集在公网暴露

安全内参编译

安全内参

**关注我们**

**带你读懂网络安全**

![](https://mmbiz.qpic.cn/sz_mmbiz_png/FzZb53e8g7vDRyFxHQTciceZrVgrPibdkIJUeXZd2A8fRuQAjXsjzYIRoneJY4Yib0doXoeJZE29aVqc62YtG3DicA/640?wx_fmt=png&from=appmsg)

**除了可访问机器学习模型外，暴露的数据还可能包括训练数据集、超参数，甚至是用于构建模型的原始数据。**

前情回顾·**人工智能安全动态**

* [向ChatGPT植入恶意“长期记忆”，持续窃取用户输入数据](http://mp.weixin.qq.com/s?__biz=MzI4NDY2MDMwMw==&mid=2247512702&idx=1&sn=183b62e899019269d6a0f8da6b16f22b&chksm=ebfaf55edc8d7c48d368e788e701ea30e94b7cbe585553bb545730aaaacc3239b90d4a081d57&scene=21#wechat_redirect)
* [多模态大语言模型的致命漏洞：语音攻击](http://mp.weixin.qq.com/s?__biz=MzI4NDY2MDMwMw==&mid=2247511649&idx=2&sn=4bed154b2b1a7dff303ab027ea8e3508&chksm=ebfae941dc8d60574155f9a5c4763bb62803bc035f1328bcf9329ca4b24e0f74b6343ddd8d48&scene=21#wechat_redirect)
* [如何操纵AI大模型？研究发现一种隐蔽的供应链投毒方法](http://mp.weixin.qq.com/s?__biz=MzI4NDY2MDMwMw==&mid=2247511085&idx=1&sn=ce6268acf57017e042c2ae69ab535c15&chksm=ebfaeb0ddc8d621bdd2ccc33ff4848cef5cd7e03b66aaa7a4a19b142356aab40ce0fbe015eff&scene=21#wechat_redirect)
* [OpenAI反复修补未果的ChatGPT数据泄露漏洞是什么？](http://mp.weixin.qq.com/s?__biz=MzI4NDY2MDMwMw==&mid=2247510652&idx=1&sn=32aae66d172b998bebb5ec073df3c99c&chksm=ebfaed5cdc8d644abaae2cbe46ad2d437b0b299bf26b7bbe75083eed945f6f0db7e9f2f255e7&scene=21#wechat_redirect)

安全内参10月10日消息，一名安全研究人员透露，数千个机器学习工具已暴露在开放的互联网中，其中一些还属于大型科技公司。任何人都能访问这些工具，并存在敏感数据泄露的潜在风险。

这则消息表明，尽管公司和研究人员在人工智能研究上突飞猛进，但保护这些工具，仍需要依赖适用于其他类型账号的通用账号安全和身份验证最佳实践。

Reddit的安全研究人员兼首席安全工程师Charan Akiri在其研究报告中指出：“除了机器学习（ML）模型本身，暴露的数据还可能包括训练数据集、超参数，甚至有时是用于构建模型的原始数据。”

暴露的工具包括MLflow、Kubeflow和TensorBoard实例。这些工具通常用于帮助企业在云端训练和部署生成式AI模型，或可视化其结果。

Akiri在研究报告中写道：“这种配置错误使得未经授权的人员能够访问、下载，甚至运行敏感的机器学习模型和数据集。这类暴露事件本不应发生，因为这些平台应该仅限于内部使用。”

Akiri指出，他们已经能够识别出部分暴露实例的所有者，但他强调，“这只是整体暴露的一小部分，实际上可能还有许多公司尚未被我们识别出来。”

其中一家公司是日本的半导体制造商瑞萨电子（Renesas Electronics）。Akiri表示，通过控制面板证书中的线索，他们确认了一个机器学习工具属于瑞萨电子。外媒404 Media联系瑞萨电子请求对此事发表评论后，瑞萨电子立即撤下了暴露的控制面板，Akiri也通知了该公司这一问题。然而，瑞萨电子最终未对评论请求作出回应。

404 Media在访问几个可以通过开放互联网找到的MLFlow实例时，发现控制面板提供了创建“新运行”的选项。用户还能查看之前的实验记录，通常还能够执行与原用户相同或类似的任务。Akiri表示，他们发现了大约5000个暴露的MLFlow实例。

**参考资料：404media.co**

**推荐阅读**

* [网安智库平台长期招聘兼职研究员](http://mp.weixin.qq.com/s?__biz=MzI4NDY2MDMwMw==&mid=2247499450&idx=2&sn=2da3ca2e0b4d4f9f56ea7f7579afc378&chksm=ebfab99adc8d308c3ba6e7a74bd41beadf39f1b0e38a39f7235db4c305c06caa49ff63a0cc1d&scene=21#wechat_redirect)
* [欢迎加入“安全内参热点讨论群”](https://mp.weixin.qq.com/s?__biz=MzI4NDY2MDMwMw==&mid=2247501251&idx=1&sn=8b6ebecbe80c1c72317948494f87b489&chksm=ebfa82e3dc8d0bf595d039e75b446e14ab96bf63cf8ffc5d553b58248dde3424fb18e6947440&token=525430415&lang=zh_CN&scene=21#wechat_redirect)

---

点击下方卡片关注我们，

带你一起读懂网络安全 ↓

预览时标签不可点

阅读原文

![]()

微信扫一扫
关注该公众号

继续滑动看下一个

轻触阅读原文

![](http://mmbiz.qpic.cn/mmbiz_png/FzZb53e8g7u3766XzHf0XHoQ1HkzDV0M7wC5zTyTO6daqAZ6LMD0Lykps2WumsWj2KMQJAGhwOYDcb3E8AicxSw/0?wx_fmt=png)

安全内参

向上滑动看下一个

知道了

![]()
微信扫一扫
使用小程序

取消
允许

取消
允许

取消
允许

×
分析

![跳转二维码]()

![作者头像](http://mmbiz.qpic.cn/mmbiz_png/FzZb53e8g7u3766XzHf0XHoQ1HkzDV0M7wC5zTyTO6daqAZ6LMD0Lykps2WumsWj2KMQJAGhwOYDcb3E8AicxSw/0?wx_fmt=png)

微信扫一扫可打开此内容，
使用完整服务

：
，
，
，
，
，
，
，
，
，
，
，
，
。

视频
小程序
赞
，轻点两下取消赞
在看
，轻点两下取消在看
分享
留言
收藏
听过