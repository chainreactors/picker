---
title: Possiamo vivere con computer che sbagliano
url: http://www.zeusnews.it/n.php?c=31312
source: Instapaper: Unread
date: 2025-09-12
fetch_date: 2025-10-02T20:03:14.248583
---

# Possiamo vivere con computer che sbagliano

![](https://b.scorecardresearch.com/p?c1=2&c2=13879765&cv=2.0&cj=1)

[![Zeus News](/pic/logo.gif)](/)

[Salta il menu](#contenuto)

* [Home](http://www.zeusnews.it)
* [Editoriale](index.php3?ar=sezioni&numero=949)
* [Recensioni](index.php3?ar=sezioni&numero=912)
* [Focus](index.php3?ar=sezioni&numero=913)
* [Sicurezza](index.php3?ar=sezioni&numero=901)
* [Trucchi](index.php3?ar=sezioni&numero=906)
* [Maipiusenza](index.php3?ar=sezioni&numero=903)
* [Segnalazioni](index.php3?ar=sezioni&numero=905)
* [Sondaggi](index.php3?ar=sezioni&numero=902)
* [Antibufala](index.php3?ar=sezioni&numero=904)
* [Download](index.php3?ar=sezioni&numero=916)
* [News](index.php3?ar=sezioni&numero=907)
* [Flash](index.php3?ar=sezioni&numero=914)
* [Pag2](index.php3?ar=sezioni&numero=915)

[![Newsletter](pic/pulsanti/newsletter.png "Newsletter")](http://newsletter.zeusnews.it/index.php?p=subscribe&id=5)
[![RSS](pic/pulsanti/rss.png "Feed RSS")](http://feeds.feedburner.com/ZeusNews)
[![Facebook](pic/pulsanti/facebook.png "Zeus News su Facebook")](http://www.facebook.com/ZeusNews)
[![Forum Olimpo Informatico](pic/pulsanti/forum.png "Forum Olimpo Informatico")](http://forum.zeusnews.com/index.php?c=1)
[![Contatti](pic/pulsanti/contatti.png "Contatti")](http://www.zeusnews.it/index.php3?ar=staff)
[![Accadde oggi](pic/pulsanti/calendar3.png "Accadde oggi")](http://www.zeusnews.it/index.php3?ar=accaddeoggi)
[![Ricerca](pic/pulsanti/ricerca.png "Cerca in Zeus News")](http://www.zeusnews.it/index.php3?ar=ricerca)

[Newsletter](http://newsletter.zeusnews.it/index.php?p=subscribe&id=5)
[Feed RSS](http://feeds.feedburner.com/ZeusNews)
[Facebook](http://www.facebook.com/ZeusNews)
[Forum](http://forum.zeusnews.com/index.php?c=1)
[Contatti](http://www.zeusnews.it/index.php3?ar=staff)
[Accadde oggi](http://www.zeusnews.it/index.php3?ar=accaddeoggi)
[Cerca](http://www.zeusnews.it/index.php3?ar=ricerca)

# Possiamo vivere con computer che sbagliano?

Cassandra Crossing/ L'introduzione forzata di LLM in tutti i settori dell'informatica, che la finanza rende obbligatoria, ha fatto una importante vittima: la fiducia nelle risposte dei computer. Ma possiamo conviverci senza perderci in un mondo fatto di allucinazioni ed errori?

[Tweet](https://twitter.com/share)

[*ZEUS News* - [www.zeusnews.it](https://www.zeusnews.it/) - 11-09-2025] Commenti (34)

![cassandra computer che sbagliano](https://www.zeusnews.it/img/2/1/3/1/3/0/031312-620-cassandra-computer-che-sbagliano.png)

La [filosofia della scienza](util/extlink/cerca_amazon.php?q=filosofia della scienza "Cerca filosofia della scienza su Amazon") non è cosa che sia familiare a Cassandra, se non a causa di quei pochi fatterelli avvenuti durante una vita passata immersa dentro la tecnologia fino ai capelli, che talvolta le hanno dato molto da pensare. È per questo che, dopo aver tanto scritto sulle [false intelligenze artificiali](/link/46448 "https://cse.google.it/cse?cx=partner-pub-8103963444977960:5422901670&q=false+intelligenze+artificiali&sa=Cerca"), cioè sui Large Language Model (LLM) venduti come oracoli, ha sentito il bisogno di fare diversi passi indietro, per osservare quello che sta succedendo e quello che succederà, e trovare non il nocciolo dei problemi presenti, che sta certamente nella finanza, ma quello dei problemi futuri. Magari perfino ipotizzare una possibilità di soluzione.

A questo livello estremamente generale quale è il rischio per l'umanità se l'introduzione massiccia di LLM come oracoli continuasse? I 24 lettori infaticabili di Cassandra potrebbero facilmente preparare una lista come questa:
1. Consumi energetici tali da incidere sul cambiamento climatico;
2. Perdita di posti di lavoro e aumento della povertà, particolarmente nei Paesi sviluppati;
3. Inquinamento [dell'infosfera](/link/46449 "https://cse.google.it/cse?cx=partner-pub-8103963444977960:5422901670&q=infosfera&sa=Cerca"), o se preferite della cultura stessa, per la diffusione incontrollabile di contenuti generati da LLM, che renderanno documentalmente indistinguibili la realtà e la storia dalle allucinazioni;
4. Esplosioni di [bolle finanziarie](zn/31256 "Il CEO di OpenAI avverte: l'IA è una bolla, qualcuno perderà un sacco di soldi") tali da mettere in pericolo gli scambi commerciali globali e incidere sui bisogni essenziali di una buona parte dei troppi abitanti di questo pianeta;
5. Perdita generalizzata di capacità mentali, di iniziativa e di competenza, a partire dai professionisti e dai ricercatori fino alla generalità dell'umanità;
6. Riduzione in [pappa](util/extlink/cerca_amazon.php?q=pappa "Cerca pappa su Amazon") delle menti di chi è nei suoi anni formativi, con la produzione massiccia di persone prive di capacità mentali e non in grado di produrre contributi significativi per l'umanità.

Queste previsioni, che sono tutte (purtroppo) destinate più o meno ad avverarsi, rappresentano ciò che si può vedere allontanandosi solo di un passo dalla cronaca quotidiana.

Facciamo ancora un passo indietro, magari più di uno. Probabilmente la maggior parte delle persone non riesce più a rendersi conto di quanto l'informatica (ormai dire "computer" sarebbe riduttivo e impreciso) abbia permeato l'antroposfera del pianeta, e di quanto tutto dipenda ormai da essa - ma proprio tutto, per i ricchi e i poveri, per i giovani e per i vecchi. Cosa cambierà se l'introduzione degli LLM come [oracoli](util/extlink/cerca_amazon.php?q=oracoli "Cerca oracoli su Amazon") continuerà come pare destinata a fare? Decenni di informatica pre-LLM ci hanno abituato a considerare i computer o meglio i sistemi informatici come oracoli. "Oracolo" nel campo intelligenza artificiale non è un termine generico e impreciso ma contraddistingue una classe precisa di sistemi; quelli con cui si può interagire ponendo una domanda generica e avendo in cambio una risposta esatta.

Leggi anche:

[![](/img/6/5/2/1/3/0/031256-620-altman-bolla-ia.jpg)](/zn/31256)

[Il CEO di OpenAI avverte: l'IA è una bolla, qualcuno perderà un sa...](/zn/31256 "Il CEO di OpenAI avverte: l'IA è una bolla, qualcuno perderà un sacco di soldi")

[![](/img/6/4/1/1/3/0/031146-620-oracoli-ia-fuffa.png)](/zn/31146)

[Le IA vendute come oracoli sono solo fuffa: ecco perché](/zn/31146 "Le IA vendute come oracoli sono solo fuffa: ecco perché")

[![](/img/6/3/2/1/3/0/031236-620-cassandra-bolla-dotcom-bolla-llm.png)](/zn/31236)

[La bolla finanziaria degliÂ LLM](/zn/31236 "La bolla finanziaria degliÂ LLM")

[![](/img/5/4/1/1/3/0/031145-620-eliza-cassandra.png)](/zn/31145)

[Eliza colpisce ancora](/zn/31145 "Eliza colpisce ancora")

Non c'è bisogno di pensare a sistemi complessi; una semplice calcolatrice tascabile, o l'equivalente app sullo smartphone, è un oracolo per le quattro operazioni, il suo campo di applicazione; se interrogata con la domanda "2+2=" darà invariabilmente la risposta "4" e in questa risposta noi riporremmo completa fiducia. E avremmo pienamente ragione. È un sistema informatico fatto per questo. A parte guasti o errori di programmazione, di solito abbastanza riconoscibili, l'informatica ci ha abituati a considerare affidabili le risposte che ci fornisce (nessuno si metta a ridere, siamo a un livello generale e filosofico, non pratico). Solo pochi anni fa a nessuno sarebbe venuto in mente di porre a una calcolatrice più grande la domanda *«Con chi devo uscire stasera?»* oppure *«Che cosa posso scrivere in questa relazione urgente?»*.

Le cose purtroppo non stanno più così, a causa degli LLM usati come oracoli. Cosa comporta l'introduzione nell'informatica di oggi degli LLM? Semplicemente l'introduzione in ogni dove di [scatole nere](util/extlink/cerca_amazon.php?q=scatole nere "Cerca scatole nere su Amazon") usate come oracoli, che forniscono risposte credibili non esatte, che poi cerchiamo di puntellare complicando ulteriormente il sistema informatico, modificando le domande indesiderate e cercando di eliminare le risposte credibili ma errate.Â Non è un modo di procedere ragionevole. Non è un modo di pro...