---
title: WAIC 2024开幕，上海AI Lab主任、首席科学家周伯文提出“人工智能45°平衡律”
url: https://www.freebuf.com/news/405218.html
source: FreeBuf网络安全行业门户
date: 2024-07-05
fetch_date: 2025-10-06T17:43:20.266984
---

# WAIC 2024开幕，上海AI Lab主任、首席科学家周伯文提出“人工智能45°平衡律”

[![freeBuf](/images/logoMax.png)](/)

主站

分类

云安全

AI安全

开发安全

终端安全

数据安全

Web安全

基础安全

企业安全

关基安全

移动安全

系统安全

其他安全

特色

热点

工具

漏洞

人物志

活动

安全招聘

攻防演练

政策法规

[报告](https://www.freebuf.com/report)[专辑](/column)

* ···
* [公开课](https://live.freebuf.com)
* ···
* [商城](https://shop.freebuf.com)
* ···
* 用户服务
* ···

行业服务

政 府

CNCERT
CNNVD

会员体系（甲方）
会员体系（厂商）
产品名录
企业空间

[知识大陆](https://wiki.freebuf.com/page)

搜索

![](/freebuf/img/7aa3bf7.svg) ![](/freebuf/img/181d733.svg)

创作中心

[登录](https://www.freebuf.com/oauth)[注册](https://www.freebuf.com/oauth)

官方公众号企业安全新浪微博

![](/images/gzh_code.jpg)

FreeBuf.COM网络安全行业门户，每日发布专业的安全资讯、技术剖析。

![FreeBuf+小程序](/images/xcx-code.jpg)

FreeBuf+小程序把安全装进口袋

[![](https://image.3001.net/images/20231020/1697804527_653270ef7570cc7356ba8.png)](https://wiki.freebuf.com)

WAIC 2024开幕，上海AI Lab主任、首席科学家周伯文提出“人工智能45°平衡律”

* ![]()
* 关注

* [资讯](https://www.freebuf.com/news)

WAIC 2024开幕，上海AI Lab主任、首席科学家周伯文提出“人工智能45°平衡律”

2024-07-04 17:04:24

所属地 上海

7月4日，2024世界人工智能大会暨人工智能全球治理高级别会议（WAIC 2024）在上海拉开帷幕。此次大会以“以共商促共享，以善治促善智”作为主题，聚集世界各国代表、顶级专家学者、行业精英、初创团队等，共同探讨在人工智能深度发展时代下的热点话题。

其中，上海人工智能实验室主任、首席科学家，清华大学惠妍讲席教授，衔远科技创始人周伯文在WAIC 2024全体会议上发表演讲。

AI安全与性能可否兼得？演讲中，他提出一个技术主张：探索人工智能45°平衡律——Towards AI-45°Law，即AI安全优先，又能保证AI性能长期发展的技术体系。

![](https://image.3001.net/images/20240704/1720083704_668664f80444634a99c15.jpg!small)以下为演讲全文：

尊敬的各位领导，各位嘉宾，大家上午好，非常荣幸在WAIC大会上、在上海，与大家分享人工智能安全的前沿技术话题，我想提出一个技术主张：探索人工智能45°平衡律——Towards AI-45°Law。
当前，以大模型为代表的生成式人工智能快速发展，但随着能力的不断提升，模型自身及其应用也带来了一系列潜在风险的顾虑。

从公众对AI风险的关注程度来看，首先是数据泄露、滥用、隐私及版权相关的内容风险；其次是恶意使用带来伪造、虚假信息等相关的使用风险；当然也诱发了偏见歧视等伦理相关问题；此外还有人担心：人工智能是否会对就业结构等社会系统性问题带来挑战。在一系列关于人工智能的科幻电影中，甚至出现了AI失控、人类丧失自主权等设定。

这些由AI带来的风险已初露端倪，但更多的是潜在风险，防范这些风险需要各界共同努力，需要科学社区做出更多贡献。

去年5月，国际上数百名AI科学家和公众人物共同签署了一份公开信《Statement of AI Risk》，表达了对AI风险的担忧，并呼吁，应该像对待流行病和核战争等其他大规模的风险一样，把防范人工智能带来的风险作为全球优先事项。

出现对这些风险担忧，根本原因是我们目前的AI发展是失衡的。

先让我们来看一下目前的AI发展趋势：在Transformer为代表的基础模型架构下，加以（大数据-大参数量与大计算）的尺度定律（Scaling Law），目前AI性能呈指数级增长。

与此形成对比的是，在AI安全维度典型的技术，如：红队测试、安全标识、安全护栏与评估测量等，呈现零散化、碎片化，且后置性的特性。

最近的一些对齐技术兼顾了性能和安全性。比如：监督式微调SFT、人类反馈的强化学习RLHF等技术，RLAIF、SuperAlignment等。这些方法帮助将人类的偏好传递给AI，助推涌现出了ChatGPT、GPT-4等令人兴奋的AI系统，以及我们上海AI实验室的书生Intern大模型等等。虽然瞄准的是安全和性能同时提升，但这些方法在实际使用中往往还是性能优先。

所以总体上，我们在AI模型安全能力方面的提升，还远远落后于性能的提升，这种失衡导致AI的发展是跛脚的，我们称之为Crippled AI。

不均衡的背后是二者投入上的巨大差异。如果对比一下，从研究是否体系化，以及人才密集度、商业驱动力、算力的投入度等方面来看，安全方面的投入是远远落后于AI能力的。

**实现安全与性能共同增长的“AI-45°平衡律”**

智能向善，要确保AI可控，统筹发展与安全。毫无疑问地，我们要避免这样的Crippled AI发展，我们应该追求的是：TrustWorthy AGI，可信的AI，可信的通用人工智能。

可信AGI需要能够兼顾安全与性能，我们需要找到AI安全优先，但又能保证AI性能长期发展的技术体系。我们把这样一种技术思想体系叫做“AI-45°平衡律” （AI-45° Law）。

AI-45°平衡律是指从长期的角度来看，我们要大体上沿着45度安全与性能平衡发展，平衡是指短期可以有波动，但不能长期低于45°（如同现在），也不能长期高于45度（这将阻碍发展与产业应用）。这个技术思想体系要求强技术驱动、全流程优化、多主体参与以及敏捷治理。

实现AI-45°平衡律也许有多种技术路径。我们上海AI实验室最近在探索一条以因果为核心的路径，我们把它取名为：可信AGI的“因果之梯”，致敬因果推理领域的先驱——图灵奖得主Judea Pearl。

可信AGI的“因果之梯”将可信AGI的发展分为三个递进阶段：泛对齐、可干预、能反思。

“泛对齐”主要包含当前最前沿的人类偏好对齐技术。但需要注意的是，这些安全对齐技术仅依赖统计相关性而忽视真正的因果关系，可能导致错误推理和潜在危险。一个典型的例子是巴甫洛夫的狗：当狗仅仅基于铃声和食物的统计相关性形成条件反射时，它可能在任何听到铃声的场合都触发行为分泌唾液——如果这些行为涉及到……时这显然是不安全的。

“可干预”主要包含通过对AI系统进行干预，探究其因果机制的安全技术，例如人在回路、机械可解释性，以及我们提出的对抗演练等，它以通过提高可解释性和泛化性来提升安全性，同时也能提升AI能力。

“能反思”则要求AI系统不仅追求高效执行任务，还能审视自身行为的影响和潜在风险，从而在追求性能的同时，确保安全和道德边界不被突破。这个阶段的技术，包括基于价值的训练、因果可解释性、反事实推理等。

目前，AI安全和性能技术发展主要停留第一阶段，部分在尝试第二阶段，但要真正实现AI的安全与性能平衡，我们必须完善第二阶段并勇于攀登第三阶段。沿着可信AGI的“因果之梯”拾级而上，我们相信可以构建真正可信AGI，实现人工智能的安全与卓越性能的完美平衡。

最终，像安全可控的核聚变技术为全人类带来清洁、丰富的能源一样，我们希望通过深入理解AI的内在机理和因果过程，从而安全且有效地开发和使用这项革命性技术。

也正如可控核聚变对全人类都是共同利益一样，我们坚信AI的安全也是全球性的公共福祉，刚刚在发布的《人工智能全球治理上海宣言》中提到“要推动各国加强交流和对话”，我们愿与大家一起携手推进AI-45°平衡律的发展，共享AI安全技术、加强全球AI安全人才交流与合作，平衡AI安全与能力的投入，共同构建开放、安全的通用人工智能创新生态和人才发展环境。

谢谢大家！

文章来源于互联网

# 人工智能

本文为 独立观点，未经授权禁止转载。
如需授权、对文章有疑问或需删除稿件，请联系 FreeBuf
客服小蜜蜂（微信：freebee1024）

被以下专辑收录，发现更多精彩内容

+ 收入我的专辑

+ 加入我的收藏

展开更多

相关推荐

![]()

关 注

* 0 文章数
* 0 关注者

![](/images/logo_b.png)

本站由阿里云 提供计算与安全服务

### 用户服务

* [有奖投稿](https://www.freebuf.com/write)
* [提交漏洞](https://www.vulbox.com/bounties/detail-72)
* [参与众测](https://www.vulbox.com/projects/list)
* [商城](https://shop.freebuf.com)

### 企业服务

* [安全咨询](https://company.freebuf.com)
* [产业全景图](https://www.freebuf.com/news/307349.html)
* [企业SRC](https://www.vulbox.com/service/src)
* [安全众测](https://www.vulbox.com/)

### 合作信息

* [斗象官网](https://www.tophant.com/)
* [广告投放](https://www.freebuf.com/articles/444331.html)
* [联系我们](https://www.freebuf.com/articles/444332.html)

### 关于我们

* [关于我们](https://www.freebuf.com/news/others/864.html)
* 微信公众号
* [新浪微博](http://weibo.com/freebuf)

### 战略伙伴

* [![](https://image.3001.net/images/20191017/1571306518_5da83c1686dd9.png)](http://www.aliyun.com/?freebuf)

### FreeBuf知识大陆

![](https://image.3001.net/images/20250703/1751535036_68664dbcae34ac40bb9e7.png)

扫码把安全装进口袋

* [斗象科技](https://www.tophant.com/)
* [FreeBuf](https://www.freebuf.com)
* [漏洞盒子](https://www.vulbox.com/)
* [斗象智能安全](https://ai.tophant.com/)
* [免责条款](https://www.freebuf.com/dis)
* [协议条款](https://my.freebuf.com/AgreeProtocol/duty)

Copyright © 2025 WWW.FREEBUF.COM All Rights Reserved
[沪ICP备2024099014号](https://beian.miit.gov.cn/#/Integrated/index) | [沪公安网备
![](https://image.3001.net/images/20200106/1578291342_5e12d08ec2379.png)](http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=31011502009321)