---
title: Amplifying AI Readiness in the DoD Workforce
url: https://insights.sei.cmu.edu/blog/amplifying-ai-readiness-in-the-dod-workforce/
source: SEI Blog
date: 2025-06-24
fetch_date: 2025-10-06T22:55:28.400322
---

# Amplifying AI Readiness in the DoD Workforce

icon-carat-right

menu

search

cmu-wordmark

[Carnegie Mellon University](https://www.cmu.edu)

[Software Engineering Institute](https://www.sei.cmu.edu)

[SEI Blog](/blog/)

1. [Home](/)
2. [Publications](/publications/)
3. [Blog](/blog/)
4. Amplifying AI Readiness in the DoD Workforce

[ ]

### Cite This Post

×

* [AMS](#amsTab)
* [APA](#apaTab)
* [Chicago](#chicagoTab)
* [IEEE](#ieeeTab)
* [BibTeX](#bibTextTab)

AMS Citation

Keylor, E., Beveridge, R., and Frederick, J., 2025: Amplifying AI Readiness in the DoD Workforce. Carnegie Mellon University, Software Engineering Institute's Insights (blog), Accessed October 3, 2025, https://doi.org/10.58012/wznp-y412.

Copy

APA Citation

Keylor, E., Beveridge, R., & Frederick, J. (2025, June 23). Amplifying AI Readiness in the DoD Workforce. Retrieved October 3, 2025, from https://doi.org/10.58012/wznp-y412.

Copy

Chicago Citation

Keylor, Eric, Robert Beveridge, and Jonathan Frederick. "Amplifying AI Readiness in the DoD Workforce." *Carnegie Mellon University, Software Engineering Institute's Insights (blog)*. Carnegie Mellon's Software Engineering Institute, June 23, 2025. https://doi.org/10.58012/wznp-y412.

Copy

IEEE Citation

E. Keylor, R. Beveridge, and J. Frederick, "Amplifying AI Readiness in the DoD Workforce," *Carnegie Mellon University, Software Engineering Institute's Insights (blog)*. Carnegie Mellon's Software Engineering Institute, 23-Jun-2025 [Online]. Available: https://doi.org/10.58012/wznp-y412. [Accessed: 3-Oct-2025].

Copy

BibTeX Code

@misc{keylor\_2025,
author={Keylor, Eric and Beveridge, Robert and Frederick, Jonathan},
title={Amplifying AI Readiness in the DoD Workforce},
month={{Jun},
year={{2025},
howpublished={Carnegie Mellon University, Software Engineering Institute's Insights (blog)},
url={https://doi.org/10.58012/wznp-y412},
note={Accessed: 2025-Oct-3}
}

Copy

# Amplifying AI Readiness in the DoD Workforce

![Headshot of Erik Keylor](/media/images/Keylor_Eric_075_241001.max-180x180.format-webp.webp)
![Headshot of Robert Beveridge.](/media/images/Beveridge_Robert_217_230111.max-180x180.format-webp.webp)

###### [Eric Keylor](/authors/eric-keylor), [Robert W. Beveridge](/authors/robert-beveridge), and [Jonathan Frederick](/authors/jonathan-frederick)

###### June 23, 2025

##### PUBLISHED IN

[Artificial Intelligence Engineering](/blog/topics/artificial-intelligence-engineering/)

##### CITE

<https://doi.org/10.58012/wznp-y412>

Get Citation

##### SHARE

AI readiness is [an established priority](https://www.dafcio.af.mil/Portals/64/TMF%20032424%20%28FINAL%20CFM%29_031224%20Update.pdf) for the Department of Defense workforce, including preparation of the workforce to use and integrate data technologies and artificial intelligence capabilities into professional and warfighting practices. One challenge with identifying workers trained in data/AI areas is the lack of formal certifications held by workers. Workers can develop relevant knowledge and skills using non-traditional learning paths, and as a result civilian and federal organizations can overlook qualified candidates. Workers may choose to cultivate expertise on their own time with online resources, personal projects, books, etc., so that they are prepared for open positions even when they lack a degree or other traditional certification.

The SEI’s [Artificial Intelligence Division](https://insights.sei.cmu.edu/divisions/artificial-intelligence-division/) is working to address this challenge. We recently partnered with the [Department of the Air Force Chief Data and AI Office (DAF CDAO)](https://www.dafcio.af.mil/) to develop a strategy to identify and assess hidden workforce talent for data and AI work roles. The collaboration has had some significant results, including (1) a Data/AI Cyber Workforce Rubric (DACWR) for assessment of skills identified within the DoD Cyberworkforce Framework, (2) prototype assessments that capture a data science pipeline (data processing, model creation, and reporting), and (3) a proof-of-concept platform, SkillsGrowth, for workers to build profiles of their expertise and assessment performance and for managers to identify the data/AI talent they need. We detail below the benefits of these outcomes.

## A Data/AI Cyber Workforce Rubric to Increase Usability of the DoD Cyber Workforce Development Framework

The [DoD Cyber Workforce Framework (DCWF)](https://public.cyber.mil/wid/dcwf/) defines data and AI work roles and “establishes the DoD’s authoritative lexicon based on the work an individual is performing, not their position titles, occupational series, or designator.” The DCWF provides consistency when defining job positions since different language may be used for the same data and AI academic and industry practices. There are 11 data/AI work roles, and the DCWF covers a wide range of AI disciplines (AI adoption, data analytics, data science, research, ethics, etc.), including the knowledge, skills, abilities, and tasks (KSATs) for each work role. There are 296 unique KSATs across data and AI work roles, and the number of KSATs per work role varies from 40 (data analyst) to 75 (AI test & evaluation specialist), where most KSATs (about 62 percent) appear in a single work role. The KSAT descriptions, however, do not distinguish levels of performance or proficiency.

The data/AI cyber workforce rubric that we created builds on the DCWF, adding levels of proficiency, defining *basic*, *intermediate*, *advanced*, and *expert* proficiency levels for each KSAT.

[![figure1_06242025](/media/images/figure1_06242025.max-1280x720.format-webp.webp)](/media/images/figure1_06242025.original.png)

Figure 1: An Excerpt from the Rubric

Figure 1 illustrates how the rubric defines acceptable performance levels in assessments for one of the KSATs. These proficiency-level definitions support the creation of data/AI work role-related assessments ranging from traditional paper-and-pencil tests to multimodal, simulation-based assessments. The rubric supports the DCWF to provide measurement options of professional practice in these work roles while providing flexibility for future changes in technologies, disciplines, etc. Measurement against the proficiency levels can give workers insight into what they can do to improve their preparation for current and future jobs aligned with specific work roles. The proficiency-level definitions can also help managers evaluate job seekers more consistently. To identify hidden talent, it is important to characterize the state of proficiency of candidates with some reasonable precision.

## Addressing Challenges: Confirming What AI Workers Know

Potential challenges emerged as the rubric was developed. Workers need a means to demonstrate the ability to apply their knowledge, regardless of how it was acquired, including through non-traditional learning paths such as online courses and on-the-job skill development. The assessment process and data collection platform that supports the assessment must respect privacy and, indeed, anonymity of candidates – until they are ready to share information regarding their assessed proficiency. The platform should, however, also give managers the ability to locate needed talent based on demonstrated expertise and career interests.

This led to the creation of prototype assessments, using the rubric as their foundation, and a proof-of-concept platform, SkillsGrowth, to provide a vision for future data/AI talent discovery. Each assessment is given online in a learning management system (LMS), and each assessment groups sets of KSATs into at least one competency that reflects daily professional practice. The purpose of the competency groupings is pragmatic, enabling integrated testing of a related collection of KSATs rather than fragmenting the process into individual KSAT testing, which could be less efficient and require more resources. Assessments are intended for basic-to-intermediate level proficiency.

## Four Assessments ...