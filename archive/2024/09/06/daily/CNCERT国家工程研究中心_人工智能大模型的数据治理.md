---
title: 人工智能大模型的数据治理
url: https://mp.weixin.qq.com/s?__biz=MzUzNDYxOTA1NA==&mid=2247546770&idx=1&sn=6ce072567d9a1b57e1aac942558ee1b3&chksm=fa938153cde40845ae7ce589a173ba03b0f4e1ecb821a1404c40023d845e7234be23e47ff83f&scene=58&subscene=0#rd
source: CNCERT国家工程研究中心
date: 2024-09-06
fetch_date: 2025-10-06T18:27:57.244636
---

# 人工智能大模型的数据治理

![cover_image](https://mmbiz.qpic.cn/mmbiz_jpg/GoUrACT176lJAmZkIgtjYeooEmhZq2ju8SfRpI1YcUCnL8ETlqOiakpOUCaQfeiab8eU2HicIvuEicJktVDNw6kDsA/0?wx_fmt=jpeg)

# 人工智能大模型的数据治理

网络安全应急技术国家工程中心

以下文章来源于信息安全与通信保密杂志社
，作者Cismag

![](http://wx.qlogo.cn/mmhead/Q3auHgzwzM57SpaEcnib8NMGibzYLk6p0uOuGZThgJsy6XBtuoV6SmKQ/0)

**信息安全与通信保密杂志社**
.

网络强国建设的思想库、安全产业发展的情报站、创新企业腾飞的动力源

**摘要：**为提高人工智能大模型全生命周期的价值和性能，推动大模型在各行各业落地应用，需要把以数据为中心的人工智能理念和技术贯穿于大模型全生命周期。在分析大模型数据治理的内涵特征、必要性、特殊性及重点内容等基础上，针对大模型的规划设计、预训练、评估、部署推理、运维监控、退役（迭代）等全生命周期关键阶段，分阶段确定数据治理的框架、对象、重点任务和技术策略，以期为大模型的数据治理提供全景式的逻辑框架和全流程的技术参考。

# **0、引言**

人工智能大模型从开发到退役迭代是周期较长的复杂系统工程，数据是人工智能大模型的基石，贯穿大模型全生命周期始终。已有研究表明，系统有效的数据治理可提高大模型全生命周期的价值和性能。

近年来，国内外学术界围绕提升大模型性能，先后提出了以模型为中心的人工智能
（Model-Centric AI）和以数据为中心的人工智能（Data-Centric AI）。对于人工智能大模型在银行等具体场景的开发应用而言，更多是采用成熟的大模型进行评测、训练改进和微调等，对大模型算法架构等改动较少，大模型落地性能及效果更大程度上依赖于行业领域及场景相关的数据状况，因此，更需落实以数据为中心的人工智能。大模型与数据关系甚为密切，贯穿于大模型全生命周期。例如，在大模型预训练阶段，海量数据为模型提供了丰富的学习材料，帮助模型发现数据中的模式、特征和规律。随着大模型参数量的增加，其对预训练数据量的需求也随之增长。例如，最新的 GPT-4 大模型具有1.8万亿参数，训练数据高达13万亿个token。大模型训练数据不仅要规模庞大，还要求类型多样、情境覆盖广泛，这样训练出的大模型才具备更好的泛化能力。

本文力图阐明大模型数据治理的必要性和特殊性，把以数据为中心的人工智能贯穿到大模型全生命周期，指出涉及的重要维度，分析大模型数据治理的重点内容和策略技术，希望为面向大模型开发应用的数据治理提供全景式的参考。

# **1、大模型和数据治理**

**1.1　大模型**

人工智能大模型是当前人工智能领域的热门研究方向和技术趋势，它们通过整合大量数据、算法和算力，在多个下游任务上实现性能显著提升和高效通用化应用，通常具有庞大的参数规模和训练数据量级，核心在于能够处理和理解大量未标记数据，通过预训练和微调等方式在自然语言处理、计算机视觉、内容生成等任务上达到良好性能。

人工智能大模型开发应用是一个长期复杂的工程，如OpenAI公司的生成式预训练变换器
（Generative Pre-trained Transformer，GPT）系列大模型，从规划设计到应用再到迭代升级，前后时间跨度近10年。这一过程不仅耗资巨大、技术复杂，还涉及数据、通信等多领域技术交叉融合。因此，树立全生命周期理念对确保大模型的高效开发、部署应用和维护升级等至关重要。国际标准化组织和国际电工委员会提出人工智能系统全生命周期概念，包括发起、设计开发、验证和确认、部署、运行与监控、持续验证、重新评估、退役迭代等重点步骤。基于上述全生命周期概念和银行大模型开发实践，可把大模型生命周期划分为6个重点环节：规划设计阶段、预训练阶段、评测阶段、部署推理阶段、运维监控阶段和退役迭代阶段。

**1.2　数据治理**

学术界、产业界认为数据治理是一个复杂的系统工程。企业等数据主体通过制定一系列围绕数据的管理与开发机制、政策，组织实施与数据的收集、存储、处理、加工、维护等有关的技术性活动，系统化提高数据的数量、质量，以确保数据的准确性、可靠性、及时性、安全性、合规性和共享性，推动数据共享和充分利用，实现数据价值最大化。

**1.3　大模型数据治理**

结合银行大模型设计开发及数据治理实践，人工智能大模型的数据治理是指在大模型整个生命周期中，对数据的收集、处理、存储、使用、保护和废弃等各个环节进行规划、监控和控制的过程，其目的是确保数据的高质量、安全合规、有效利用，进而支持大模型的持续优化与可信应用。

大模型数据治理不仅仅是对大模型某个开发应用阶段的数据治理，还是对大模型开发应用等整个生命周期进行的数据治理。落实以数据为中心的人工智能，在大模型规划设计阶段，
进行数据需求分析、数据策略制定、数据架构设计等数据治理任务；在大模型预训练阶段，进行数据清洗标注、数据安全与隐私保护、优化数据的多样性与代表性、优化数据集的配比结构等数据治理任务；在大模型评测阶段，根据模型任务目标和应用领域，进行评测数据建设和选择、评测数据迭代更新等数据治理任务；在大模型部署推理阶段，为激发模型潜在性能，进行指令数据集构造、数据流监控、实时数据处理等数据治理任务；在大模型运维和监控阶段，持续进行数据质量监控、数据合规性审计等数据治理任务；在大模型退役迭代阶段，进行数据归档与销毁、迭代数据准备等数据治理任务。

# **2、大模型数据治理的必要性、特殊性和重点**

**2.1　大模型数据治理的必要性**

数据治理在大模型全生命周期中扮演着基石角色，通过数据治理确保数据的高质量、安全、合规和高效利用，为大模型的成功训练、部署和持续优化提供支撑，也为数据价值充分释放、大模型达到预期性能及安全合规使用夯实
基础。

**2.1.1　提升数据数量质量，确保模型性能**

数据不仅是大模型训练的“燃料”，更是模型性能提升的决定性因素之一。数据的数量、质量和多样性共同决定了大模型的上限，是其能够实现各种高级认知任务的基础。经过精心治理的数据集能更好地反映真实世界的多样性，帮助模型在不同场景下都能有良好的表现，增强模型的泛化能力。清晰、规范化的数据治理流程有助于构建可追溯的数据链路，这对于理解模型决策过程、提升模型的可解释性至关重要。数据治理还包括对模型反馈数据的管理和分析，这有助于及时发现模型在实际应用中的不足，为模型的持续优化和迭代提供依据。

**2.1.2　减少偏差和偏见，保障模型安全与合规**

数据中的偏差和偏见会直接影响模型的决策结果，导致不公平或错误的判断。通过数据治理，可以识别并纠正数据中的偏差，确保模型的输出更加公正、可靠，符合伦理和法律要求。数据治理还包括对数据的合法合规使用，尤其是在涉及个人隐私和敏感信息时。有效的数据治理策略能够确保数据处理过程和大模型开发应用全过程符合相关法律法规，避免数据泄露或滥用的风险，保护用户隐私。

**2.1.3　优化数据生命周期管理，充分释放数据价值效能**

从数据的收集、存储、处理到模型训练、评估和部署，每个阶段都需要有效的数据治理。这有助于提高数据利用效率，最大限度实现数据的价值，减少不必要的存储和计算成本，同时确保模型训练过程的高效和可持续性。

**2.2　大模型数据治理的特殊性**

大模型的数据治理在数据规模、动态性、可解释性等方面提出了更高的要求，需要更为精细化和智能化的治理策略，相较于普遍意义上的数据治理，具有以下特殊性。

**2.2.1　数据的海量规模与复杂性**

大模型训练往往需要海量数据，数据规模远超传统应用场景，这要求数据治理方案必须具备高效处理大规模数据的能力，包括数据的存储、处理、分析和传输。同时，数据类型和来源的多样性增加了数据治理的复杂度，需要更有效的数据整合与管理策略。

**2.2.2　数据持续迭代与动态性**

大模型的训练和应用是一个持续迭代的过程，模型在部署后的使用中还会产生新的数据反馈，这些反馈数据需要被纳入模型的持续优化中。因此，数据治理不仅要考虑初始训练数据的管理，还要涵盖模型运行期间的实时数据处理和周期性数据更新。

**2.2.3　数据对模型性能的高度影响性**

大模型的性能高度依赖于数据质量，即使是少量的噪声数据也可能对模型性能造成显著影响。因此，数据治理必须实施更为严格的数据质量控制，包括精确的数据清洗、去重、去噪，以及对数据偏见和不一致性进行校正。

**2.2.4　数据对模型可解释性和监管合规的高度关联性**

大模型的黑盒特性要求数据治理不仅关注数据本身，还要考虑如何通过数据治理提高模型的可解释性，以满足监管要求和公众的透明度期望。

**2.3　大模型数据治理的重点**

**2.3.1　以模型为中心的AI与以数据为中心的AI**

以模型为中心的AI通常把数据置于从属地位，注重对模型的类型、架构、算法和超参数选择和改进，以构建高效能的大模型AI系统。以数据为中心的AI则选择适合数据的算法模型，强调系统化设计数据，实现数据工程化，改善数据质量和数量以提高大模型AI系统的性能。尽管两者存在差异，但数据和模型两者缺一不可、相辅相成，它们在开发AI大模型时应融合使用。

**2.3.2　数据数量与数据质量**

以数据为中心的AI强调扩充数据以获取更多的数据、精炼数据以获取质量更高的数据 。其中，扩充数据是指广泛获取额外数据以填补数据集中的“盲点”，从而满足具体业务应用要求，并应对数据分布的变化，维持模型性能。精炼数据是指系统提升已有数据的质量，如改善特征或标注的质量、增加高相关实例的数量、识别和移除低质量样本，使模型更好地泛化，
以提高性能和可靠性。可见，数据的数量和质量是一体两面的关系，数据治理应追求实现更多、更好的数据。

**2.3.3　自动化数据治理技术与人工参与**

自动化技术可提高数据治理的效率和准确性。例如，在数据维护方面，用自动化进行质量改进、数据验证模块训练大模型来识别潜在问题。人工参与数据治理可分为人工全面参与、人工部分参与和人工最低参与3种情形。人工全面参与是人工完全控制数据治理整个过程，自动化方法辅助人工做决策，如数据清洗和特征提取；人工部分参与是用自动化方法控制过程，但需人工提供大量反馈或频繁交互，如数据标注；人工最低参与是由自动化方法完全控
制整个过程，只在需要时咨询人类，如数据合成。上述3种情形反映效率（减少人力）和效果（更
符合人类意图）之间的权衡，而自动化技术及人工参与程度的选择取决于大模型应用领域和利益相关者对效率、效果的需求。

**2.3.4　个体、组织与跨组织层面的数据治理**

在个体层面，大模型全生命周期的数据治理过程需较多的人工参与，甚至部分个体在数据治理方面发挥重要作用，大模型各阶段的数据治理有所侧重，但都需数据专家与开发人员、领域专家等深度互动，数据对大模型的影响最终取决于个体实施数据治理的成效。在组织层面，监控数据质量是组织的关键任务，研究表明，大模型性能受数据完整性、特征和标签准确性等影响，因此需整个组织从全流程确保数据质量。在跨组织层面，大模型涉及的数据来源经常是跨组织的，数据理解和数据准备需要不同组织实体之间的分布式协作。为实现跨组织的数据准备，不同组织间需要就数据处理达成共识标准，如统一数据处理的编码环境及版本控制。可见，数据治理贯穿个体、组织、跨组织多个层级，因此针对大模型全生命周期的数据治理需统筹好个体、组织和跨组织的协同。

# **3、大模型数据治理的阶段性重点任务**

大模型开发应用周期长，分为6个重点阶段，数据治理不是一蹴而就的，不能仅针对大模型开发应用中个别环节或阶段进行，而需要遵循全生命周期的理念，按照系统化、流程化的技术逻辑有序开展，只有通过系统化地加强数据治理，才能充分发挥数据和大模型应有的价值和作用。大模型数据治理流程如图 1 所示。

![](https://mmbiz.qpic.cn/sz_mmbiz_png/iclynibMMTgBwqibPaRHPFNY3QJ6bxXNLcz4oJx0BNpVj4xZ0iaSU7GqLWRh0VCsrU4rExseOhBLudGWYEoJQIppmA/640?wx_fmt=other&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

图 1　大模型数据治理流程

**3.1　大模型规划设计阶段要建立数据治理框架**

大模型规划设计之初，需根据大模型的任务定位、功能要求等建立全面的数据治理框架，包括开展数据需求分析、确立数据治理技术框架。

**3.1.1　开展数据需求分析**

明确数据的类型、来源、规模和质量要求，是大模型设计的基础。良好的数据需求分析结合源数据、专业领域的数据治理，能够帮助准确识别大模型研发所需的数据特征，避免后期因数据不足或不匹配导致的大模型性能问题。

**3.1.2　确立数据治理技术框架**

以数据为中心，将大模型全生命周期和数据全生命周期结合起来，建立数据治理框架，确保数据收集、处理、使用的全过程符合法律法规和伦理标准，以预防数据质量数量等方面的潜在问题，防控数据偏见和隐私泄露风险。

**3.2　大模型预训练阶段要对预训练数据进行治理**

预训练数据是大模型训练的基础，大模型的性能受其质量和数量影响最大 。预训练数据数量庞大，其治理涵盖的环节较多，包括数据收集、标注、准备、降维、增强和版本控制等。

**3.2.1　数据收集**

重视专业领域知识的收集，有助于收集相关领域数据和有代表性的数据，确保数据与大模型的设计规划目标等保持一致。高效数据收集策略包括数据集发现、数据集成和数据合成等。其中，数据集发现通过查询已有相关数据源，构建新的数据集，减少人力成本，提高数据收集效率。数据集成可借助机器学习技术，旨在把不同来源的数据合并为一个统一的数据集。数据合成则生成包含所需模式的数据集，如合成异常模式数据。

**3.2.2　数据标注**

数据标注覆盖如下重点：发挥专业领域知识的作用、平衡标注质量和数量、考虑标注过程中的主观性和伦理等。首先，要深入了解大模型的应用领域，确保收集到的数据具有相关性、多样性和代表性；其次，标注过程要平衡标注质量、标注数量和财务成本，并借助专业领域知识进行考量，监控标注过程中的主观性
（标注人员可能误解指导说明，产生标注噪声）；最后，还需考虑伦理，特别是在标注任务分配给大量不特定人群时，要重视数据隐私和偏见等问题。

**3.2.3　数据准备**

数据准备涵盖数据清洗、特征提取和特征转换。其中，数据清洗涉及识别和纠正数据集中的错误、不一致性和不准确性，通过程序化软件工具或机器学习方法修复数据。特征提取是从原始数据提取相关特征值，可手动提取特
征，也可利用深度学习方法自动提取特征。特征转换将原始特征转换为新特征，常用方法有归一化、标准化、对数转换和多项式转换等。

**3.2.4　数据降维**

数据降维是将高维数据映射到低维空间，以保留数据关键信息并降低数据的复杂性，通常以减少特征数量或样本数量来实现。降维方法有特征选择和维度压降两种策略。其中，特征选择是指采用过滤、包装和嵌入等方法，选择与任务相关的特征子集。维度压降是将高维特征转换到低维空间，主要方法有线性技术和非线性技术。线性技术通过线性组合原始数据的特征生成新的特征，如主成分分析。非线性技术则利用非线性映射函数，如自动编码器将原始特征编码为低维空间并使用神经解码器重构特征。

**3.2.5　数据增强**

数据增强主要包括基本操作和数据合成。其中，基本操作是对原始数据进行轻微修改以直接生成增强样本，如缩放、旋转、翻转和模糊化等方法。数据合成则通过学习现有数据的分布来合成新的训练样本，一般通过生成建模实现。生成对抗网络被广泛用于数据增强，通过训练鉴别器和生成器，生成与现有数据相似的合成数据。相比于基本操作，数据合成从全局视角学习数据模式，并使用学习模型生成新样本。

**3.2.6　数据版本控制**

数据版本控制的重点内容包括：一是加强元数据管理。详细记录各数据版本的元数据（数据集来源、处理步骤、质量评估指标、修改日期、修改人等信息），并与数据版本一起存储，以便查询分析。二是实现数据回滚与分支管理。允许在发现问题或需要回溯时快速恢复到先前的数据版本，利用分支机制支持对新数据集或数据处理方法的实验，不影响主数据流的稳定性。三是建立全面的文档。明确数据版本控制的流程、最佳实践和工具使用指南。四是提升数据版本控制意识。定期进行培训，确保参与预训练数据治理的每个人都了解数据治理的重要性并能有效执行。

**3.3　大模型评测阶段要对评测数据进行治理**

评测数据是开展大模型评测的基础，而评测数据治理是一项重要的基础性工作，对评估或优化大模型的性能起着锚定作用，具体包括开展同分布评测、异分布评测及相关评测数据集的治理。

**3.3.1　同分布评测**

同分布评测是评估大模型性能效果的最直接方式，即在与预训练数据相同分布的数据集上评估大模型的推理能力，有助于发现模型在特定数据子集上表现不佳的情况，从而通过识别和校准相应的子数据集，以避免偏见和错误。同分布评测需对评测数据进行数据切片，即将评测数据集划分为相关子集，并分别评估大模型在每个子集上的性能，有助于发现大模型在哪些切片上表现不佳。常见的数据切片方法使用预定义的标准，如年龄、性别或种族。自动化切片方法可提高切片效率，在数据空间中筛选所有潜在的切片，以识别重要的数据切片。

**3.3.2　异分布评测**

大模型在部署环境中可能会遇到与预训练数据不同的数据分布，因此需要评估大模型在意外情况下的泛化能力。生成对抗样本，有助于了解模型的鲁棒性，特别是当训练和部署数据环境之间存在分布差异时，生成具有分布偏移的样本，有助于评估模型在不同分布上的表现。

**3.3.3　评测数据集治理**

评测数据集是优化模型性能的基准，也是评估和比较不同模型性能的重要工具。评测数据集的治理重点包括：一是数量和质量。目前评测数据集无论从类型上还是从数量上都相对较少，大模型开发应用进入快速发展阶段，需建立数量质量标准，丰富评测数据集的类型并提升评测数据集数量质量。二是多样性和代表性。高阶多数据集建模的研究表明，利用多模态、多类型的数据集能更有效解决传统数据处理和分析方法失效的问题，在设计评测数据集时，应尽可能考虑数据的多样性和代表性，确保在多种不同场景下有效评估模型。三是性能数据记录。系统性地管理模型评估数据，以分析模型在不同数据子集上的差异表现，指导后续调优工作。

**3.4　大模型部署推理阶段要对部署与推理数据进行治理**

部署与推理阶段涉及的输入输出数据数量很大，是大模型全生命周期数据治理的重点，包括对部署数据、指令数据集、偏好数据集、强化学习数据集、提示工程数据、运维监控数据等的治理。

**3.4.1　部署数据的治理**

着眼于保障大模型服务的高效性和安全合规性，综合采取以下技术措施：一是建立高效的数据接入与预...