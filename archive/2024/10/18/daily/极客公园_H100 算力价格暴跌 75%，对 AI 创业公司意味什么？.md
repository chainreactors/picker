---
title: H100 算力价格暴跌 75%，对 AI 创业公司意味什么？
url: https://mp.weixin.qq.com/s?__biz=MTMwNDMwODQ0MQ==&mid=2653059447&idx=1&sn=5979ff435afa1e0265df55880a921260&chksm=7e5704c149208dd7e8e871c772f96b99fa93434d35d56183083d4ed296e7c15adc10eee351f6&scene=58&subscene=0#rd
source: 极客公园
date: 2024-10-18
fetch_date: 2025-10-06T18:53:30.061407
---

# H100 算力价格暴跌 75%，对 AI 创业公司意味什么？

![cover_image](https://mmbiz.qpic.cn/mmbiz_jpg/8cu01Kavc5YUQQlsaMpaGA7VficUZlaDweNaCYEzvNgXGA5qQic85DI2CAIUAEm3tr17PE8aTl4QvgKWpIGTY7OQ/0?wx_fmt=jpeg)

# H100 算力价格暴跌 75%，对 AI 创业公司意味什么？

Eugene Cheah

极客公园

![](https://mmbiz.qpic.cn/mmbiz_jpg/8cu01Kavc5YUQQlsaMpaGA7VficUZlaDwpQXkBB0vMAVxZ9KpwgEcxOmvC3icrRyWDIyuLAHLic5udrj9VkOutnYA/640?wx_fmt=jpeg)

买不如租

作者 | Eugene Cheah

OneFlow 编译

原标题：2美元/小时出租H100：GPU泡沫破灭前夜

红杉资本的报告曾指出，AI 产业的年产值超过 6000 亿美元，才够支付数据中心、加速 GPU 卡等 AI 基础设施费用。而现在一种普遍说法认为，基础模型训练的资本支出是「历史上贬值最快的资产」，但关于 GPU 基础设施支出的判定仍未出炉，GPU 土豪战争仍在进行。尤其是，以 OpenAI 为代表的大模型公司在训练+推理上的支出超过了收入，最近他们在有史以来最大的风险投资轮中筹集了 66 亿美元，同时预计 2026 年的亏损将达到 140 亿美元。

近期，NVIDIA 的新一代 Blackwell 系列芯片交付给了 OpenAI，他们还表示接下来一年的产品已经售罄，NVIDIA CEO 黄仁勋指出这可能是行业历史上最成功的产品。与此同时，AMD CEO 苏姿丰推出了 MI325X，而**AI 推理芯片公司 Cerebras**提交了 IPO 申请。

随着数十亿美元投入到 AI 基础设施层，这会促进 AI 上层的繁荣还是泡沫？现在，是时候深入探讨 GPU 市场的时候了。

本文作者 Eugene Cheah 深入研究了 H100 市场，可能为即将到来的 Blackwell 芯片的未来走向提供一些参考。他指出，由于预留计算资源的转售、开放模型的微调以及基础模型公司的减少，市场上的 H100 算力已经供过于求，尤其是 H100 从去年以 8 美元/小时到现在多家算力转售商以低于 2 美元/小时的价格出租。经过深度分析后，他建议用户在需要时租用而不是购买算力。

（Eugene Cheah 是 AI 推理服务供应商 Featherless.AI 的联合创始人，也是 RWKV 开源基础模型项目的联合负责人。本文由 OneFlow 编译发布，转载请联系授权。原文：https://www.latent.space/p/gpu-bubble）

**01**

**AI 竞赛简史**

2022 年 11 月 30 日，基于 A100 GPU 系列训练的 GPT3.5 与 ChatGPT 仿佛一夜之间吸引了全世界对 AI 的想象，并开启了 AI 竞赛。2023 年 3 月 21 日，随着惊人的 AI 势头，H100 很快就来了。

如果 OpenAI 可以用「旧」的 A100 构建智能，那么使用新推出的性能高 3 倍、价格多 2 倍的 H100，你也能够构建一个更大、更好的模型，甚至可能超越 OpenAI 率先到达 AGI——如果你的财力比 OpenAI 还雄厚。

第一个成功实现这一目标的 AI 公司，将获得新 AI 经济中的一大块份额——每一个分析师的粗略计算都表明，取代通用的人类智能将意味着数万亿美元的市场。如果能够成功，你将比地球上一半的国家或历史上任何王国都要富有。怀着这样的渴望，有 100 亿到 1000 亿美元的资金投入到 AI 公司和创始人身上，以推动新一轮科技革命，这导致 H100 的需求突然激增。

市场价飙升，H100 的初始租赁价格约为 4.70 美元/小时，但实际价格超过了 8 美元/小时。所有急切的创始人纷纷涌入，急于训练他们的模型，以说服投资者进行下一轮亿级美元的融资。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/lBhAE42wKWpLMjqMYHWw6gE9oWia3LCC40yyJIEciaDc4p6U83pa6SiaVfmb5c7yEwZjAMULawqYbqbjbMVOr6obw/640?wx_fmt=jpeg&from=appmsg)在 2023 年的投资者会议上，英伟达向他们的投资者和数据中心客户推介了以 4 美元/小时的价格出租 H100 的「市场机会」。

对于 GPU 农场来说，这感觉像是不劳而获的钱——如果你能让这些创始人以 4.70 美元/小时或更高的价格租用你的 H100 SXM GPU，甚至让他们提前支付，投资回报期将少于 1.5 年。从那以后，每个 GPU 每年将带来超过 10 万美元的现金流。

由于 GPU 需求似乎没有尽头，他们的投资者同意了，甚至进行了更大规模的投资……

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/lBhAE42wKWpLMjqMYHWw6gE9oWia3LCC4E4ApRcd69icmFq1fUFhLAQKZ4jslPP9IM5q3LrIicz2wiapheAMeRxv6w/640?wx_fmt=jpeg&from=appmsg)《郁金香狂热》——描绘了有记录以来历史上第一次投机泡沫，郁金香价格在 1634 年持续攀升，并于 1637 年 2 月崩盘。

**02**

**六千亿美元的投资之后**

与数字商品不同，实物商品会受到延迟发货的影响，尤其是在多次发货延迟的情况下。2023 年的大部分时间里，H100 的价格感觉会永远高于 4.70 美元/小时以上（除非你愿意支付一大笔预付款）。2024 年初，H100 的价格在多个供应商那里降至大约 2.85 美元/小时。

然而，随着更多供应商的加入……我开始收到这样的邮件：

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/lBhAE42wKWpLMjqMYHWw6gE9oWia3LCC4H8mmTo2j3F5hXZXibibnnBdtMSU1xMWib1iagmdEzmJ1esTxggNcMTtPpw/640?wx_fmt=jpeg&from=appmsg)虽然我未能以 4 美元/小时的价格获得 H100 节点（8 个 H100），但我多次确认，你可以以 8 到 16 美元/小时的价格获得。

2024 年 8 月，如果你愿意竞拍一小段时间的 H100 使用时间（几天到几周），你可以找到 1-2 美元/小时的 H100。

尤其对于小型集群而言，我们正面临着每年至少 40% 的价格下跌。NVIDIA 预测的 4 美元/小时的 GPU 价格在 4 年内保持不变，但不到 1.5 年就烟消云散了。

这非常可怕，因为这意味着有人可能会被套牢——尤其是如果他们刚刚购买了新的 GPU。那么，到底发生了什么？

**03**

**一张 H100 SXM GPU**

**的投资回报率（ROI）**

**是多少？**

这里将重点关注经济成本和租赁的 ROI，对比不同的市场价格，不包括机会成本或业务价值。

在数据中心，平均一张 H100 SXM GPU 的设置、维护和运营成本（即大部分资本支出）为 50000 美元或更多，不包括电费和冷却的运营成本。本文后面将提供更详细的计算方法。

但对今天的单元经济和投资意味着什么？特别是假设 GPU 的使用寿命为 5 年的情况下。

通常，H100 的租赁业务模式有两种，我们将会覆盖这两种模式。

1. **短期按需租赁（按小时、周或月）**
2. **长期租赁（3-5 年）**

**按需租赁的 ROI**

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/lBhAE42wKWpLMjqMYHWw6gE9oWia3LCC4vibvGo6BiaibNT7O797IibQHwZTFbOFFPSnmibKQmo6mSPmEJ8EMziaf5UCQ/640?wx_fmt=jpeg&from=appmsg)

新的 H100 ROI（2024 年 8 月）

总结来说，对于按需工作负载：

* **2.85 美元/小时：**超过股市的内部收益率（IRR）
* **低于 2.85 美元/小时：**低于股市的 IRR
* **低于 1.65 美元/小时：**预期投资亏损

对于上述 ROI 和收入预测，我们引入了「混合价格（blended price）」，假设租赁价格在 5 年内逐步下降 50%。

鉴于我们目前看到的每年价格下降>=40%，这可以被视为一个保守/乐观的估计，但这是一种通过考虑一定比例的价格下降的同时来预测 ROI 的一种方法。

在 4.50 美元/小时的情况下，即使考虑混合价格，我们也能看到 NVIDIA 最初对数据中心提供商的承诺，即在 2 年后几乎可以「印钞」，内部收益率（IRR）超过 20%。

然而，在 2.85 美元/小时的情况下，IRR 刚刚超过 10%。

这意味着，如果你今天购买新的 H100 服务器，并且市场价低于 2.85 美元/小时，你的投资回报率几乎只能勉强与市场基本回报水平持平，并且假设使用率是 100%（这是一个不合理的假设）。任何低于这个价格的情况，作为投资者，投资 H100 基础设施公司不如投资股市。

**如果价格降至 1.65 美元/小时以下，作为基础设施提供商，在 5 年内使用 H100 注定会亏损**，特别是如果你今年刚刚购买了节点和集群。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/lBhAE42wKWpLMjqMYHWw6gE9oWia3LCC4PeOAnJ65q2fV62jsuYbJCFlvqrdiaug6pgkBUwKNoMyzVxSybNj6fYw/640?wx_fmt=jpeg&from=appmsg)

**长期预订租赁（3 年+）**

许多基础设施提供商，尤其是那些较老的公司，并不是对此一无所知——因为他们曾经亲身经历过 GPU 租赁价格在加密货币时代大幅上涨后的急剧跳水，他们已经经历过这种周期。

**因此，在这一周期中，去年他们大力推动 3-5 年的前期承诺和/或支付，价格在 4 美元/小时以上（通常预付 50% 到 100%）。**今天，他们推动的价格范围在 2.85 美元/小时以上，以锁定他们的利润。

这种情况在 2023 年 AI 高峰期尤为明显，尤其是在图像生成领域，许多基础模型公司被迫签订高价的 3-5 年合同，只是为了在新集群客户中排在前面，成为第一个推出目标模型的公司，以促进完成下一轮融资。

这可能不是最经济的举措，但可以让他们比竞争对手更快地行动。

然而，这导致了一些有趣的市场动态——如果你在未来 3 年内以 3 美元或 4 美元/小时的价格签订了合同，那么你将被合同绑定。当模型创建者完成模型训练后，他们不再需要这个集群后会怎么做？——**他们转售并开始收回部分成本。**

**04**

****当前 H100 的价值链****

从硬件到 AI 推理/微调，可以大致分为以下几个方面：

1. **硬件供应商****与 Nvidia 合作**（一次性购买成本）
2. **数据中心基础设施提供商及合作伙伴**（出售长期租赁，包括设施空间和/或 H100 节点）
3. **风险投资基金、大型公司和初创公司**：

   计划构建基础模型（或已经完成模型构建）
4. **算力转售商**：

   如 Runpod、SFCompute、Together.ai、Vast.ai、GPUlist.ai
5. **托管 AI 推理/微调提供商**：

   使用上述资源的组合

虽然堆栈中的任何一层都可能实现垂直整合（例如跳过基础设施提供商），但关键驱动因素是**「未使用算力资源的转售商」**和「足够好」的开放权重模型（如 Llama 3）的兴起，这些因素都是当前 H100 经济压力的主要影响因素。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/lBhAE42wKWpLMjqMYHWw6gE9oWia3LCC4PhzLpiaicyFuSTOibhB5kOD2dlPogEaN5g2tZu20xEbztR4h5heVwgnuA/640?wx_fmt=jpeg&from=appmsg)开放权重模型的兴起，其性能与闭源模型相当，正在导致市场发生根本性的变化。

**05**

****市场趋势：****

****开放权重模型的兴起****

对 AI 推理和微调的需求增加：由于许多「开放」模型缺乏适当的「开源」许可证，但仍然被免费分发和广泛使用，甚至用于商业用途。在这里，我们将统称它们为「开放权重」或「开放」模型。

总体而言，随着各种大小的开放权重模型的不断构建，对这些模型的推理和微调的需求也在增长。这主要由两个重大事件推动：

**1.****GPT-4 级别的开放模型的出现**（例如，4050 亿参数的 LLaMA3，DeepSeek-v2）

**2.****小型（约 80 亿参数）和中型（约 700 亿参数）微调模型的成熟和采用**

如今，对于大多数企业可能需要的用例，已经有现成的开放权重模型。这些模型在某些基准测试中可能略逊于专有模型，但提供了以下优势：

**灵活性**：特定领域/任务的微调。

**可靠性**：不再有小的模型更新导致用例失效（目前，社区对模型权重在没有通知的情况下在公共 API 端点上悄悄更改导致不可解释的效果退化缺乏信任度）。

**安全性和隐私**：确保他们的提示词和客户数据的安全。

所有这些因素都导致了当前开放模型的持续增长和采用，以及对推理和微调需求的增长。

但这确实带来了另一个问题……

**06**

**小型和中型模型创建者的崩溃**

基础模型创建市场萎缩（小型和中型）：我们用「模型创建者」来统称从零开始创建模型的组织。对于微调者，我们称他们为「模型微调者」。

许多企业，以及多个小型和中型基础模型创建初创公司——尤其是那些以「更小、更专业领域模型」为卖点的公司——都是没有长期计划或目标从零开始训练大型基础模型（>= 700 亿参数）的群体。

对于这两个群体，他们都意识到，微调现有的开放权重模型比「自行训练」更经济和高效。

这最终导致了对 H100 需求的三重打击！

**1.****微调比从零开始训练便宜得多**

**微调的计算需求显著较低**（通常需要 4 个节点或更少，通常是一个节点），而从零开始训练则需要 16 个节点或更多（对于 70 亿参数及以上的模型需要更多节点）。

这一行业转变基本上消灭了大量小型集群的需求。

**2.****减少对基础模型的投资（小型和中型）**

2023 年，文本和图像领域出现了大量小型和中型基础模型。

然而，如今，除非你非常有信心能够超越 LLaMA3，或者你带来了新的东西（例如，新的架构、100 倍更低的推理延迟、100 多种语言支持等），否则几乎没有新的基础模型公司从零开始构建模型。

总体而言，大型玩家（如 Facebook 等）创建的小型和中型开放模型，使得小型玩家很难证明训练基础模型的合理性——除非他们有强大的差异化优势（技术或数据）——或者有计划扩展到更大的模型。

这一点在投资者中也有所反映，因为新的基础模型创建者的资金急剧减少。大多数小型团队已经转向微调。（这种情绪与最近多家公司不尽如人意的退出相吻合。）

目前，据我估计，全球大约有：<20 个大型模型创建团队（即 700 亿参数及以上模型，也可能创建小型模型）；<30 个小型/中型模型创建团队（70 亿到 700 亿参数模型）。

总体而言，全球只有不到 50 个团队在任何时间点会需要 16 个节点的 H100（或更多）来进行基础模型训练。

全球有超过 50 个 H100 集群，每个集群拥有超过 16 个节点。

**3.****预留节点的过剩算力资源正在上线**

对于集群所有者，特别是那些在 2023 年初「抢购」中进行了长期租赁的各种基础模型初创公司和风险投资公司。

由于转向微调，以及 H100 交付时需要非常长的等待时间（最高峰时达到 6 个月或更长），许多团队可能在做出改变之前已经支付了预付款，这使得他们的预付硬件「到货即过时」。

另一方面，那些硬件按时到货，用于训练最初几个模型的团队，也意识到最好在下一次迭代中微调模型会更好，而不是自行构建新模型。

在这两种情况下，他们都会有未使用的算力资源，这些过剩资源通过「算力转售商」进入市场供应。

**07**

****导致算力供应增加****

****和训练需求减少****

****的其他因素****

**1.****大型模型创建者离开公共云平台**

另一个主要因素是，所有主要的模型创建者，如 Facebook、X.AI，以及 OpenAI（如果你认为它们是微软的一部分），都在从现有的公共云提供商转向，通过构建自己的数十亿美元规模的集群，从而减少了对现有集群的依赖。

这一转变主要出于以下几个原因：

* 现有的约 1000 节点集群（建造成本超过 5000 万美元）已经不足以训练更大的模型。
* 在数十亿美元的规模上，购买资产（如服务器、土地等）对资产计算更有利，这些资产有账面价值（是公司估值和资产的一部分），而不是纯粹的租赁费用。
* 如果你没有相关的人才（他们有），你可以直接购买小型数据中心公司，这些公司有构建这些集群的专业知识。

随着需求逐渐分阶段减少，这些集群正在进入公共云市场。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/lBhAE42wKWpLMjqMYHWw6gE9oWia3LCC47SMvlIBkNOFqxoYmIB9icTNVekTdNpBS9VPO5xfRYicjnMDvRFeHRZmw/640?wx_fmt=jpeg&from=appmsg)Vast.ai 基本上实行的是自由市场系统，全球的供应商被迫相互竞争。

**2.****未使用/延迟供应的算力上线**

回忆一下 2023 年的 H100 大批量发货延迟，或 6 个月或更长时间？这些延迟的算力供应现在正在上线，同时还有 H200、B200 等芯片。

这还伴随着各种未使用的算力资源上线（来自现有的初创公司、企业或风险投资公司，如前所述）。

这些资源的大部分是通过算力转售商上线的，例如：together.ai、sfcompute、runpod、vast.ai 等。

在大多数情况下，集群所有者拥有的是一个小型或中型集群（通常为 8-64 个节点），这些集群的利用率较低。而购买这些集群的资金已经「花掉」了。

为了尽可能收回成本，他们更愿意以低于市场价的方式保证资源的分配，而不是与主要提供商竞争。

这通常通过固定费率、拍卖系统或自由市场列表等方式实现。后两种方式通常会推动市场价格下降。
...