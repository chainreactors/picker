---
title: From RAGs to Riches: Using LLMs and RAGs to Enhance Your Ops
url: https://trustedsec.com/blog/from-rags-to-riches-using-llms-and-rags-to-enhance-your-ops
source: TrustedSec
date: 2025-02-12
fetch_date: 2025-10-06T20:37:40.832354
---

# From RAGs to Riches: Using LLMs and RAGs to Enhance Your Ops

[Skip to Main Content](#main)

All Trimarc services are now delivered through TrustedSec!
[Learn more](https://trustedsec.com/about-us/news/trimarc-joins-forces-with-trustedsec-to-strengthen-security-advisory-services)

Close

[TrustedSec](https://trustedsec.com/)

* [Solutions](https://trustedsec.com/solutions)

  ## Solutions

  Our custom solutions are tailored to address the unique challenges of different roles in security.

  [Solutions](https://trustedsec.com/solutions)

  + [01

    For Leadership

    We understand the challenges facing modern executives and develop solutions unique to leaders.](https://trustedsec.com/solutions/for-leadership)
  + [02

    For Operations

    We stay one step ahead to proactively safeguard our clients and partners.](https://trustedsec.com/solutions/for-operations)
  + [03

    For Infrastructure

    From architecture to resiliency and maintainability, we keep your tech aligned to best practices.](https://trustedsec.com/solutions/for-infrastructure)
  + [04

    For Assurance

    Our compliance experts guide partners through regulatory requirements to ensure standards are met.](https://trustedsec.com/solutions/for-assurance)
* [Services](https://trustedsec.com/services)

  ## Services

  From building to testing to hardening, our services support security at every stage.

  [Services](https://trustedsec.com/services)

  + [01

    Design

    Design an exceptional, custom security program alongside our security experts.](https://trustedsec.com/services/design)
  + [02

    Evaluate

    Evaluate your security program with proven assessment methodologies.](https://trustedsec.com/services/evaluate)
  + [03

    Harden

    Harden your security program with the help of our security experts.](https://trustedsec.com/services/harden)
  + [04

    Respond

    Respond to threats to your security program with the help of our security experts.](https://trustedsec.com/services/respond)
* [Research](https://trustedsec.com/research)
* [Blog](https://trustedsec.com/blog)
* [Resources](https://trustedsec.com/resources)
* [About Us](https://trustedsec.com/about-us)

  ## About Us

  Driven by purpose, fueled by experts.

  [About Us](https://trustedsec.com/about-us)

  + [01

    Our Team

    Meet our security experts.](https://trustedsec.com/about-us/our-team)
  + [02

    Our Partners

    Become a TrustedSec partner to help your customers anticipate and prepare for potential attacks.](https://trustedsec.com/about-us/our-partners)
  + [03

    News

    Our team is trusted by local and national media to be the subject matter experts for security news.](https://trustedsec.com/about-us/news)
  + [04

    Events

    See our upcoming webinars, conferences, talks, trainings, and more!](https://trustedsec.com/about-us/events)

Search

Menu

Search Input

Search

* [Contact Us](https://trustedsec.com/contact)
* [Report a breach](https://trustedsec.com/report-a-breach)

* [Solutions](https://trustedsec.com/solutions)
* [Services](https://trustedsec.com/services)
* [Research](https://trustedsec.com/research)
* [Blog](https://trustedsec.com/blog)
* [Resources](https://trustedsec.com/resources)
* [About Us](https://trustedsec.com/about-us)

Search

* [Contact Us](https://trustedsec.com/contact)
* [Report a breach](https://trustedsec.com/report-a-breach)

* [Blog](https://trustedsec.com/blog)
* [From RAGs to Riches: Using LLMs and RAGs to Enhance Your Ops](https://trustedsec.com/blog/from-rags-to-riches-using-llms-and-rags-to-enhance-your-ops)

February 11, 2025

# From RAGs to Riches: Using LLMs and RAGs to Enhance Your Ops

Written by
Brandon McGrath

Red Team Adversarial Attack Simulation
Artificial Intelligence (AI)

![](https://trusted-sec.transforms.svdcdn.com/production/images/Blog-Covers/FromRAGStoRiches_WebHero.jpg?w=320&h=320&q=90&auto=format&fit=crop&dm=1739201870&s=7ee6416c1757e5748ed9cdc6423a3a5c)

Table of contents

* [1.1      Introduction](#Introduction)
* [1.2      LLMs and RAG](#LLMsRAG)
* [1.3      RAG Use Cases](#UseCases)
* [1.4      Development](#Development)
* [1.5      Conclusion](#Conclusion)

Share

* Share URL
* [Share via Email](/cdn-cgi/l/email-protection#a996dadccbc3cccadd94eac1cccac28c9b99c6dcdd8c9b99ddc1c0da8c9b99c8dbddc0cac5cc8c9b99cfdbc6c48c9b99fddbdcdaddcccdfaccca8c9b988fc8c4d992cbc6cdd094efdbc6c48c9b99fbe8eeda8c9b99ddc68c9b99fbc0cac1ccda8c9ae88c9b99fcdac0c7ce8c9b99e5e5e4da8c9b99c8c7cd8c9b99fbe8eeda8c9b99ddc68c9b99ecc7c1c8c7cacc8c9b99f0c6dcdb8c9b99e6d9da8c9ae88c9b99c1ddddd9da8c9ae88c9bef8c9befdddbdcdaddcccddaccca87cac6c48c9befcbc5c6ce8c9befcfdbc6c484dbc8ceda84ddc684dbc0cac1ccda84dcdac0c7ce84c5c5c4da84c8c7cd84dbc8ceda84ddc684ccc7c1c8c7cacc84d0c6dcdb84c6d9da "Share via Email")
* [Share on Facebook](http://www.facebook.com/sharer.php?u=https%3A%2F%2Ftrustedsec.com%2Fblog%2Ffrom-rags-to-riches-using-llms-and-rags-to-enhance-your-ops "Share on Facebook")
* [Share on X](http://twitter.com/share?text=From%20RAGs%20to%20Riches%3A%20Using%20LLMs%20and%20RAGs%20to%20Enhance%20Your%20Ops%3A%20https%3A%2F%2Ftrustedsec.com%2Fblog%2Ffrom-rags-to-riches-using-llms-and-rags-to-enhance-your-ops "Share on X")
* [Share on LinkedIn](https://www.linkedin.com/shareArticle?url=https%3A%2F%2Ftrustedsec.com%2Fblog%2Ffrom-rags-to-riches-using-llms-and-rags-to-enhance-your-ops&mini=true "Share on LinkedIn")

## 1.1      Introduction

In this blog, I will explore Retrieval-Augmented Generation (RAG) and how it can be applied to research capabilities. RAG is a framework that integrates retrieval-based models with generative AI to provide accurate and context-aware responses by storing and retrieving snippets of relevant information prior to prompting.

## 1.2      LLMs and RAG

Before jumping into the code and use cases, we must first define what LLM and RAG are. [OpenAI](https://openai.com/) defined Large Language Models (LLMs) in their 2018 paper [Improving Language Understanding by Generative Pre-Training](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf). LLMs are trained on huge datasets to predict the next word in a sequence, which enables them to generate coherent and contextually relevant responses.

Traditional LLMs rely solely on pretrained knowledge, which can lead to outdated or incomplete responses, especially in specialized domains. RAG addresses this limitation by integrating retrieval-based models with generative AI. This allows LLMs to access external knowledge sources, ensuring responses are more accurate and context aware. Unlike standard LLMs, which generate text purely from internal weights, RAG actively retrieves relevant information, keeping outputs grounded in up-to-date and domain-specific data. This approach was demonstrated in [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401), which explores RAG’s definition and its role in Natural Language Processing (NLP). Below is an example workflow of a RAG system:

![](https://trusted-sec.transforms.svdcdn.com/production/images/Blog-assets/RAGsLLMs_McGrath/figure-1.png?w=320&q=90&auto=format&fit=max&dm=1739201568&s=e1d91b56c2813382707c88dcc9a59742)

Figure 1 - Example Workflow

## 1.3      RAG Use Cases

There is a plethora of use cases for these systems, and some are much better than others. For example, we attempted to use a RAG system to identify new methods of code execution by feeding it infosec blogs/papers and Microsoft documentation. However, it was never consistent in its responses and often made things up (as LLMs do). There is an element of fine-tuning here, but we want to explore some other offerings.

We are going to discuss the following use cases:

1. Research assistant
2. Research generation
3. Target-specific tasking

Note, all prompts were tested with these three (3) models. This blog is not aimed at comparing the models; this is purely a callout of the ones used during testing.

* [Llama3](https://ollama.com/library/llama3)
* [llama2-uncensored...