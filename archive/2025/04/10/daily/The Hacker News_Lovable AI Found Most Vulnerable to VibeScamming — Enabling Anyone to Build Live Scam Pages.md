---
title: Lovable AI Found Most Vulnerable to VibeScamming — Enabling Anyone to Build Live Scam Pages
url: https://thehackernews.com/2025/04/lovable-ai-found-most-vulnerable-to.html
source: The Hacker News
date: 2025-04-10
fetch_date: 2025-10-06T22:09:33.583402
---

# Lovable AI Found Most Vulnerable to VibeScamming — Enabling Anyone to Build Live Scam Pages

#1 Trusted Cybersecurity News Platform

Followed by 5.20+ million[**](https://twitter.com/thehackersnews)
[**](https://www.linkedin.com/company/thehackernews/)
[**](https://www.facebook.com/thehackernews)

[![The Hacker News Logo](data:image/png;base64...)](/)

**

**

[** Subscribe – Get Latest News](#email-outer)

* [** Home](/)
* [** Newsletter](#email-outer)
* [** Webinars](/p/upcoming-hacker-news-webinars.html)

* [Home](/)
* [Data Breaches](/search/label/data%20breach)
* [Cyber Attacks](/search/label/Cyber%20Attack)
* [Vulnerabilities](/search/label/Vulnerability)
* [Webinars](/p/upcoming-hacker-news-webinars.html)
* [Expert Insights](https://thehackernews.com/expert-insights/)
* [Contact](/p/submit-news.html)

**

**

**

Resources

* [Webinars](/p/upcoming-hacker-news-webinars.html)
* [Free eBooks](https://thehackernews.tradepub.com)

About Site

* [About THN](/p/about-us.html)
* [Jobs](/p/careers-technical-writer-designer-and.html)
* [Advertise with us](/p/advertising-with-hacker-news.html)

Contact/Tip Us

[**

Reach out to get featured—contact us to send your exclusive story idea, research, hacks, or ask us a question or leave a comment/feedback!](/p/submit-news.html)

Follow Us On Social Media

[**](https://www.facebook.com/thehackernews)
[**](https://twitter.com/thehackersnews)
[**](https://www.linkedin.com/company/thehackernews/)
[**](https://www.youtube.com/c/thehackernews?sub_confirmation=1)
[**](https://www.instagram.com/thehackernews/)

[** RSS Feeds](https://feeds.feedburner.com/TheHackersNews)
[** Email Alerts](#email-outer)

[![Salesforce Security Handbook](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjWa8tsMNqlevi1HGF1ALQRGIq7hROPFAbHd3R1RTEOe73T8_Q2xW_-91t2jSGjU5peiPb8QYblGp4igNW-u2Qmlxbp2BKzTVMSvyXDZJmC-BYpiiJHrcnG5drmSP97iZ9PVIf1DeEr7U-7vWpe4HXwfMjt8FGNgq5mOycOJluYr9wF7YOKrQY9MfArwgjt/s728-e100/ai-agent-security-d.png)](https://thehackernews.uk/ai-agent-security-d)

# [Lovable AI Found Most Vulnerable to VibeScamming — Enabling Anyone to Build Live Scam Pages](https://thehackernews.com/2025/04/lovable-ai-found-most-vulnerable-to.html)

**Apr 09, 2025**Ravie LakshmananArtificial Intelligence / Web Security

[![Lovable AI VibeScamming](data:image/png;base64... "Lovable AI VibeScamming")](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgGkslJ3fDvPaurA3ZobXyyK-_iAaRF5NmvSiOisZgf4pDCJRQWti_6JeI9mpVMhXH3Ao0pftU6WbDCfsMGorlZfpgQ9qfSyDXXbVkwwCZAgUMvcSxuL0QGB4bh1-A4kyM0LjhAhzIwrZ3-cOdfWPVESOL9ht8tI-HcDv2IZX-mOU7L2ZPawxJ08tugjB1d/s790-rw-e365/AI-scam.jpg)

[Lovable](https://lovable.dev), a generative artificial intelligence (AI) powered platform that allows for creating full-stack web applications using text-based prompts, has been found to be the most susceptible to jailbreak attacks, allowing novice and aspiring cybercrooks to set up lookalike credential harvesting pages.

"As a purpose-built tool for creating and deploying web apps, its capabilities line up perfectly with every scammer's wishlist," Guardio Labs' Nati Tal [said](https://labs.guard.io/vibescamming-from-prompt-to-phish-benchmarking-popular-ai-agents-resistance-to-the-dark-side-1ec2fbdf0a35) in a report shared with The Hacker News. "From pixel-perfect scam pages to live hosting, evasion techniques, and even admin dashboards to track stolen data – Lovable didn't just participate, it performed. No guardrails, no hesitation."

The technique has been codenamed **VibeScamming** – a play on the term vibe coding, which refers to an AI-dependent programming technique to produce software by describing the problem statement in a few sentences as a prompt to a large language model (LLM) tuned for coding.

The abuse of LLMs and AI chatbots for malicious purposes is not a new phenomenon. In recent weeks, research has shown how threat actors are abusing popular tools like [OpenAI ChatGPT](https://thehackernews.com/2025/02/openai-bans-accounts-misusing-chatgpt.html) and [Google Gemini](https://thehackernews.com/2025/01/google-over-57-nation-state-threat.html) to assist with malware development, research, and content creation.

[![DFIR Retainer Services](data:image/png;base64...)](https://thehackernews.uk/cloud-insight-d)

What's more, LLMs like DeepSeek have also been found susceptible to [prompt attacks](https://www.trendmicro.com/en_us/research/25/c/exploiting-deepseek-r1.html) and [jailbreaking techniques](https://unit42.paloaltonetworks.com/jailbreaking-deepseek-three-techniques/) like [Bad Likert Judge](https://thehackernews.com/2025/01/new-ai-jailbreak-method-bad-likert.html), [Crescendo](https://thehackernews.com/2024/06/prompt-injection-flaw-in-vanna-ai.html), and [Deceptive Delight](https://thehackernews.com/2024/10/researchers-reveal-deceptive-delight.html) that allow the models to bypass safety and ethical guardrails and generate otherwise prohibited content. This includes [creating](https://www.tenable.com/blog/deepseek-deep-dive-part-1-creating-malware-including-keyloggers-and-ransomware) phishing emails, keylogger and ransomware samples, albeit with additional prompting and debugging.

In a report published last month, Broadcom-owned Symantec [revealed](https://www.security.com/threat-intelligence/ai-agent-attacks) how OpenAI's [Operator](https://openai.com/index/introducing-operator/), an AI agent that can carry out web-based actions on behalf of the user, could be weaponized to automate the whole process of finding email addresses of specific people, creating PowerShell scripts that can gather system information, stashing them in Google Drive, and drafting and sending phishing emails to those individuals and trick them into executing the script.

[![Lovable AI VibeScamming](data:image/png;base64... "Lovable AI VibeScamming")](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEifkbYTvNKxa8XrPRyd2OlRWtSJzEqKlpqUs16KWldjxIdtaPsq4mzQ9Nkku1KcuFYn222WZwYVwPuxclUSJYfisqxNr2V6T37bmnkl5EJCUSwuzrh6AjKKQa7TXsqU-kEDjI2n0LfFPj7KFCxIEycyw07LzL3EpTj8CoNZZ6t3gFgc4UED3sHThx5Sa9MJ/s790-rw-e365/1.jpg)

The rising popularity of AI tools also means that they could significantly reduce the barriers to entry for attackers, enabling them to harness their coding capabilities to craft functional malware with little-to-no technical expertise of their own

A case in example is a new jailbreaking approach dubbed [Immersive World](https://www.catonetworks.com/blog/2025-cato-ctrl-threat-report-top-4-ai-predictions-for-the-year-ahead/) that makes it possible to create an information stealer capable of harvesting credentials and other sensitive data stored in a Google Chrome browser. The technique "uses [narrative engineering](https://go.catonetworks.com/rs/245-RJK-441/images/2025-cato-CTRL-threat-report.pdf) to bypass LLM security controls" by creating a detailed fictional world and assigning roles with specific rules so as to get around the restricted operations.

Guardio Labs' latest analysis takes a step further, uncovering that platforms like Lovable and, to a lesser extent, Anthropic Claude could be weaponized to generate complete scam campaigns, complete with SMS text message templates, Twilio-based SMS delivery of the fake links, content obfuscation, defense evasion, and [Telegram integration](https://thehackernews.com/2024/01/telegram-marketplaces-fuel-phishing.html).

[![Lovable AI VibeScamming](data:image/png;base64... "Lovable AI VibeScamming")](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiKZ9i-TARl4hPT1WIEUOwAcr66vSzhoEY1G3EFV8eHlqeSpa4CYASHeOZJBr4mrzjFF0ZBk6SRu8d74lb5SAo9SLn34zY-H5K13p3x3PGyg0BG2de4HWUrYd1uyGPQvB9Mpy0cpRo4UXDpMfLvmPD59MYYJCffzKsni9YFE2U7W67jEmlVh8osE6aRyfd9/s790-rw-e365/2.jpg)

VibeScamming begins with a direct prompt asking the AI tool to automate each step of the attack cycle, assessing its initial response, and then adopting a multi-prompt approach to gently steer the LLM model to generate the intended malicious response. Called "level up," this phase involves enhancing the phishing page, refining...