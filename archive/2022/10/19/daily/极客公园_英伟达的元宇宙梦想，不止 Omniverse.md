---
title: 英伟达的元宇宙梦想，不止 Omniverse
url: https://mp.weixin.qq.com/s?__biz=MTMwNDMwODQ0MQ==&mid=2652970221&idx=1&sn=37fa3cb6b753b45aa57993f1b5dc455f&chksm=7e54615b4923e84d1bf10511e6a691e27eaaaaf3004b8a4f154beeea103c9baccfb78d4c889f&scene=58&subscene=0#rd
source: 极客公园
date: 2022-10-19
fetch_date: 2025-10-03T20:18:29.411090
---

# 英伟达的元宇宙梦想，不止 Omniverse

![cover_image](https://mmbiz.qpic.cn/mmbiz_jpg/8cu01Kavc5a2eJiaAd1LzUWq5niajiaRibdmZfquGp3CBiapEgiczfV1shHk2ibypu4ZPnQBCCmCpL7Gdq9VDgraMQ6RQ/0?wx_fmt=jpeg)

# 英伟达的元宇宙梦想，不止 Omniverse

极客公园

以下文章来源于Founder Park
，作者Rebuild

![](http://wx.qlogo.cn/mmhead/Q3auHgzwzM5WmgV1o3EiaCiab839tNFuZAlaJCadCedmxgxQzXQnaqIA/0)

**Founder Park**
.

来自极客公园，专注与科技创业者聊「真问题」。

![](https://mmbiz.qpic.cn/mmbiz_jpg/8cu01Kavc5a2eJiaAd1LzUWq5niajiaRibdm4cQ25sZ2ib8nJqOoqUaMVVQYQKIyz4YJiaJBn15H44egpwFOcl3f3MZQ/640?wx_fmt=jpeg)

英伟达已经成为元宇宙的基础服务商。

**作者 | Founder Park**

要谈元宇宙，英伟达是避不开的。

不管是更真实呈现虚拟世界所需要的光追技术，还是元宇宙所需要的人工智能以及大算力，英伟达都提供了一系列的技术和平台支持。而在今年的英伟达 GTC 2022 大会上，除了 RTX 40 系列显卡之外，最引人瞩目的，就是旗下一系列元宇宙相关的产品和技术的更新了。

在去年正式发布「工程师的元宇宙」NVIDIA Omniverse（以下简称 Omniverse）之后，英伟达这次推出了 Omniverse Cloud 云服务，创始人黄仁勋曾表示：「通过云端的 Omniverse，我们可以连接世界各地的团队，共同设计、构建和运行虚拟世界和数字孪生。」

对于英伟达来说，Omniverse 还是将他们擅长的计算机图形、人工智能，以及科技计算和物理模拟真正大一统的平台，他们对于元宇宙的所有畅想和规划，都可以在 Omniverse 中略见一斑。

在今年 5 月的 Rebuild 大会上，我们邀请了 NVIDIA 中国区 Omniverse Lead 何展，畅聊了他们对于 Omniverse 这个「工程师元宇宙」的思考。而这次，配合着更高算力的 GPU、自动驾驶芯片雷神 Thor，还有 Omniverse Cloud 的发布，英伟达对于元宇宙的思考又有了什么新变化？他们心目中的「工程师元宇宙」的目标有了新调整吗？

9 月 29 日，在极客公园的 Rebuild 2022，Founder Park 的主播王式和 NVIDIA 中国区高级技术市场经理施澄秋，一起聊聊英伟达在元宇宙的新思考。

![](https://mmbiz.qpic.cn/mmbiz_png/8cu01Kavc5Zoia7hrgDnmPUBCuPZ2KoyjE9JYcu4icGfm3fDpHlHuYA0yoaBFctvRbehlg3dibk6DkK2mUSibbOQtA/640?wx_fmt=png)

施澄秋做客极客公园的「Rebuild」栏目 | 来源：直播截图

**01**

**元宇宙之外，**

**GTC 大会的新亮点**

**Founder Park：今年新推出的雷神 Thor 芯片直接将算力拉到了 2000T，并且直接取代了计划于 2024 年量产的 Atlan 芯片，而不是作为后续的升级版，是出于什么样的考虑?**

**施澄秋：**自动驾驶车辆有两个关键点。

第一点，车辆上采集器的数据来源非常多，激光雷达、雷达、摄像头等。这些采样得到的数据不是单一的，而是多样性的，高精的地图、环境；车内外的一些互动，比如突然穿过的行人、道路上的路标；甚至包括车内人员的谈话、口型、面部表情，因为有人机互动，可能都会有一些捕捉。要把这些数据来源全部汇总起来，意味着这个车规级的计算机每秒钟运算的数据量是非常巨大的。

第二点，数据一定要有冗余性。车辆行驶的安全性是至关重要的，车上装一个摄像头足以捕捉前方的数据，再加上雷达和激光雷达可以达到不同层级的冗余性；确保当有某一个设备出现意外或受阻，比如摄像头被其他车辆或者树叶挡住的时候，其他设备还能够实时地提供一个安全的数据冗余。

冗余性和多样性造就了自动驾驶的车规级电脑实时处理的海量运算，这也是今后日益发展的自动驾驶车辆所提出的算力需求。我们的产品可能要丰富到一个极高的算力高度，才能够完成对于这样的复杂预算环境的挑战，所以我们推出了一个更高级的产品雷神 Thor，基于今年最新的 Ada Lovelace 构架，除了第三代光线追踪以外，还加入了人工智能和神经学图形学的配合。

**Founder Park：雷神 Thor 背后其实是基于 Ada Lovelace 架构，这个新架构核心创新点以及要去聚焦解决的问题是什么？**

**施澄秋：**Ada Lovelace 这个架构可能衍生到各个方面，可以说它是图形学和图形图像处理的一个巅峰之作。比如游戏玩家心心念念的 RTX 40 系列的产品，以及我们的数据中心马上要使用的 RTX 6000 Ada 架构，还有 L40 等系列产品都是基于 Ada Lovelace 架构来设计的。

Ada Lovelace 架构加入了最新的第三代光线追踪核心，在做图形开发专业级渲染或打游戏时，都拥有了实时光线追踪的能力，而且每一秒钟可能达到电影的 24 帧；另外还加入了人工智能的 TensorFlow 张量运算，可以用 FP8 低精度去做非常快速的图形图像预测，这个部分就是神经图形的概念；还加入了大量的新功能，甚至能够靠人工智能 AI 自动加一个完整的帧出来。

**Founder Park：智能汽车的算力应该往集中化的方向走还是分布式算力？英伟达是如何布局的？**

**施澄秋：**对现在的车用市场而言，驾驶座舱的仪表、行车电脑、自动驾驶系统、娱乐系统，还有 HUD 的显示器等可能都是由不同的处理器处理的，甚至是多个不同的电脑或者操作系统去处理的。很长时间内都是这样的模式运作的，有两个原因。第一个是算力不够，无法用一台中央电脑处理繁多冗杂的任务；另外就是各家有各自的系统，没有厂商想过推出一个平台去集成车上所有的系统。

首先，英伟达的算力要做到足够强大。其次，我们的平台要能够兼容这些操作系统的运算底层模式。如果能够提供足够的算力，把车上的系统集成化，对于生产、验证、维修保养环节都是一个更好的方向，对用户、车主也是更有利的。

**Founder Park：这次还发布了 Grace Hopper 推荐系统，搜索推荐感觉都要没什么增长了，Grace Hopper 为什么还要聚焦于「推荐系统」？**

**施澄秋：**GPU 作为 Deep Learning 的加速器，在推荐系统里的算法远比 CPU 快。Grace Hopper 拥有 500 多 G 的内存，Grace CPU 核心和 Hopper GPU 核心是通过 NVLink 高带宽连接技术连接的，大内存可以随时被 Hopper GPU 访问，意味着这套系统的能力远比一个单 GPU 所拥有的运算能力和加速器能力要强大得多，因为它有 ARM 架构可以处理很多单线程的非常高速的任务，这些任务可能并不适合在多线程的 GPU 上运行；它们之间的缓存机制、内存调用机制、显存调用机制都是在 NVLink 的指导下完成的。

短视频平台的 UGC（用户生成内容）会储存在互联网服务商的服务器里，这些内容需要一个神经网络经过算法将其标签化。无论是从运算模式、软件框架，还是使用上的调度便利性和数据规模来说，Grace Hopper 都是数据中心最合适使用的一款产品。我们觉得今后的数据中心必然是往后迭代的，人工智能深入学习这套算法在过去的十年里面发展得非常快，以后可能会有各式各样的新算法，而硬件一定要在软件之前准备好；当提出一个软件的构想，能够提供一个匹配的算力去验证这个软件的构想。

另外就是，现在的搜索或者推荐系统，不仅仅是字符或者文本内容的搜索，要处理语音、视频等复杂的内容，其中的自然语言处理也是很复杂的事情，这些都需要深度神经网络处理，需要 AI 和大算力。

**Founder Park：NVIDIA 目前做的方向，似乎越来越接近 AI 的应用层面了，比如医疗图像处理 AI 框架 Monai，还比如 Tokkio，未来你们会直接提供 AI 应用吗？**

**施澄秋：**这些其实都是进行演示的 demo，演示的是英伟达现有的软件框架和硬件设备所能够达到的效果以及能够提供的服务，用户可以根据自身需求做深度的二次开发。比如医疗影像学的辅助诊断，可以提示这张 CT 某个位置可能有一些问题，提示医生额外注重某些位置；而这并不是英伟达最后的应用。医规级的设备是非常严格的，英伟达必定是要跟客户共同开发，做出一个符合当地法律又满足医管局要求的医疗设备；这就足以证明了英伟达不会直接提供应用。

英伟达首先要保证的是做好硬件的算力与功能，做好之后再做一个软件开发工具包和中间的一些运行框架等，叠上层层软件栈，最终让用户获得一个开箱就可以使用的开发环境；英伟达营造的是开箱即有的开发环境，而不是开箱就有的实用案例。人工智能不是一个消费形式，它必定要建立在整个行业内共建的复杂的生态系统之上，所以英伟达不会直接推出 AI 应用的产品，我们做的是在平台上提供一个全软件堆栈的服务层。

**02**

**Omniverse 致力于搭建**

**一个平等的元宇宙**

**Founder Park：在产品上，为什么要做 Omniverse Nucleus 以及 Omniverse Cloud，它们和一般的数据库和云有什么区别？**

**施澄秋：**数据库的描述并不准确，我们做的叫 MDL（Material Description Language），材质描述语言，它能描述物体的粗糙程度、重力、光线反射程度等；可以把它想成一个包罗万象的元宇宙里所有物体的大型数据库。在相当长的一段时间内，我们都在耕耘 MDL，用户也可以自由地添加材质；中国有一些特有的材质，我们有很多合作伙伴在帮忙做这些材质；把 MDL 放到 Omniverse 让元宇宙的建设者、参与者能够自由地调配和使用这些元宇宙的材质是很重要的。

元宇宙必须提供一个统一的源源不断的随叫随到的算力，实现「在元宇宙里大家都是平等的」的概念；英伟达 Omniverse Cloud 希望元宇宙的建设者都可以到云上参与设计 Nucleus 元宇宙的生态环境，算力不应该成为阻碍，通过云端的 GPU 算力来保障用户能够参与到元宇宙的设计、建设、验证、训练、部署等等的各式各样的环境里。Omniverse Cloud 通过 Nucleus 存储 MDL 的材质，数据资产能够保有数据建模和一整套工作的流程，再通过我们的 OmniverseConnector 连接到几百款第三方合作伙伴的生态系统，去打造整个元宇宙的数字资产，这是我们的一个设计初衷。

**Founder Park：注意到 Omniverse 试图把以往计算机的 AI、数据处理等统一化，变成一款产品，这是不是也是 Omniverse 未来的产品方向？**

**施澄秋：**是这样的，在 Omniverse 中会有很多不同的需求，比如有人要做复杂的 AI 的训练，机器人或者自动驾驶的训练，首先是需要的算力比较高，然后就是 Omniverse 里的环境也需要 1:1 的数字孪生，比如还原街道和城市，需要让车辆经历春夏秋冬、阴晴雨雪等各种天气，这样车辆在训练的时候才能达到硬件的闭环，它会以为是在真实的世界训练。另外对于环境来说，也要对车子的碰撞产生和现实世界一样的反馈，撞到墙、电线杆、动物和人的反馈是不一样的。

这些都需要仿真，也需要人工智能、光线追踪、图形学计算以及深度神经网络，甚至还有语言模型，因为还牵扯到人机互动，这些元素自然地就融入在一个系统中了。事实上，当所有的元素都集中在一起的时候，我们认为它就是元宇宙了。

**Founder Park：这次还发布了一些硬件系统，比如 NVIDIA OVX，背后的思考是什么？**

**施澄秋：**OV 是 Omniverse 的缩写；X 是英伟达常用的一个结尾，代表了两件事，一个是极致 Extreme，一个是加速 Acceleration；OVX 是专为元宇宙做加速的加速器。

我们的 OVX 很强大，里面有 8 张显卡，以及很先进的网络 CPU 存储，这次新发布的 OVX 采用了 Ada Lovelace 架构的 L40 图卡，这些先进的设备组合成 OVX 能够为元宇宙提供算力支撑；多个 OVX 组成的 OVX SuperPOD 为 Omniverse 计算系统集群提供了基础硬件的支撑。

OVX 很快就会上市，不过可以认为这是我们的公版设计，我们的合作伙伴会提供经过 NV 认证的 OVX 系统，为用户提供演示——我们的 OVX 可以用系统堆叠出的集群去支撑元宇宙的算力。

![](https://mmbiz.qpic.cn/mmbiz_jpg/8cu01Kavc5Zoia7hrgDnmPUBCuPZ2KoyjAHRPMQzAAtvEuE2zRS9xfKHy53UicDxE6y2iat6LicogFeibjDkvhKPFgg/640?wx_fmt=jpeg)

OVX 硬件系统 | 来源：NVIDIA 官网

**Founder Park：目前 Omniverse 有哪些应用扩展？**

**施澄秋：**Omniverse 的扩展很丰富。比如设计师可以做在线协同工作，英伟达在这次 GDC 大会发布的技术演示就是由不同国家的工程师用 Omniverse 在线上分工协作完成的；在这个过程中，每个人负责的部分和使用的应用都不同，Omniverse 就是要做分工的 3D 世界的协同、构造、创建、查看等这些方面的应用。

比如构建元宇宙时，不可能把地球上的事物一一画出来，可以用 AI 去生成，Omniverse Replicator 可以把摄像头照到的生成出 3D 建模，而这些 3D 建模可以即时导入到元宇宙中，这就叫合成数据，是具有物理真值并符合自然界的物理规律的。

Omniverse 能够让所有元宇宙的创造者、使用者能够更好地管理并运行这个模拟世界，能够让整个团队都能在 Omniverse 进行共同地设计、编程、优化、部署、训练基于人工智能的深度神经网络的一系列的应用和服务。比如自动驾驶车辆、机械手臂、服务机器人的训练等等，都可以直接在元宇宙里进行。

**Founder Park：前不久，你们推出了 Omniverse ACE，英伟达对于未来虚拟人的理解是怎样的？**

**施澄秋：**英伟达在云端云原生的开发工具叫 ACE（Avatar Cloud  Engine），就是虚拟形象的云端引擎。我们对虚拟人的标准定位很高，虚拟人要做得真实，要符合自然界的定律，要物理准确，需要光线追踪，毛发、皮肤、表情、嘴型都要跟这个人匹配；能够以假乱真，是虚拟人能够达到的高度。

在这个基础上，还要配合一系列光线追踪、人工智能、物理模拟等，Omniverse 里有一款产品 Audio2Face，输入一段话，可以自动地把这段话投射到 CG 角色的脸部上，并且可以根据前后文理解这段话，自动地认知到喜怒哀乐，并相应地投射出丰富的面部表情。

Omniverse 还有一个小组件 Machinima，用机器学习的方式制造电影场景。通过单个普通的民用摄像头捕捉的动作，可以实时地把人的骨骼、关节、肢体语言、每一个身体动作都 1:1 仿真到虚拟人上。

**03**

**英伟达立足于**

**元宇宙的基础服务商**

**Founder Park：NVIDIA 是怎么定义元宇宙的？**

**施澄秋：**从 Web1.0 到 Web2.0 再到如今的 Web3，首先是移动互联网的出现，然后就是大家都随时随地永远在线，在 Web3 的元宇宙里，也应该是永远在线的状态。

英伟达定义的元宇宙是用 USD（Universal Scene Description，一种用于描述虚拟世界的可扩展通用语言） 的方式把所有的数字资产串连起来。地球上的所有事物可能都会进入元宇宙，用现有的第三方 ISV 软件去描述这些数字资产，用 USD 作为桥梁，把各种格式的数字资产通过 Omniverse Connector 连接起来，成为实时的 3D 互联网。

以前的人绝对想不到互联网会成为生活的重要组成部分，元宇宙最后会变成什么样也是无法预测的，英伟达作为全软件堆栈服务的提供商，能做好的是硬件的算力、软件交换能力、软件的 SDK 等一系列框架，做好基础服务商，帮助用户共同构建元宇宙。

**Founder Park：为什么英伟达做的虚拟世界，追求和真实世界的相似度？甚至老黄还表示：要把「粒子物理定律、引力定律、电磁定律.... 压力和声音」都应用到元宇宙中。**

**施澄秋：**元宇宙的初期肯定是用户先感受、探索的过程，但如果元宇宙跟真实世界毫无交集，那元宇宙最后就变成一个科幻世界了。早期的科幻可以说是对未来世界的一种展望，现在的元宇宙也可能是未来某个时间点现实社会的一种表达；如果能够把元宇宙里的内容拿到现实社会去验证，会对科技发展起到推波助澜的作用。比如美国的零售店把元宇宙里对门店的规划通过增强现实的方式投射到门店陈列的物品上，马上就能得到反馈，如何陈列展示会更加合理、增加用户的购买欲；这就是元宇宙跟现实的交互。

在元宇宙里可以验证、训练、设想、实践各种各样的猜想，部署天马行空的创意，最后它能够在某一个时间节点上连接到物理世界；英伟达的 GPU 加速器是为了加速人工智能的发展，希望通过我们的硬件、软件一系列的堆栈和环境的构建，帮助各种各样的运算环境都能达到加速，因为我们相信元宇宙终有一天会落实到现实世界中。虚拟世界最终还是要和现实世界做耦合，虚拟世界的价值应该回到现实世界完成闭环。

**Founder Park：最近 AIGC（AI 生成内容）很热，英伟达在这个领域，看中什么？**

**施澄秋：**从早期的服务商提供内容，到由用户提供内容，今后由 AI 自主生成提供的内容，这是三步进化的必然过程。未来的元宇宙内容的丰富还是要依靠 AI 生成的内容。

现在通过 GauGAN 画几笔就能帮用户生成一幅艺术大师级别的美术画作，这就是基于生成式对抗网络的 AIGC 的内容。在今年的图形学大会 SIGGRAPH 上，英伟达的一篇关于 AI 生成的论文就获得了最佳论文奖，论文的核心就是将一张静态的 3D 图片逆向渲染成动态 3D 建模。

英伟达这次发布的 40 系列显卡有一个最重要的功能 DLSS3，就是第三版的 Deep Learning Super Sampling 深度学习超采样技术。它可以完整生成一幅画面——一帧 4K 相当于四帧 1080P 的画面，我们只有 1/8 的运算量，每两帧 4K 的画面只有一帧 1080P 的真实渲染运算量，剩下的 7/8...