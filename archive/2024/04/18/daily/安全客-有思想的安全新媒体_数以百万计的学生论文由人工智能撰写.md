---
title: 数以百万计的学生论文由人工智能撰写
url: https://www.anquanke.com/post/id/295694
source: 安全客-有思想的安全新媒体
date: 2024-04-18
fetch_date: 2025-10-04T12:14:37.910750
---

# 数以百万计的学生论文由人工智能撰写

首页

阅读

* [安全资讯](https://www.anquanke.com/news)
* [安全知识](https://www.anquanke.com/knowledge)
* [安全工具](https://www.anquanke.com/tool)

活动

社区

学院

安全导航

内容精选

* [专栏](/column/index.html)
* [精选专题](https://www.anquanke.com/subject-list)
* [安全KER季刊](https://www.anquanke.com/discovery)
* [360网络安全周报](https://www.anquanke.com/week-list)

# 数以百万计的学生论文由人工智能撰写

阅读量**72318**

发布时间 : 2024-04-17 10:55:16

**x**

##### 译文声明

本文是翻译文章

原文地址：<https://cybernews.com/news/millions-student-papers-written-with-ai/>

译文仅供参考，具体内容表达以及含义原文为准。

***抄袭和相似性检测服务 Turnitin 研究了数百万份学生作品，发现这些作品似乎使用了大量大型语言模型 (LLM) 生成的内容。***

在使用新的 AI 写作检测器检查超过 2 亿篇论文后，Turnitin 发现超过 2200 万篇（约 11% 的作品）包含至少 20% 的 AI 写作。

超过 600 万篇论文（约占 3% 左右）至少有 80% 的内容是LLM生成的。

Turnitin 首席产品官 Annie Chechitelli表示： “我们正处于教育领域的一个重要时刻，技术正在改变学习方式，对学术诚信的需求比以往任何时候都更加重要。” “教育界的每个人都在寻找资源，使他们能够发挥最佳水平。”

在过去的一年里，生成式人工智能的使用有所增加，而且未来还会有更多。

Tyton Partners 最近进行的一项研究显示，近一半的受访学生每月、每周或每天使用过生成式人工智能工具，例如 ChatGPT。

调查发现，75% 的学生表示，即使教师或机构禁止使用该技术，他们也会继续使用该技术。

虽然 Turnitin 背后的公司认为人工智能写作检测功能有助于在不牺牲学术诚信的情况下推进学习，但它也认为学术政策可能需要一些修改。

Turnitin 表示：“Turnitin 数据中始终存在人工智能写作，这凸显出我们需要将人工智能写作工具在教育中的使用视为一个复杂的、不断发展的难题。” “教育工作者和机构应该考虑各种无法察觉的因素——或者说拼图。这包括与学生就人工智能写作在课堂上的可接受用途进行公开讨论、审查学术政策以及修改论文提示。”

本文翻译自 [原文链接](https://cybernews.com/news/millions-student-papers-written-with-ai/)。如若转载请注明出处。

商务合作，文章发布请联系 anquanke@360.cn

本文由**安全客**原创发布

转载，请参考[转载声明](https://www.anquanke.com/note/repost)，注明出处： [https://www.anquanke.com/post/id/295694](/post/id/295694)

安全KER - 有思想的安全新媒体

本文转载自:

如若转载,请注明出处： <https://cybernews.com/news/millions-student-papers-written-with-ai/>

安全KER - 有思想的安全新媒体

分享到：![微信](https://p0.ssl.qhimg.com/sdm/28_28_100/t01e29062a5dcd13c10.png)

* [人工智能](/tag/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD)

**+1**1赞

收藏

![](https://p0.ssl.qhimg.com/t010857340ce46bb672.jpg)安全客

分享到：![微信](https://p0.ssl.qhimg.com/sdm/28_28_100/t01e29062a5dcd13c10.png)

## 发表评论

您还未登录，请先登录。

[登录](/login/index.html)

![](https://p1.ssl.qhimg.com/t014757b72460d855bf.png)

[![](https://p0.ssl.qhimg.com/t010857340ce46bb672.jpg)](/member.html?memberId=170061)

[安全客](/member.html?memberId=170061)

这个人太懒了，签名都懒得写一个

* 文章
* **2096**

* 粉丝
* **6**

### TA的文章

* ##### [英国通过数据访问和使用监管法案](/post/id/308719)

  2025-06-20 17:11:10
* ##### [CISA警告：严重缺陷（CVE-2025-5310）暴露加油站设备](/post/id/308715)

  2025-06-20 17:09:03
* ##### [大多数公司高估了AI治理，因为隐私风险激增](/post/id/308708)

  2025-06-20 17:05:02
* ##### [研究人员发现了有史以来最大的数据泄露事件，暴露了160亿个登录凭证](/post/id/308704)

  2025-06-20 17:02:15
* ##### [CVE-2025-6018和CVE-2025-6019漏洞利用：链接本地特权升级缺陷让攻击者获得大多数Linux发行版的根访问权限](/post/id/308701)

  2025-06-20 16:59:36

### 相关文章

* ##### [人工智能可能修复帮助传播了 15 年的漏洞](/post/id/308401)

  2025-06-12 15:19:33
* ##### [浅析新型网络犯罪DeepSeek AI实战应用](/post/id/305102)

  2025-03-18 10:38:20
* ##### [360SRC x Hacking Group丨「奇御」AI安全技术沙龙议题征集！](/post/id/302279)

  2024-11-28 17:43:31
* ##### [从误用到滥用： 人工智能风险与攻击](/post/id/300992)

  2024-10-17 11:00:07
* ##### [一种用于网络钓鱼攻击的生成式人工智能恶意软件](/post/id/300410)

  2024-09-25 14:16:34
* ##### [苹果加入美国政府对人工智能安全的自愿承诺](/post/id/298565)

  2024-07-31 11:23:56
* ##### [Vanta筹集1.5亿美元，加速其AI产品创新](/post/id/298358)

  2024-07-25 15:02:41

### 热门推荐

文章目录

![](https://p0.qhimg.com/t11098f6bcd5614af4bf21ef9b5.png)

安全KER

* [关于我们](/about)
* [联系我们](/note/contact)
* [用户协议](/note/protocol)
* [隐私协议](/note/privacy)

商务合作

* [合作内容](/note/business)
* [联系方式](/note/contact)
* [友情链接](/link)

内容需知

* [投稿须知](https://www.anquanke.com/contribute/tips)
* [转载须知](/note/repost)
* 官网QQ群：568681302

合作单位

* [![安全KER](https://p0.ssl.qhimg.com/t01592a959354157bc0.png)](http://www.cert.org.cn/)
* [![安全KER](https://p0.ssl.qhimg.com/t014f76fcea94035e47.png)](http://www.cnnvd.org.cn/)

Copyright © 北京奇虎科技有限公司 三六零数字安全科技集团有限公司 安全KER All Rights Reserved [京ICP备08010314号-66](https://beian.miit.gov.cn/)[![](https://icon.cnzz.com/img/pic.gif)](https://www.cnzz.com/stat/website.php?web_id=1271278035 "站长统计")

微信二维码

**X**![安全KER](https://p0.ssl.qhimg.com/t0151209205b47f2270.jpg)