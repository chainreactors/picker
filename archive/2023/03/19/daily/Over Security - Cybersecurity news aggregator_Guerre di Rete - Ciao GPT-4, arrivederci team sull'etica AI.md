---
title: Guerre di Rete - Ciao GPT-4, arrivederci team sull'etica AI
url: https://guerredirete.substack.com/p/guerre-di-rete-ciao-gpt-4-arrivederci
source: Over Security - Cybersecurity news aggregator
date: 2023-03-19
fetch_date: 2025-10-04T10:03:22.404470
---

# Guerre di Rete - Ciao GPT-4, arrivederci team sull'etica AI

[![Guerre di Rete](https://substackcdn.com/image/fetch/$s_!JKxa!,w_80,h_80,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9c3cbe9e-1c39-4535-99d8-940270e03588_1010x1010.png)](/)

# [Guerre di Rete](/)

IscrivitiAccedi

# Guerre di Rete - Ciao GPT-4, arrivederci team sull'etica AI

### Trasparenza ed etica dell'AI. Il piano della Cina per il digitale.

[![Avatar di Carola Frediani](https://substackcdn.com/image/fetch/$s_!tOoV!,w_36,h_36,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9403bb00-3959-45dc-afb5-ac7994d708b8_750x741.jpeg)](https://substack.com/%40guerredirete)

[Carola Frediani](https://substack.com/%40guerredirete)

mar 18, 2023

20

Condividi

[![](https://substackcdn.com/image/fetch/$s_!wYsJ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa9c22fdf-9679-423c-aa6f-66050fbbca66_1086x856.png)](https://substackcdn.com/image/fetch/%24s_%21wYsJ%21%2Cf_auto%2Cq_auto%3Agood%2Cfl_progressive%3Asteep/https%3A//substack-post-media.s3.amazonaws.com/public/images/a9c22fdf-9679-423c-aa6f-66050fbbca66_1086x856.png)

**Guerre di Rete - una newsletter di notizie cyber
a cura di Carola Frediani
N.155 - 18 marzo 2023**

*Specie per i nuovi, ricordo che questa newsletter (che oggi conta più di 11mila iscritti - ma molti più lettori, essendo pubblicata anche online - e oltre 500 sostenitori) è gratuita e del tutto indipendente, non ha mai accettato sponsor o pubblicità, e viene fatta nel mio tempo libero. Se vi piace potete contribuire inoltrandola a possibili interessati, o promuovendola sui social. Molti lettori sono diventati sostenitori facendo una [donazione.](https://www.paypal.com/donate/?hosted_button_id=V8WAZ44NT942C) La prima campagna per raccogliere fondi è andata molto bene, e [qua ci sono i dettagli](https://guerredirete.substack.com/p/guerre-di-rete-vaccini-e-green-pass) (qua la [lista degli oltre 500 donator](https://associazione.guerredirete.it/donatori-di-guerre-di-rete/)i).*

[Dona alla newsletter](https://www.paypal.com/donate/?hosted_button_id=V8WAZ44NT942C)

*In più, a marzo il progetto si è ingrandito con un sito indipendente e noprofit di informazione cyber, [GuerrediRete.it](https://www.guerredirete.it/). Qui spieghiamo il [progetto](https://www.guerredirete.it/il-progetto/). Qui [l’editoriale](https://www.guerredirete.it/perche-e-il-momento-di-fare-e-informare/) di lancio del sito.*

**In questo numero:
- Ciao GPT-4, addio team sull’etica
- Trasparenza ed etica dell’AI
- Il grande piano della Cina per il dominio sul digitale
- Cloud, Spid e altro

Ciao GPT-4, arrivederci team sull’etica**
Nella settimana in cui la corsa all'intelligenza artificiale fa l'ennesimo balzo in avanti, le questioni etiche e soprattutto i team che si occupano di etica in relazione a questa tecnologia sono mollati indietro come un'inutile zavorra.

Microsoft ha licenziato l'intero gruppo di etica e società nella divisione di intelligenza artificiale, nell'ambito dei recenti licenziamenti che hanno colpito 10.000 dipendenti in tutta l'azienda.  “La mossa lascia Microsoft senza un team dedicato a garantire che i principi dell'AI siano strettamente legati alla progettazione dei prodotti”, in un momento in cui l'azienda è in prima linea per rendere questi strumenti disponibili al grande pubblico, [scrive](https://www.platformer.news/p/microsoft-just-laid-off-one-of-its) The Platformer. Malgrado Microsoft rassicuri sul suo impegno in relazione a uno sviluppo responsabile di questa tecnologia, e malgrado esista ancora un dipartimento dedicato a creare regole per governare le iniziative AI dell’azienda (Office of Responsible AI), quel team aveva un compito molto specifico e interessante. Si occupava cioè di riportare le dichiarazioni di principio nel design dei prodotti, insomma di applicarle.

“L'eliminazione del team Etica e società è avvenuta proprio quando i dipendenti rimasti si stavano concentrando sulla sfida più grande  - scrive ancora The Platformer - anticipare ciò che sarebbe accaduto quando Microsoft avrebbe rilasciato strumenti basati su OpenAI a un pubblico globale. L'anno scorso, il team ha redatto un promemoria che illustrava i rischi per il marchio associati a Bing Image Creator, [uno strumento] che utilizza il sistema DALL-E di OpenAI per creare immagini a partire da testi. (...) Sebbene la tecnologia text-to-image si sia dimostrata estremamente popolare, i ricercatori di Microsoft avevano correttamente previsto che avrebbe potuto anche minacciare il sostentamento degli artisti, consentendo a chiunque di copiare facilmente il loro stile. ‘Nel testare Bing Image Creator, si è scoperto che con una semplice richiesta che includeva solo il nome dell'artista e un mezzo (pittura, stampa, fotografia o scultura), le immagini generate erano quasi impossibili da distinguere dalle opere originali’, avevano scritto i ricercatori nella nota”.

**Ecco GPT-4**
Al di là di qualsiasi altra considerazione, il tempismo non poteva essere più simbolico. Infatti come sapete in questi giorni OpenAI ha annunciato GPT-4, il suo ultimo modello linguistico di AI che nella versione precedente abbiamo visto all’opera nel chatbot ChatGPT (e nel nuovo Bing che però, [è emerso ora](https://blogs.bing.com/search/march_2023/Confirmed-the-new-Bing-runs-on-OpenAI%E2%80%99s-GPT-4), stava già usando GPT-4). Non mi soffermo molto su GPT-4 perché ne ha scritto il mondo (qui un [pezzo](https://www.nytimes.com/2023/03/14/technology/openai-new-gpt4.html) riepilogativo del NYT). In sintesi, secondo OpenAI il nuovo modello (disponibile al grande pubblico tramite ChatGPT Plus, l'abbonamento mensile di OpenAI o attraverso Bing di Microsoft, dove è adattato alla ricerca) sarebbe "più creativo e collaborativo” e potrebbe “risolvere problemi difficili con maggiore precisione" mantenendo però molte delle precedenti criticità, tra cui la tendenza a inventare informazioni (o "allucinazioni") e la capacità di generare testi violenti e dannosi. Tra le novità più interessanti il fatto che possa analizzare input sia di testo che di immagine (anche se può rispondere solo tramite testo e per il pubblico per ora è solo testuale). Ma anche che appaia ancora più credibile a livello formale: [secondo](https://benparr.substack.com/p/the-implications-of-todays-huge-ai) il giornalista e imprenditore Ben Parr “gli strumenti esistenti per rilevare [testi prodotti da] l'intelligenza artificiale falliscono con GPT-4. L'ho appena testato: due diversi rilevatori di AI hanno pensato che un testo GPT-4 da me generato fosse umano al 100%”.

Per riassumere la strada fatta finora da questi modelli ricordiamo che il primo paper che descriveva GPT è stato pubblicato nel 2018, GPT-2 è stato annunciato nel 2019 e GPT-3 nel 2020. “Questi modelli vengono addestrati su enormi dataset di testi, in gran parte prelevati da Internet, che vengono analizzati per individuare modelli statistici”, [scrive](https://www.theverge.com/2023/3/14/23638033/openai-gpt-4-chatgpt-multimodal-deep-learning) The Verge.
Ora siamo arrivati a GPT-4 che nel suo r[eport tecnico](https://cdn.openai.com/papers/gpt-4.pdf) (firmato OpenAI) scrive: “Dato il panorama competitivo e le implicazioni per la sicurezza di modelli di grandi dimensioni come GPT-4, il presente rapporto non contiene ulteriori dettagli sull'architettura (comprese le dimensioni del modello), sull'hardware, sulla quantità di calcolo impiegata, sulla costruzione del set di dati, sul metodo di training o simili”.

**Trasparenza ed etica dell’AI**
Dunque non è dato sapere quasi nulla (tranne i successi, invece molto dettagliati), di questo modello, oscurità totale su informazioni cruciali per valutare tecnologie di questo tipo, con buona pace della parola “open” nel nome OpenAI.
“GPT-4 è la release più segreta che l'azienda abbia mai rilasciato...