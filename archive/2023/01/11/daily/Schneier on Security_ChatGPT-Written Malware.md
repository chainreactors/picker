---
title: ChatGPT-Written Malware
url: https://www.schneier.com/blog/archives/2023/01/chatgpt-written-malware.html
source: Schneier on Security
date: 2023-01-11
fetch_date: 2025-10-04T03:33:32.518559
---

# ChatGPT-Written Malware

# [Schneier on Security](https://www.schneier.com/)

Menu

* [Blog](https://www.schneier.com)
* [Newsletter](https://www.schneier.com/crypto-gram/)
* [Books](https://www.schneier.com/books/)
* [Essays](https://www.schneier.com/essays/)
* [News](https://www.schneier.com/news/)
* [Talks](https://www.schneier.com/talks/)
* [Academic](https://www.schneier.com/academic/)
* [About Me](https://www.schneier.com/blog/about/)

### Search

*Powered by [DuckDuckGo](https://duckduckgo.com/)*

Blog

Essays

Whole site

### Subscribe

[![Atom](https://www.schneier.com/wp-content/uploads/2019/10/rss-32px.png)](https://www.schneier.com/feed/atom/)[![Facebook](https://www.schneier.com/wp-content/uploads/2019/10/facebook-32px.png)](https://www.facebook.com/bruce.schneier)[![Twitter](https://www.schneier.com/wp-content/uploads/2019/10/twitter-32px.png)](https://twitter.com/schneierblog)[![Email](https://www.schneier.com/wp-content/uploads/2019/10/email-32px.png)](https://www.schneier.com/crypto-gram)

[Home](https://www.schneier.com)[Blog](https://www.schneier.com/blog/archives/)

## ChatGPT-Written Malware

I don’t know how much of a thing this will end up being, but we [are seeing](https://arstechnica.com/information-technology/2023/01/chatgpt-is-enabling-script-kiddies-to-write-functional-malware/) ChatGPT-written malware in the wild.

> …within a few weeks of ChatGPT going live, participants in cybercrime forums—­some with little or no coding experience­—were using it to write software and emails that could be used for espionage, ransomware, malicious spam, and other malicious tasks.
>
> “It’s still too early to decide whether or not ChatGPT capabilities will become the new favorite tool for participants in the Dark Web,” company researchers wrote. “However, the cybercriminal community has already shown significant interest and are jumping into this latest trend to generate malicious code.”
>
> Last month, one forum participant posted what they claimed was the first script they had written and credited the AI chatbot with providing a “nice [helping] hand to finish the script with a nice scope.”
>
> The Python code combined various cryptographic functions, including code signing, encryption, and decryption. One part of the script generated a key using elliptic curve cryptography and the curve ed25519 for signing files. Another part used a hard-coded password to encrypt system files using the Blowfish and Twofish algorithms. A third used RSA keys and digital signatures, message signing, and the blake2 hash function to compare various files.

Check Point Research [report](https://research.checkpoint.com/2023/opwnai-cybercriminals-starting-to-use-chatgpt/).

ChatGPT-generated code [isn’t that good](https://www.techtarget.com/searchsoftwarequality/news/252528379/ChatGPT-writes-code-but-wont-replace-developers), but it’s a start. And the technology will only get better. Where it matters here is that it gives less skilled hackers—script kiddies—new capabilities.

Tags: [chatbots](https://www.schneier.com/tag/chatbots/), [cybercrime](https://www.schneier.com/tag/cybercrime/), [encryption](https://www.schneier.com/tag/encryption/), [malware](https://www.schneier.com/tag/malware/)

[Posted on January 10, 2023 at 7:18 AM](https://www.schneier.com/blog/archives/2023/01/chatgpt-written-malware.html) •
[30 Comments](https://www.schneier.com/blog/archives/2023/01/chatgpt-written-malware.html#comments)

### Comments

Ted •
[January 10, 2023 9:03 AM](https://www.schneier.com/blog/archives/2023/01/chatgpt-written-malware.html/#comment-415314)

“Another part used a hard-coded password to encrypt system files using the Blowfish and Twofish algorithms.”

Oh wow.

I went to explore this, however I’m receiving the message: “ChatGPT is at capacity right now.”

It’s popular, that’s for sure.

I believe OpenAI implemented tools to promote responsible deployment. Will they be able to adjust these tools for code as well?

<https://openai.com/blog/language-model-safety-and-misuse/>

[Stéphane Bortzmeyer](https://www.bortzmeyer.org/) •
[January 10, 2023 9:16 AM](https://www.schneier.com/blog/archives/2023/01/chatgpt-written-malware.html/#comment-415317)

The report seems quite far-fetched. From my experience with ChatGPT, yes, it helps when you develop code, it automatizes some boring tasks such as reading the documentation but it also makes big mistakes and, if you’re not an expert, you cannot spot them. Also, asking questions to ChatGPT is an art in itself (I just asked it “Write code to encrypt all files on the hard disk (Windows operating system).” and the result is… interesting.)

Clive Robinson •
[January 10, 2023 10:52 AM](https://www.schneier.com/blog/archives/2023/01/chatgpt-written-malware.html/#comment-415321)

@ Bruce, ALL,

Re : Future Predictions.

> “I don’t know how much of a thing this will end up being, but we are seeing ChatGPT-written malware in the wild.”

A couple of days back I made my future predictions for cyber-attacks in 2023[1]…

Basically I said, it will be more or less the same as 2022 with phishing leading to ransomware, made easy by idiotic supply chains, only with an increasing use of AI or to quote myself,

> *“What might be new is cyber criminals –which includes government perps– likely will “polish the turd” using AI to make attacking the weak link in the chain “humans” easier.”*

The point is that the tools we have even as bad as they are –they are after all commercial / consumer software with all those failings– have got things to the point were attacking human failings is now easier than finding vulnerabilities. Even though we are discovering more than 200 vulnerabilities per day every working day that get CVE numbers…

The thing about the likes of AI chat bots and the like is their mistakes are generally not spelling, grammar, or vocabulary that give away most phishing attacks.

So geting them “to write the sell” puts detecting them on a different level, for near minimal effort by the attackers.

If an attacker can get sufficient messages from your boss, getting an AI chat bot to write in your bosses style is not going to be hard…

We have after all seen some AI generated comments poping up on this blog just recently.

@ MarkH and myself spoted one[2], but I suspect there are others that are getting through.

I expect this to become the norm for certain types that peddle “Fake News” but then want to “shut down” people who call them out on their fakes… An AI chat-bot could generate a hundred or more “Fake rebufs” in less time than it would take an individual to write a debunk.

Effectively giving truth to the observation that the effort to rebut a falsehood is significantly more than creating a falsehood.

[1] <https://www.schneier.com/blog/archives/2023/01/friday-squid-blogging-squid-fetish.html/#comment-415211>

[2] <https://www.schneier.com/blog/archives/2023/01/breaking-rsa-with-a-quantum-computer.html/#comment-415234>

Givon Zirkind •
[January 10, 2023 11:22 AM](https://www.schneier.com/blog/archives/2023/01/chatgpt-written-malware.html/#comment-415322)

I just saw this. There are text to sql attacks being launched this way. They are like sql injection attacks but, slightly different.

Aaron •
[January 10, 2023 11:49 AM](https://www.schneier.com/blog/archives/2023/01/chatgpt-written-malware.html/#comment-415323)

I’m less concerned about what ChatGPT v3.5 is creating today
I’m more concerned about what ChatGPT v17.0 will create in the future

“Just because we can, doesn’t always mean we should”

echo •
[January 10, 2023 12:32 PM](https://www.schneier.com/blog/archives/2023/01/chatgpt-written-malware.html/#comment-415325)

ChatGPT output makes as much sense and has as much credibility as a Russia government press release. Script kiddies like the Russians only get their strength through exploiting laziness and personality flaws and loopholes in administrative or technical systems.

Anyone who is caught by surprise by ChatGPT wasn’t doing their job prop...