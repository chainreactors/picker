---
title: 孙凝晖院士：人工智能与智能计算的发展
url: https://mp.weixin.qq.com/s?__biz=MzA5MzE5MDAzOA==&mid=2664212220&idx=2&sn=6ab711abc122eff78943b564a0efd15e&chksm=8b59a405bc2e2d1324a606d5ddd8d62e0973a431a8b3a7412881b5e3b5308013bb3199e72a08&scene=58&subscene=0#rd
source: 中国信息安全
date: 2024-05-05
fetch_date: 2025-10-06T17:16:03.431317
---

# 孙凝晖院士：人工智能与智能计算的发展

![cover_image](https://mmbiz.qpic.cn/sz_mmbiz_jpg/1brjUjbpg5wuA6lG6SMWESVo3gmH19DRibPH4oJlO5zPibXEZMMPF0jArFf5RjRgljzrkFqxGibMyoMWGHVlYIeXA/0?wx_fmt=jpeg)

# 孙凝晖院士：人工智能与智能计算的发展

孙凝晖

中国信息安全

![](https://mmbiz.qpic.cn/sz_mmbiz_gif/1brjUjbpg5wuA6lG6SMWESVo3gmH19DRHTEWWGicItNQ7ic2YsAA6AZPNJyDNl0y5JEblXrebCWvFkntqFZJO4cg/640?wx_fmt=gif&from=appmsg)

![](https://mmbiz.qpic.cn/sz_mmbiz_gif/1brjUjbpg5wuA6lG6SMWESVo3gmH19DRHTEWWGicItNQ7ic2YsAA6AZPNJyDNl0y5JEblXrebCWvFkntqFZJO4cg/640?wx_fmt=gif&from=appmsg)

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/1brjUjbpg5wuA6lG6SMWESVo3gmH19DR8oaYIncxcafoDJg8RaaMBuQDdxNRd3oL5KYribWTVSq4k0cWUkXFxcw/640?wx_fmt=jpeg&from=appmsg)

![](https://mmbiz.qpic.cn/sz_mmbiz_gif/1brjUjbpg5wuA6lG6SMWESVo3gmH19DRHTEWWGicItNQ7ic2YsAA6AZPNJyDNl0y5JEblXrebCWvFkntqFZJO4cg/640?wx_fmt=gif&from=appmsg)

![](https://mmbiz.qpic.cn/sz_mmbiz_gif/1brjUjbpg5wuA6lG6SMWESVo3gmH19DRHTEWWGicItNQ7ic2YsAA6AZPNJyDNl0y5JEblXrebCWvFkntqFZJO4cg/640?wx_fmt=gif&from=appmsg)

**扫码订阅《中国信息安全》**

邮发代号 2-786

征订热线：010-82341063

十四届全国人大常委会专题讲座第十讲讲稿

**人工智能与智能计算的发展**

中国工程院院士，中国科学院计算技术研究所研究员、学术委员会主任

孙凝晖

委员长、各位副委员长、秘书长、各位委员：

人工智能领域近年来正在迎来一场由生成式人工智能大模型引领的爆发式发展。2022年11月30日，OpenAI公司推出一款人工智能对话聊天机器人ChatGPT，其出色的自然语言生成能力引起了全世界范围的广泛关注，2个月突破1亿用户，国内外随即掀起了一场大模型浪潮，Gemini、文心一言、Copilot、LLaMA、SAM、SORA等各种大模型如雨后春笋般涌现，2022年也被誉为大模型元年。当前信息时代正加快进入智能计算的发展阶段，人工智能技术上的突破层出不穷，逐渐深入地赋能千行百业，推动人工智能与数据要素成为新质生产力的典型代表。习近平总书记指出，把新一代人工智能作为推动科技跨越发展、产业优化升级、生产力整体跃升的驱动力量，努力实现高质量发展。党的十八大以来，以习近平同志为核心的党中央高度重视智能经济发展，促进人工智能和实体经济深度融合，为高质量发展注入强劲动力。

**一、计算技术发展简介**

计算技术的发展历史大致可分为四个阶段，算盘的出现标志着人类进入第一代——机械计算时代，第二代——电子计算的标志是出现电子器件与电子计算机，互联网的出现使我们进入第三代——网络计算，当前人类社会正在进入第四阶段——智能计算。

早期的计算装置是手动辅助计算装置和半自动计算装置，人类计算工具的历史是从公元1200年的中国算盘开始，随后出现了纳皮尔筹（1612年）和滚轮式加法器（1642年），到1672年第一台自动完成四则运算的计算装置——步进计算器诞生了。

机械计算时期已经出现了现代计算机的一些基本概念。查尔斯∙巴贝奇（Charles Babbage）提出了差分机（1822年）与分析机（1834年）的设计构想，支持自动机械计算。这一时期，编程与程序的概念基本形成，编程的概念起源于雅卡尔提花机，通过打孔卡片控制印花图案，最终演变为通过计算指令的形式来存储所有数学计算步骤；人类历史的第一个程序员是诗人拜伦之女艾达（Ada），她为巴贝奇差分机编写了一组求解伯努利数列的计算指令，这套指令也是人类历史上第一套计算机算法程序，它将硬件和软件分离，第一次出现程序的概念。

直到在二十世纪上半叶，出现了布尔代数(数学)、图灵机(计算模型) 、冯诺依曼体系结构(架构) 、晶体管(器件)这四个现代计算技术的科学基础。其中，布尔代数用来描述程序和硬件如CPU的底层逻辑；图灵机是一种通用的计算模型，将复杂任务转化为自动计算、不需人工干预的自动化过程；冯诺依曼体系结构提出了构造计算机的三个基本原则：采用二进制逻辑、程序存储执行、以及计算机由运算器、控制器、存储器、输入设备、输出设备这五个基本单元组成；晶体管是构成基本的逻辑电路和存储电路的半导体器件，是建造现代计算机之塔的“砖块”。基于以上科学基础，计算技术得以高速发展，形成规模庞大的产业。

从1946年世界上第一台电子计算机ENIAC诞生到二十一世纪的今天，已经形成了五类成功的平台型计算系统。当前各领域各种类型的应用，都可以由这五类平台型计算装置支撑。第一类是高性能计算平台，解决了国家核心部门的科学与工程计算问题；第二类是企业计算平台，又称服务器，用于企业级的数据管理、事务处理，当前像百度、阿里和腾讯这些互联网公司的计算平台都属于这一类；第三类是个人电脑平台，以桌面应用的形式出现，人们通过桌面应用与个人电脑交互；第四类是智能手机，主要特点是移动便携，手机通过网络连接数据中心，以互联网应用为主，它们分布式地部署在数据中心和手机终端；第五类是嵌入式计算机，嵌入到工业装备和军事设备，通过实时的控制，保障在确定时间内完成特定任务。这五类装置几乎覆盖了我们信息社会的方方面面，长期以来人们追求的以智能计算应用为中心的第六类平台型计算系统尚未形成。

现代计算技术的发展大致可以划分为三个时代。IT1.0又称电子计算时代（1950-1970），基本特征是以“机”为中心。计算技术的基本架构形成，随着集成电路工艺的进步，基本计算单元的尺度快速微缩，晶体管密度、计算性能和可靠性不断提升，计算机在科学工程计算、企业数据处理中得到了广泛应用。

IT2.0又称网络计算时代（1980-2020），以“人”为中心。互联网将人使用的终端与后台的数据中心连接，互联网应用通过智能终端与人进行交互。以亚马逊等为代表的互联网公司提出了云计算的思想，将后台的算力封装成一个公共服务租借给第三方用户，形成了云计算与大数据产业。

IT3.0又称智能计算时代，始于2020年，与IT2.0相比增加了“物”的概念，即物理世界的各种端侧设备，被数字化、网络化和智能化，实现“人-机-物”三元融合。智能计算时代，除了互联网以外，还有数据基础设施，支撑各类终端通过端边云实现万物互联，终端、物端、边缘、云都嵌入AI，提供与ChatGPT类似的大模型智能服务，最终实现有计算的地方就有AI智能。智能计算带来了巨量的数据、人工智能算法的突破和对算力的爆发性需求。

**二、智能计算发展简介**

智能计算包括人工智能技术与它的计算载体，大致历经了四个阶段，分别为通用计算装置、逻辑推理专家系统、深度学习计算系统、大模型计算系统。

智能计算的起点是通用自动计算装置（1946年）。艾伦·图灵（Alan Turing）和冯·诺依曼（John von Neumann）等科学家，一开始都希望能够模拟人脑处理知识的过程，发明像人脑一样思考的机器，虽未能实现，但却解决了计算的自动化问题。通用自动计算装置的出现，也推动了1956年人工智能（AI）概念的诞生，此后所有人工智能技术的发展都是建立在新一代计算设备与更强的计算能力之上的。

智能计算发展的第二阶段是逻辑推理专家系统（1990年）。E.A.费根鲍姆（Edward Albert Feigenbaum）等符号智能学派的科学家以逻辑和推理能力自动化为主要目标，提出了能够将知识符号进行逻辑推理的专家系统。人的先验知识以知识符号的形式进入计算机，使计算机能够在特定领域辅助人类进行一定的逻辑判断和决策，但专家系统严重依赖于手工生成的知识库或规则库。这类专家系统的典型代表是日本的五代机和我国863计划支持的306智能计算机主题，日本在逻辑专家系统中采取专用计算平台和Prolog这样的知识推理语言完成应用级推理任务；我国采取了与日本不同的技术路线，以通用计算平台为基础，将智能任务变成人工智能算法，将硬件和系统软件都接入通用计算平台，并催生了曙光、汉王、科大讯飞等一批骨干企业。

符号计算系统的局限性在于其爆炸的计算时空复杂度，即符号计算系统只能解决线性增长问题，对于高维复杂空间问题是无法求解的，从而限制了能够处理问题的大小。同时因为符号计算系统是基于知识规则建立的，我们又无法对所有的常识用穷举法来进行枚举，它的应用范围就受到了很大的限制。随着第二次AI寒冬的到来，第一代智能计算机逐渐退出历史舞台。

直到2014年左右，智能计算进阶到第三阶段——深度学习计算系统。以杰弗里·辛顿（Geoffrey Hinton）等为代表的连接智能学派，以学习能力自动化为目标，发明了深度学习等新AI算法。通过深度神经元网络的自动学习，大幅提升了模型统计归纳的能力，在模式识别等应用效果上取得了巨大突破，某些场景的识别精度甚至超越了人类。以人脸识别为例，整个神经网络的训练过程相当于一个网络参数调整的过程，将大量的经过标注的人脸图片数据输入神经网络，然后进行网络间参数调整，让神经网络输出的结果的概率无限逼近真实结果。神经网络输出真实情况的概率越大，参数就越大，从而将知识和规则编码到网络参数中，这样只要数据足够多，就可以对各种大量的常识进行学习，通用性得到极大的提升。连接智能的应用更加广泛，包括语音识别、人脸识别、自动驾驶等。在计算载体方面，中国科学院计算技术研究所2013年提出了国际首个深度学习处理器架构，国际知名的硬件厂商英伟达（NVIDIA）持续发布了多款性能领先的通用GPU芯片，都是深度学习计算系统的典型代表。

智能计算发展的第四阶段是大模型计算系统（2020年）。在人工智能大模型技术的推动下，智能计算迈向新的高度。2020年，AI从“小模型+判别式”转向“大模型+生成式”，从传统的人脸识别、目标检测、文本分类，升级到如今的文本生成、3D数字人生成、图像生成、语音生成、视频生成。大语言模型在对话系统领域的一个典型应用是OpenAI公司的ChatGPT，它采用预训练基座大语言模型GPT-3，引入3000亿单词的训练语料，相当于互联网上所有英语文字的总和。其基本原理是：通过给它一个输入，让它预测下一个单词来训练模型，通过大量训练提升预测精确度，最终达到向它询问一个问题，大模型产生一个答案，与人即时对话。在基座大模型的基础上，再给它一些提示词进行有监督的指令微调，通过人类的<指令，回复>对逐渐让模型学会如何与人进行多轮对话；最后，通过人为设计和自动生成的奖励函数来进行强化学习迭代，逐步实现大模型与人类价值观的对齐。

大模型的特点是以“大”取胜，其中有三层含义，（1）参数大，GPT-3就有1700亿个参数；（2）训练数据大，ChatGPT大约用了3000亿个单词，570GB训练数据；（3）算力需求大，GPT-3大约用了上万块V100 GPU进行训练。为满足大模型对智能算力爆炸式增加的需求，国内外都在大规模建设耗资巨大的新型智算中心，英伟达公司也推出了采用256个H100芯片，150TB海量GPU内存等构成的大模型智能计算系统。

大模型的出现带来了三个变革。一是技术上的规模定律（Scaling Law），即很多AI模型的精度在参数规模超过某个阈值后模型能力快速提升，其原因在科学界还不是非常清楚，有很大的争议。AI模型的性能与模型参数规模、数据集大小、算力总量三个变量成“对数线性关系”，因此可以通过增大模型的规模来不断提高模型的性能。目前最前沿的大模型GPT-4参数量已经达到了万亿到十万亿量级，并且仍在不断增长中；二是产业上算力需求爆炸式增长，千亿参数规模大模型的训练通常需要在数千乃至数万GPU卡上训练2-3个月时间，急剧增加的算力需求带动相关算力企业超高速发展，英伟达的市值接近两万亿美元，对于芯片企业以前从来没有发生过；三是社会上冲击劳动力市场，北京大学国家发展研究院与智联招聘联合发布的《AI大模型对我国劳动力市场潜在影响研究》报告指出，受影响最大的20个职业中财会、销售、文书位于前列，需要与人打交道并提供服务的体力劳动型工作，如人力资源、行政、后勤等反而相对更安全。

人工智能的技术前沿将朝着以下四个方向发展。**第一个前沿方向为多模态大模型。**从人类视角出发，人类智能是天然多模态的，人拥有眼、耳、鼻、舌、身、嘴(语言)，从AI视角出发，视觉，听觉等也都可以建模为token的序列，可采取与大语言模型相同的方法进行学习，并进一步与语言中的语义进行对齐，实现多模态对齐的智能能力。

**第二个前沿方向为视频生成大模型。**OpenAI于2024年2月15日发布文生视频模型SORA，将视频生成时长从几秒钟大幅提升到一分钟，且在分辨率、画面真实度、时序一致性等方面都有显著提升。SORA的最大意义是它具备了世界模型的基本特征，即人类观察世界并进一步预测世界的能力。世界模型是建立在理解世界的基本物理常识（如，水往低处流等）之上，然后观察并预测下一秒将要发生什么事件。虽然SORA要成为世界模型仍然存在很多问题，但可以认为SORA学会了画面想象力和分钟级未来预测能力，这是世界模型的基础特征。

**第三个前沿方向为具身智能。**具身智能指有身体并支持与物理世界进行交互的智能体，如机器人、无人车等，通过多模态大模型处理多种传感数据输入，由大模型生成运动指令对智能体进行驱动，替代传统基于规则或者数学公式的运动驱动方式，实现虚拟和现实的深度融合。因此，具有具身智能的机器人，可以聚集人工智能的三大流派：以神经网络为代表的连接主义，以知识工程为代表的符号主义和控制论相关的行为主义，三大流派可以同时作用在一个智能体，这预期会带来新的技术突破。

**第四个前沿方向是AI4R(AI for Research)成为科学发现与技术发明的主要范式。**当前科学发现主要依赖于实验和人脑智慧，由人类进行大胆猜想、小心求证，信息技术无论是计算和数据，都只是起到一些辅助和验证的作用。相较于人类，人工智能在记忆力、高维复杂、全视野、推理深度、猜想等方面具有较大优势，是否能以AI为主进行一些科学发现和技术发明，大幅提升人类科学发现的效率，比如主动发现物理学规律、预测蛋白质结构、设计高性能芯片、高效合成新药等。因为人工智能大模型具有全量数据，具备上帝视角，通过深度学习的能力，可以比人向前看更多步数，如能实现从推断(inference)到推理(reasoning)的跃升，人工智能模型就有潜力具备爱因斯坦一样的想象力和科学猜想能力，极大提升人类科学发现的效率，打破人类的认知边界。这才是真正的颠覆所在。

最后，通用人工智能（Artificial General Intelligence，简称AGI）是一个极具挑战的话题，极具争论性。曾经有一个哲学家和一个神经科学家打赌：25年后（即2023年）科研人员是否能够揭示大脑如何实现意识？当时关于意识有两个流派，一个叫集成信息理论，一个叫全局网络工作空间理论，前者认为意识是由大脑中特定类型神经元连接形成的“结构”，后者指出意识是当信息通过互连网络传播到大脑区域时产生的。2023年，人们通过六个独立实验室进行了对抗性实验，结果与两种理论均不完全匹配，哲学家赢了，神经科学家输了。通过这一场赌约，可以看出人们总是希望人工智能能够了解人类的认知和大脑的奥秘。从物理学的视角看，物理学是对宏观世界有了透彻理解后，从量子物理起步开启了对微观世界的理解。智能世界与物理世界一样，都是具有巨大复杂度的研究对象，AI大模型仍然是通过数据驱动等研究宏观世界的方法，提高机器的智能水平，对智能宏观世界理解并不够，直接到神经系统微观世界寻找答案是困难的。人工智能自诞生以来，一直承载着人类关于智能与意识的种种梦想与幻想，也激励着人们不断探索。

**三、人工智能的安全风险**

人工智能的发展促进了当今世界科技进步的同时，也带来了很多安全风险，要从技术与法规两方面加以应对。

**首先是互联网虚假信息泛滥。**这里列举若干场景：**一是数字分身。**AI Yoon是首个使用 DeepFake 技术合成的官方“候选人”，这个数字人以韩国国民力量党候选人尹锡悦（Yoon Suk-yeol）为原型，借助尹锡悦 20 小时的音频和视频片段、以及其专门为研究人员录制的 3000 多个句子，由当地一家 DeepFake 技术公司创建了虚拟形象 AI Yoon，并在网络上迅速走红。实际上 AI Yoon 表达的内容是由竞选团队撰写的，而不是候选人本人。

**二是伪造视频，**尤其是伪造领导人视频引起国际争端，扰乱选举秩序，或引起突发舆情事件，如伪造尼克松宣布第一次登月失败，伪造乌克兰总统泽连斯基宣布“投降”的信息，这些行为导致新闻媒体行业的社会信任衰退。

**三是伪造新闻，**主要通过虚假新闻自动生成牟取非法利益，使用ChatGPT生成热点新闻，赚取流量，截至2023年6月30日全球生成伪造新闻网站已达277个，严重扰乱社会秩序。

**四是换脸变声，**用于诈骗。如由于AI语音模仿了企业高管的声音，一家香港国际企业因此被骗3500万美元。

**五是生成不雅图片，**特别是针对公众人物。如影视明星的色情视频制作，造成不良社会影响。因此，迫切需要发展互联网虚假信息的伪造检测技术。

**其次，AI大模型面临严重可信问题。**这些问题包括：（1）“一本正经胡说八道”的事实性错误；（2）以西方价值观叙事，输出政治偏见和错误言论；（3）易被诱导，输出错误知识和有害内容；（4）数据安全问题加重，大模型成为重要敏感数据的诱捕器，ChatGPT将用户输入纳入训练数据库，用于改善ChatGPT，美方能够利用大模型获得公开渠道覆盖不到的中文语料，掌握我们自己都可能不掌握的“中国知识”。因此，迫切需要发展大模型安全监管技术与自己的可信大模型。

除了技术手段外，人工智能安全保障需要相关立法工作。2021年科技部发布《新一代人工智能伦理规范》，2022年8月，全国信息安全标准化技术委员会发布《信息安全技术 机器学习算法安全评估规范》，2022-2023年，中央网信办先后发布《互联网信息服务算法推荐管理规定》《互联网信息服务深度合成管理规定》《生成式人工智能服务管理办法》等。欧美国家也先后出台法规，2018...