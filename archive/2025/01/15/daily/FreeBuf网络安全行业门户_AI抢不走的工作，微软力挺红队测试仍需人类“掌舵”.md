---
title: AI抢不走的工作，微软力挺红队测试仍需人类“掌舵”
url: https://www.freebuf.com/news/419782.html
source: FreeBuf网络安全行业门户
date: 2025-01-15
fetch_date: 2025-10-06T20:10:35.199846
---

# AI抢不走的工作，微软力挺红队测试仍需人类“掌舵”

[![freeBuf](/images/logoMax.png)](/)

主站

分类

云安全

AI安全

开发安全

终端安全

数据安全

Web安全

基础安全

企业安全

关基安全

移动安全

系统安全

其他安全

特色

热点

工具

漏洞

人物志

活动

安全招聘

攻防演练

政策法规

[报告](https://www.freebuf.com/report)[专辑](/column)

* ···
* [公开课](https://live.freebuf.com)
* ···
* [商城](https://shop.freebuf.com)
* ···
* 用户服务
* ···

行业服务

政 府

CNCERT
CNNVD

会员体系（甲方）
会员体系（厂商）
产品名录
企业空间

[知识大陆](https://wiki.freebuf.com/page)

搜索

![](/freebuf/img/7aa3bf7.svg) ![](/freebuf/img/181d733.svg)

创作中心

[登录](https://www.freebuf.com/oauth)[注册](https://www.freebuf.com/oauth)

官方公众号企业安全新浪微博

![](/images/gzh_code.jpg)

FreeBuf.COM网络安全行业门户，每日发布专业的安全资讯、技术剖析。

![FreeBuf+小程序](/images/xcx-code.jpg)

FreeBuf+小程序把安全装进口袋

[![](https://image.3001.net/images/20231020/1697804527_653270ef7570cc7356ba8.png)](https://wiki.freebuf.com)

AI抢不走的工作，微软力挺红队测试仍需人类“掌舵”

* ![]()
* 关注

* [资讯](https://www.freebuf.com/news)

AI抢不走的工作，微软力挺红队测试仍需人类“掌舵”

2025-01-14 10:32:41

所属地 上海

![](https://image.3001.net/images/20250114/1736824239_6785d5af72ba6876cf342.png!small)

随着AI的快速发展，安全专家担心人工智能会取代他们的工作，但微软的研究人员坚持认为，有效的红队测试仍然依赖于人类的专业知识、文化意识和情商——这些品质是机器无法复制的。

微软的AI红队严格测试了100多款生成式AI产品，并确定人类的创造力在发现漏洞，以及预测黑客如何利用这些系统方面仍然至关重要。

根据雷德蒙德AI红队发布的白皮书，其开源的PyRIT（Python风险识别工具包）等工具可以简化模拟黑客攻击，但最终，在处理复杂风险方面，人类的参与仍然不可替代。

在网络安全医学、化学或生物风险等专业领域，微软坚持认为，人类驱动的专业知识是必不可少的，才能正确、精确地评估人工智能的响应，这远远超出了语言模型的能力。

在网络安全医学、化学或生物风险等专业领域，微软坚持认为，想要精确评估AI的响应，人类专家的专业知识必不可少，而这远远超出了语言模型的能力范围。

微软表示：“在多次操作中，我们依赖‘人类’来评估我们自己或使用大型语言模型（LLMs）无法评估的内容风险”，并强调“AI红队意识到这些局限性非常重要”。

公司研究团队还强调了所谓的“文化能力”，即红队必须考虑语言和文化差异，以识别可能被主要基于英语数据集训练的AI模型忽视的安全风险。

同时研究团队指出：“AI红队中的人类元素在回答需要情商的AI安全问题时最为明显。”例如“这个模型响应在不同情境下会如何被解读？”以及“这些输出是否让我感到不适？”等问题只有人类操作员才能解析。

微软补充表示：“最终，只有人类操作员才能评估用户在实际环境中与AI系统进行的全部互动。”

该论文还包括一个案例研究，在这个案例中，微软红队评估了聊天机器人对陷入困境用户的回应，以此来调查“心理社会危害”。并警告说，红队成员可能会接触到大量“令人不安和困扰的AI生成的内容”。

微软表示：“这凸显了很重要的一点，AI红队要拥有能让操作员在需要时脱离工作的流程，还要有支持他们心理健康的资源。”

研究人员警告称，生成式AI模型在现代应用中的集成引入了新的攻击向量，其中一个案例是，视频处理AI应用中的一个过时的FFmpeg组件引入了服务器端请求伪造（SSRF）漏洞，允许恶意黑客提升系统权限。

研究团队表示：“AI模型通过引入新的漏洞扩大了攻击面。”并指出，提示注入攻击利用了AI模型通常难以区分系统级指令和用户数据的事实。

**参考来源：**

> <https://www.securityweek.com/ai-wont-take-this-job-microsoft-says-human-ingenuity-crucial-to-red-teaming/>

# AI安全 # 红队开发

本文为 独立观点，未经授权禁止转载。
如需授权、对文章有疑问或需删除稿件，请联系 FreeBuf
客服小蜜蜂（微信：freebee1024）

被以下专辑收录，发现更多精彩内容

+ 收入我的专辑

+ 加入我的收藏

展开更多

相关推荐

![]()

关 注

* 0 文章数
* 0 关注者

![](/images/logo_b.png)

本站由阿里云 提供计算与安全服务

### 用户服务

* [有奖投稿](https://www.freebuf.com/write)
* [提交漏洞](https://www.vulbox.com/bounties/detail-72)
* [参与众测](https://www.vulbox.com/projects/list)
* [商城](https://shop.freebuf.com)

### 企业服务

* [安全咨询](https://company.freebuf.com)
* [产业全景图](https://www.freebuf.com/news/307349.html)
* [企业SRC](https://www.vulbox.com/service/src)
* [安全众测](https://www.vulbox.com/)

### 合作信息

* [斗象官网](https://www.tophant.com/)
* [广告投放](https://www.freebuf.com/articles/444331.html)
* [联系我们](https://www.freebuf.com/articles/444332.html)

### 关于我们

* [关于我们](https://www.freebuf.com/news/others/864.html)
* 微信公众号
* [新浪微博](http://weibo.com/freebuf)

### 战略伙伴

* [![](https://image.3001.net/images/20191017/1571306518_5da83c1686dd9.png)](http://www.aliyun.com/?freebuf)

### FreeBuf知识大陆

![](https://image.3001.net/images/20250703/1751535036_68664dbcae34ac40bb9e7.png)

扫码把安全装进口袋

* [斗象科技](https://www.tophant.com/)
* [FreeBuf](https://www.freebuf.com)
* [漏洞盒子](https://www.vulbox.com/)
* [斗象智能安全](https://ai.tophant.com/)
* [免责条款](https://www.freebuf.com/dis)
* [协议条款](https://my.freebuf.com/AgreeProtocol/duty)

Copyright © 2025 WWW.FREEBUF.COM All Rights Reserved
[沪ICP备2024099014号](https://beian.miit.gov.cn/#/Integrated/index) | [沪公安网备
![](https://image.3001.net/images/20200106/1578291342_5e12d08ec2379.png)](http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=31011502009321)