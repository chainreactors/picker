---
title: 大语言模型加速供应链攻击，只是时间问题
url: https://mp.weixin.qq.com/s?__biz=MzI2NTg4OTc5Nw==&mid=2247521932&idx=2&sn=ca363bafcb541f84bed911b9db4e071d&chksm=ea94a7e6dde32ef0dcd29411574233d316ebcf82ea07330fd6d077253bd25035507563202ca6&scene=58&subscene=0#rd
source: 代码卫士
date: 2024-12-31
fetch_date: 2025-10-06T19:41:16.715643
---

# 大语言模型加速供应链攻击，只是时间问题

![cover_image](https://mmbiz.qpic.cn/mmbiz_jpg/oBANLWYScMRicoqpSXwETiazJtyJ4LKibhGtBEKXg3GiaOLf9XqZ7SHicf7rBwociaLTZNgLt1D4P4iaqn9G6IsYKuguQ/0?wx_fmt=jpeg)

# 大语言模型加速供应链攻击，只是时间问题

Jessica Lyons

代码卫士

![](https://mmbiz.qpic.cn/mmbiz_gif/Az5ZsrEic9ot90z9etZLlU7OTaPOdibteeibJMMmbwc29aJlDOmUicibIRoLdcuEQjtHQ2qjVtZBt0M5eVbYoQzlHiaw/640?wx_fmt=gif) 聚焦源代码安全，网罗国内外最新资讯！

**编译：代码卫士**

**既然犯罪分子已经意识到无需训练自己的大模型 (LLMs) 实现任何恶意目的，因为窃取凭据之后破解现有凭据更便宜快捷，那么使用生成式AI的大规模供应链攻击的威胁变得更加真实。**

![](https://mmbiz.qpic.cn/mmbiz_png/oBANLWYScMRicoqpSXwETiazJtyJ4LKibhGxy2loicNAs99ksm8bVPD7icade5lNf7OBicvAQ5KFAibF3S4u5CfoaFIYw/640?wx_fmt=png&from=appmsg)

我们并非讨论从初始访问权限到导致商业运营关闭的完整的AI生成式攻击。从技术上来讲，犯罪分子尚未达到这一水平。不过，LLMs 变得越来越得心应手的是协助社工攻击。

而这，也是为何美国空军的前情报分析师、现任 Sysdig 公司网络安全战略家的 Crystal Morin 认为2025年预测将看到因LLM生成的鱼叉式钓鱼攻击而导致供应链攻击高度成功的原因所在。

在提到使用LLMs时，Morin 表示，“和我们一样，威胁行动者正在学习和理解并攻城略地。我们目前处于跑步比赛状态。这是机器之间的对决。”

Sysdig 公司与其他研究员在2024年发现，使用被盗云凭据访问LLMs 的攻击活动增多。5月份，该公司记录了针对Anthropic公司Claude LLM 模型的攻击活动。虽然攻击者本可利用该访问权限提取 LLM 训练数据，但他们在这类型攻击中的主要目标似乎是将访问权限出售给其它犯罪分子。这就导致涵盖云账户的所有人买单，与LLM使用成本有关的价格每天高达4.6万美元。

研究人员深挖后发现，这起攻击中使用更广的脚本能够查看10家不同AI服务的凭据：AI21 Labs、Anthropic、AWS Bedrock、Azure、ElevenLabs、MakerSuite、Mistral、OpenAI、OpenRouter 和GCP Vertex AI。

2023年年末，Sysdig 公司发现攻击者试图使用被盗凭据启用LLMs。研究人员将非法获取对模型访问权限的任何尝试都称为 “LLM劫持”，他们在9月份发现这类攻击“正在增多，7月份一个月LLM请求增加了10倍，在2024年上半年参与这些攻击的唯一IP地址数量增长了2倍”。这些攻击不仅使受害者损失大量钱财，当受害者所在组织机构使用更新的模型如 Calude 3 Opus 时，每天的费用在10万美元。另外，受害者被迫为人员和技术付费以阻止这些攻击。企业LLMs也可能面临遭武器化的风险，从而导致发生进一步的潜在费用。

**2025：LLM钓鱼攻击之年？**

![](https://mmbiz.qpic.cn/mmbiz_gif/oBANLWYScMRicoqpSXwETiazJtyJ4LKibhGrCeUjFqk2YDEsTQUV2Sqb7jKJ5GgSGUrOnrHtarXFpWHSSrtoVS76A/640?wx_fmt=gif&from=appmsg)

Morin 表示，2025年“最大的担忧是鱼叉式钓鱼和社工攻击。获得LLM访问权限的方法有无数种，他们可根据目标的受雇单位、购物偏好、所使用银行、所生活地区、该地区的饭店等消息，使用该GenAI构造唯一的、定制化消息发给目标。”

除了帮助攻击者客服语言障碍外，这种方法能够让通过邮件或社交媒体消息应用发送的消息看似更加令人信服，因为这些消息是专门为个人受害者构造的。Morin 提到，“他们会从街道或者附近受欢迎的这个饭店给你发送一条消息，希望你会点击它，这样就会很大程度上提升他们的成功率。这就是为什么会发生很多攻陷事件的过程，它就是人对人的初始访问权限。”

她提到了 Change Healthcare 勒索攻击作为2024年损害巨大的攻陷事件。不过应该注意的是，并未有证据表明该事件获得了LLM的协助。在本案例中，勒索团伙锁定了 Change Healthcare 的系统，扰乱了美国数千家药房和医院病访问了约1亿名人员的私人数据。该医疗付款巨头花费了9个月的时间才从攻击后恢复了交换中心的服务。

Morin 提到，“说回鱼叉式钓鱼攻击：假设Change Healthcare 的一名员工收到一封邮件并点击链接的场景。攻击者就能够访问他们的凭据，或者访问该环境，攻击者就能闯入系统并横向移动。”我们何时并是否会看到这种GenAI 协助攻击案例，“它将会是一个非常小型的简单的攻击部分但可能产生巨大影响”。

创业公司和已有企业正在发布安全工具，它们也使用AI检测并阻止邮件钓鱼攻击，每个人都可通过一些非常简单的步骤避免落入任何钓鱼攻击类型，“对自己点击的内容一定要小心。”

**三思而点**

![](https://mmbiz.qpic.cn/mmbiz_gif/oBANLWYScMRicoqpSXwETiazJtyJ4LKibhGrCeUjFqk2YDEsTQUV2Sqb7jKJ5GgSGUrOnrHtarXFpWHSSrtoVS76A/640?wx_fmt=gif&from=appmsg)

另外，密切注意邮件发送人员。她还补充表示，“不管邮件主体内容看似多么好，你注意查看邮件地址了吗？里面会有一些疯狂的字符串或者奇怪的地址如 name@gmail 但它声称发自 Verizon？这是不合理的。”

LLMs也可基于合法的为人熟知的企业名称，通过不同的字母数字为犯罪分子构建一个域名，它们可使用多种提示让发件人看似更加可信。即使是语音通话钓鱼邮件也可能因为语音克隆AI的存在而变得真假难分。

她提到，“我一天能从全国收到五通垃圾电话，我就直接无视，因为我的手机告知我它们是垃圾邮件。但它们现在也在使用语音克隆。多数时候人们接听电话时，尤其是开车或者干别的事情时，并没有在积极听，可能不会注意到它是一种语音克隆，尤其是听起来像某个熟悉的人的语音，或者他们所说的看似是可信的，而且他们听起来确实像与你有关的银行的。”在2024年美国总统大选助选活动中，就有AI生成的机器通话模拟拜登总统，督促选举人员不要参与该州的总统初选活动。之后，美国食品药品监督管理局 (FTC) 就悬赏2.5万美元寻求对抗AI语音克隆的最佳方法，美国联邦通信委员会 (FCC) 也宣布称AI生成的机器人通话是非法行为。

Morin 认为这并不能震慑犯罪分子。她认为，“有志者事竟成。如果说需要花钱，那么他们就会想办法免费获取到。”

代码卫士试用地址：https://codesafe.qianxin.com

开源卫士试用地址：https://oss.qianxin.com

---

---

**推荐阅读**

[在线阅读版：《2024中国软件供应链安全分析报告》全文](https://mp.weixin.qq.com/s?__biz=MzI2NTg4OTc5Nw==&mid=2247520484&idx=1&sn=8a845b39720a318c297075e98f5fe5e0&scene=21#wechat_redirect)

[ShadowLogic 技术利用AI模型图创建无代码后门，可引发供应链攻击](https://mp.weixin.qq.com/s?__biz=MzI2NTg4OTc5Nw==&mid=2247521075&idx=2&sn=78b278425ea0267c473467bfb24894f2&scene=21#wechat_redirect)

[RSAC 2024观察：软件供应链安全进入AI+时代](https://mp.weixin.qq.com/s?__biz=MzI2NTg4OTc5Nw==&mid=2247519497&idx=1&sn=3f531af375c16bd26e01ca94f96d2f6b&scene=21#wechat_redirect)

[SAP AI Core中严重的 “SAPwned” 缺陷可引发供应链攻击](https://mp.weixin.qq.com/s?__biz=MzI2NTg4OTc5Nw==&mid=2247520194&idx=2&sn=7b4dbeae684f3e9a1f79148a5bacf221&scene=21#wechat_redirect)

[Hugging Face 等AI即服务平台易受严重漏洞影响，遭AI供应链攻击](https://mp.weixin.qq.com/s?__biz=MzI2NTg4OTc5Nw==&mid=2247519250&idx=2&sn=9683638aaf21b4d1d794837ff20dd0ab&scene=21#wechat_redirect)

**原文链接**

https://www.theregister.com/2024/12/20/gen\_ai\_red\_teaming/

题图：Pexels License

**本文由奇安信编译，不代表奇安信观点。转载请注明“转自奇安信代码卫士 https://codesafe.qianxin.com”。**

![](https://mmbiz.qpic.cn/mmbiz_jpg/oBANLWYScMSf7nNLWrJL6dkJp7RB8Kl4zxU9ibnQjuvo4VoZ5ic9Q91K3WshWzqEybcroVEOQpgYfx1uYgwJhlFQ/640?wx_fmt=jpeg)

![](https://mmbiz.qpic.cn/mmbiz_jpg/oBANLWYScMSN5sfviaCuvYQccJZlrr64sRlvcbdWjDic9mPQ8mBBFDCKP6VibiaNE1kDVuoIOiaIVRoTjSsSftGC8gw/640?wx_fmt=jpeg)

**奇安信代码卫士 (codesafe)**

国内首个专注于软件开发安全的产品线。

![](https://mmbiz.qpic.cn/mmbiz_gif/oBANLWYScMQ5iciaeKS21icDIWSVd0M9zEhicFK0rbCJOrgpc09iaH6nvqvsIdckDfxH2K4tu9CvPJgSf7XhGHJwVyQ/640?wx_fmt=gif) 觉得不错，就点个 “在看” 或 "赞” 吧~

预览时标签不可点

阅读原文

![]()

微信扫一扫
关注该公众号

继续滑动看下一个

轻触阅读原文

![](http://mmbiz.qpic.cn/mmbiz_png/oBANLWYScMQnXWuOU95T0gnUjHe8IhdLQuqwxvDpLf7GwP25ntfz6W8dhDhUS3BstsPLPL9YBRXE1QhF9eIjiaw/0?wx_fmt=png)

代码卫士

向上滑动看下一个

知道了

![]()
微信扫一扫
使用小程序

取消
允许

取消
允许

取消
允许

×
分析

![跳转二维码]()

![作者头像](http://mmbiz.qpic.cn/mmbiz_png/oBANLWYScMQnXWuOU95T0gnUjHe8IhdLQuqwxvDpLf7GwP25ntfz6W8dhDhUS3BstsPLPL9YBRXE1QhF9eIjiaw/0?wx_fmt=png)

微信扫一扫可打开此内容，
使用完整服务

：
，
，
，
，
，
，
，
，
，
，
，
，
。

视频
小程序
赞
，轻点两下取消赞
在看
，轻点两下取消在看
分享
留言
收藏
听过