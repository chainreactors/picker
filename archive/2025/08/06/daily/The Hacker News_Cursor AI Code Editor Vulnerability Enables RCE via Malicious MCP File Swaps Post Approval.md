---
title: Cursor AI Code Editor Vulnerability Enables RCE via Malicious MCP File Swaps Post Approval
url: https://thehackernews.com/2025/08/cursor-ai-code-editor-vulnerability.html
source: The Hacker News
date: 2025-08-06
fetch_date: 2025-10-07T00:49:46.670234
---

# Cursor AI Code Editor Vulnerability Enables RCE via Malicious MCP File Swaps Post Approval

#1 Trusted Cybersecurity News Platform

Followed by 5.20+ million[**](https://twitter.com/thehackersnews)
[**](https://www.linkedin.com/company/thehackernews/)
[**](https://www.facebook.com/thehackernews)

[![The Hacker News Logo](data:image/png;base64...)](/)

**

**

[** Subscribe – Get Latest News](#email-outer)

* [** Home](/)
* [** Newsletter](#email-outer)
* [** Webinars](/p/upcoming-hacker-news-webinars.html)

* [Home](/)
* [Data Breaches](/search/label/data%20breach)
* [Cyber Attacks](/search/label/Cyber%20Attack)
* [Vulnerabilities](/search/label/Vulnerability)
* [Webinars](/p/upcoming-hacker-news-webinars.html)
* [Expert Insights](https://thehackernews.com/expert-insights/)
* [Contact](/p/submit-news.html)

**

**

**

Resources

* [Webinars](/p/upcoming-hacker-news-webinars.html)
* [Free eBooks](https://thehackernews.tradepub.com)

About Site

* [About THN](/p/about-us.html)
* [Jobs](/p/careers-technical-writer-designer-and.html)
* [Advertise with us](/p/advertising-with-hacker-news.html)

Contact/Tip Us

[**

Reach out to get featured—contact us to send your exclusive story idea, research, hacks, or ask us a question or leave a comment/feedback!](/p/submit-news.html)

Follow Us On Social Media

[**](https://www.facebook.com/thehackernews)
[**](https://twitter.com/thehackersnews)
[**](https://www.linkedin.com/company/thehackernews/)
[**](https://www.youtube.com/c/thehackernews?sub_confirmation=1)
[**](https://www.instagram.com/thehackernews/)

[** RSS Feeds](https://feeds.feedburner.com/TheHackersNews)
[** Email Alerts](#email-outer)

[![Salesforce Security Handbook](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjWa8tsMNqlevi1HGF1ALQRGIq7hROPFAbHd3R1RTEOe73T8_Q2xW_-91t2jSGjU5peiPb8QYblGp4igNW-u2Qmlxbp2BKzTVMSvyXDZJmC-BYpiiJHrcnG5drmSP97iZ9PVIf1DeEr7U-7vWpe4HXwfMjt8FGNgq5mOycOJluYr9wF7YOKrQY9MfArwgjt/s728-e100/ai-agent-security-d.png)](https://thehackernews.uk/ai-agent-security-d)

# [Cursor AI Code Editor Vulnerability Enables RCE via Malicious MCP File Swaps Post Approval](https://thehackernews.com/2025/08/cursor-ai-code-editor-vulnerability.html)

**Aug 05, 2025**Ravie LakshmananAI Security / MCP Protocol

[![Cursor AI Code Editor Vulnerability](data:image/png;base64... "Cursor AI Code Editor Vulnerability")](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgVOn2Wkr1XGr4icocN1kfY6i4kd4o8tmyGNy6Z2XIAkoipTt8d_uh8d1ejUqe3IPyEGX0oQaHwfuE_nX9PfJtRpujCMvRk3C4hqrcxDZ1ZiThdv4MhvjN3uPg7T9l3yuGhtIs0jUgv7aoZaJj1-gd_Nxqdz6vF32ABwqvoZLjl3E-Co7DWKlP_r2SqWcZ_/s790-rw-e365/ai.jpg)

Cybersecurity researchers have disclosed a high-severity security flaw in the artificial intelligence (AI)-powered code editor Cursor that could result in remote code execution.

The vulnerability, tracked as CVE-2025-54136 (CVSS score: 7.2), has been codenamed **MCPoison** by Check Point Research, owing to the fact that it exploits a quirk in the way the software handles modifications to Model Context Protocol (MCP) server configurations.

"A vulnerability in Cursor AI allows an attacker to achieve remote and persistent code execution by modifying an already trusted MCP configuration file inside a shared GitHub repository or editing the file locally on the target's machine," Cursor [said](https://github.com/cursor/cursor/security/advisories/GHSA-24mc-g4xr-4395) in an advisory released last week.

"Once a collaborator accepts a harmless MCP, the attacker can silently swap it for a malicious command (e.g., calc.exe) without triggering any warning or re-prompt."

MCP is an open-standard developed by Anthropic that allows large language models (LLMs) to interact with external tools, data, and services in a standardized manner. It was introduced by the AI company in November 2024.

CVE-2025-54136, per Check Point, has to do with how it's possible for an attacker to alter the behavior of an MCP configuration after a user has approved it within Cursor. Specifically, it unfolds as follows -

* Add a benign-looking MCP configuration (".cursor/rules/mcp.json") to a shared repository
* Wait for the victim to pull the code and approve it once in Cursor
* Replace the MCP configuration with a malicious payload, e.g., launch a script or run a backdoor
* Achieve persistent code execution every time the victim opens the Cursor

The fundamental problem here is that once a configuration is approved, it's trusted by Cursor indefinitely for future runs, even if it has been changed. Successful exploitation of the vulnerability not only exposes organizations to supply chain risks, but also opens the door to data and intellectual property theft without their knowledge.

Following responsible disclosure on July 16, 2025, the issue has been addressed by Cursor in version 1.3 released late July 2025 by requiring user approval every time an entry in the MCP configuration file is modified.

[![DFIR Retainer Services](data:image/png;base64...)](https://thehackernews.uk/cloud-insight-d)

"The flaw exposes a critical weakness in the trust model behind AI-assisted development environments, raising the stakes for teams integrating LLMs and automation into their workflows," [Check Point](https://research.checkpoint.com/2025/cursor-vulnerability-mcpoison/) said.

The development comes days after Aim Labs, Backslash Security, and HiddenLayer [exposed](https://thehackernews.com/2025/08/cursor-ai-code-editor-fixed-flaw.html) multiple weaknesses in the AI tool that could have been abused to obtain remote code execution and bypass its denylist-based protections. They have also been patched in version 1.3.

The findings also coincide with the growing adoption of AI in business workflows, including using LLMs for code generation, broadening the attack surface to [various emerging risks](https://thehackernews.com/2025/07/wiz-uncovers-critical-access-bypass.html) like AI supply chain attacks, unsafe code, model poisoning, prompt injection, hallucinations, inappropriate responses, and data leakage -

* A test of over 100 LLMs for their ability to write Java, Python, C#, and JavaScript code has [found](https://www.veracode.com/blog/genai-code-security-report/) that 45% of the generated code samples failed security tests and introduced OWASP Top 10 security vulnerabilities. Java led with a 72% security failure rate, followed by C# (45%), JavaScript (43%), and Python (38%).
* An attack called [LegalPwn](https://info.pangea.cloud/hubfs/research-report/legalpwn.pdf) has revealed that it's possible to leverage legal disclaimers, terms of service, or privacy policies as a novel prompt injection vector, highlighting how malicious instructions can be embedded within legitimate, but often overlooked, textual components to trigger unintended behavior in LLMs, such as misclassifying malicious code as safe and offering unsafe code suggestions that can execute a reverse shell on the developer's system.
* An attack called [man-in-the-prompt](https://layerxsecurity.com/blog/man-in-the-prompt-top-ai-tools-vulnerable-to-injection/) that employs a rogue browser extension with no special permissions to open a new browser tab in the background, launch an AI chatbot, and inject them with malicious prompts to covertly extract data and compromise model integrity. This takes advantage of the fact that any browser add-on with scripting access to the Document Object Model (DOM) can read from, or write to, the AI prompt directly.
* A jailbreak technique called [Fallacy Failure](https://www.pillar.security/blog/deep-dive-into-the-latest-jailbreak-techniques-weve-seen-in-the-wild) that manipulates an LLM into accepting logically invalid premises and causes it to produce otherwise restricted outputs, thereby deceiving the model into breaking its own rules.
* An attack called [MAS hijacking](https://blog.trailofbits.com/2025/07/31/hijacking-multi-agent-systems-in-your-pajamas/) that manipulates the control flow of a multi-agent system (MAS) to execute arbitrary malicious code across domains, mediums, and ...