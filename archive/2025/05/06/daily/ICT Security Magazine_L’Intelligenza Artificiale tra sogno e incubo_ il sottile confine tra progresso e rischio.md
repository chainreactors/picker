---
title: L’Intelligenza Artificiale tra sogno e incubo: il sottile confine tra progresso e rischio
url: https://www.ictsecuritymagazine.com/articoli/intelligenza-artificiale-rischi/
source: ICT Security Magazine
date: 2025-05-06
fetch_date: 2025-10-06T22:30:45.496804
---

# L’Intelligenza Artificiale tra sogno e incubo: il sottile confine tra progresso e rischio

[Salta al contenuto](#main)

[![ICT Security Magazine](https://www.ictsecuritymagazine.com/wp-content/uploads/2016/01/logo-ict-security.jpg)](https://www.ictsecuritymagazine.com/)

* [Home](https://www.ictsecuritymagazine.com/)
* [Articoli](https://www.ictsecuritymagazine.com/argomenti/articoli/)
* RubricheEspandi
  + [Cyber Security](https://www.ictsecuritymagazine.com/argomenti/cyber-security/)
  + [Cyber Crime](https://www.ictsecuritymagazine.com/argomenti/cyber-crime/)
  + [Cyber Risk](https://www.ictsecuritymagazine.com/argomenti/cyber-risk/)
  + [Cyber Law](https://www.ictsecuritymagazine.com/argomenti/cyber-law/)
  + [Digital Forensic](https://www.ictsecuritymagazine.com/argomenti/digital-forensic/)
  + [Digital ID Security](https://www.ictsecuritymagazine.com/argomenti/digital-id-security/)
  + [Business Continuity](https://www.ictsecuritymagazine.com/argomenti/business-continuity/)
  + [Digital Transformation](https://www.ictsecuritymagazine.com/argomenti/digital-transformation/)
  + [Cyber Warfare](https://www.ictsecuritymagazine.com/argomenti/cyber-warfare/)
  + [Ethical Hacking](https://www.ictsecuritymagazine.com/argomenti/ethical-hacking/)
  + [GDPR e Privacy](https://www.ictsecuritymagazine.com/argomenti/gdpr-e-privacy/)
  + [IoT Security](https://www.ictsecuritymagazine.com/argomenti/iot-security/)
  + [Industrial Cyber Security](https://www.ictsecuritymagazine.com/argomenti/industrial-cyber-security/)
  + [Blockchain e Criptovalute](https://www.ictsecuritymagazine.com/argomenti/blockchain-e-criptovalute/)
  + [Intelligenza Artificiale](https://www.ictsecuritymagazine.com/argomenti/intelligenza-artificiale/)
  + [Geopolitica e Cyberspazio](https://www.ictsecuritymagazine.com/argomenti/geopolitica-cyberspazio/)
  + [Interviste](https://www.ictsecuritymagazine.com/argomenti/interviste/)
* [Notizie](https://www.ictsecuritymagazine.com/argomenti/notizie/)
* [Pubblicazioni](https://www.ictsecuritymagazine.com/pubblicazioni/)
* [Cybersecurity Video](https://www.ictsecuritymagazine.com/argomenti/cybersecurity-video/)
* [Eventi](https://www.ictsecuritymagazine.com/eventi/)
* [Newsletter](https://www.ictsecuritymagazine.com/newsletter/)

[Linkedin](https://www.linkedin.com/company/ict-security-magazine/) [YouTube](https://www.youtube.com/%40ictsecuritymagazine1403) [RSS](https://www.ictsecuritymagazine.com/feed/)

[![ICT Security Magazine](https://www.ictsecuritymagazine.com/wp-content/uploads/2016/01/logo-ict-security.jpg)](https://www.ictsecuritymagazine.com/)

Attiva/disattiva menu

[![Forum ICT Security 2025](https://www.ictsecuritymagazine.com/wp-content/uploads/banner-header-2025.jpg)](https://www.ictsecuritymagazine.com/eventi/forumictsecurity2025)

![Intelligenza Artificiale rischi machine learning etica](https://www.ictsecuritymagazine.com/wp-content/uploads/Intelligenza-Artificiale-Rischi.jpg)

# L’Intelligenza Artificiale tra sogno e incubo: il sottile confine tra progresso e rischio

A cura di:[Andrea Pasquinucci](#molongui-disabled-link)  Ore 5 Maggio 202524 Aprile 2025

L’arrivo di ChatGPT il 30 novembre 2022 ha focalizzato l’attenzione di molti di noi sui sistemi di Intelligenza Artificiale (AI), che più propriamente dovremmo chiamare modelli di Machine Learning (ML). L’interesse in questa “nuova” tecnologia ha incluso sin da subito sia informatici, sia utilizzatori di sistemi IT, sia chi usa quotidianamente applicazioni IT anche solo sugli smartphone, sia chi con le tecnologie informatiche ha di solito poco a che fare.

Questo vasto interesse può essere facilmente compreso dato che sin dai tempi antichi, ad esempio degli antichi greci, già l’uomo immaginava la creazione di “automi” che potessero sostituirlo o almeno aiutarlo nei compiti più gravosi, più pericolosi o anche solo di poco interesse. Infatti l’uomo ha la capacità unica di creare strumenti che l’aiutano nelle sue azioni, è quindi logico sognare di avere un servitore meccanico e autonomo che lo aiuti e renda più facile e piacevole la propria vita.

Con la recente maturazione delle tecnologie di ML e AI in generale, che ormai hanno più di mezzo secolo di vita, è quindi comprensibile l’interesse di molti di noi non tanto da un punto di vista tecnico e specialistico informatico, quanto proprio come strumento a supporto dell’umanità.

Pertanto è utile cercare di capire cosa, come uomini, ci attendiamo da androidi, robot e sistemi AI in esecuzione su elaboratori sia grandi e distribuiti sia piccoli (almeno in dimensioni fisiche) come gli smartphone.

Un possibile punto di partenza non è tanto cosa dovrebbero fare queste applicazioni e strumenti ma piuttosto come dovrebbero comportarsi. Ad esempio è interessante considerare i 10 principi generali delle raccomandazioni UNESCO sull’Etica dell’Intelligenza Artificiale [[1]](#_ftn1):

1. Proporzionalità e non nuocere,
2. Sicurezza e protezione,
3. Equità e non discriminazione,
4. Sostenibilità,
5. Diritto alla privacy e alla protezione dei dati,
6. Supervisione umana e discrezionalità,
7. Trasparenza e spiegabilità,
8. Responsabilità e responsabilizzazione,
9. Consapevolezza e alfabetizzazione,
10. Governance e collaborazione adattive e multilaterali.

Può anche essere d’aiuto l’approccio del NIST alla gestione dei rischi derivanti dall’utilizzo del AI [[2]](#_ftn2) che descrive 7 criteri per valutare la “Trustworthiness” dei sistemi AI:

1. validità e affidabilità,
2. protezione,
3. sicurezza e resilienza,
4. responsabilità e trasparenza,
5. comprensione e modellazione,
6. riservatezza,
7. imparzialità, attraverso la mitigazione dei pregiudizi dannosi.

Un altro, per alcuni aspetti più semplice ma anche più ambiguo, è il famoso approccio di Isaac Asimov alle leggi che dovrebbero governare i “robot” [[3]](#_ftn3). E’ possibile riassumere le 3+1 leggi di Asimov come segue:

* **Legge 0**: Un robot non può arrecare danno all’umanità né, a causa del suo mancato intervento, permettere che l’umanità subisca danni.
* **Legge 1**: Un robot non può recare danno a un essere umano né può permettere che, a causa del suo mancato intervento, un essere umano riceva danno, purché tali azioni non contrastino con la Legge Zero.
* **Legge 2**: Un robot deve obbedire agli ordini impartiti dagli esseri umani, purché tali ordini non contrastino con la Legge Zero o la Prima Legge.
* **Legge 3**: Un robot deve proteggere la propria esistenza, purché la salvaguardia di essa non contrasti con la Legge Zero o la Prima o la Seconda Legge.

Sono state proposte molte integrazioni a queste leggi, la seguente compare spesso come Quarta Legge [[4]](#_ftn4):

* **Legge 4**: Un robot deve stabilire la sua identità come robot in tutti i casi e non deve ingannare un essere umano impersonandolo.

Infine, è utile citare anche l’approccio proposto da Satya Nadella (CEO di Microsoft) [[5]](#_ftn5) e ispirato alle leggi di Asimov:

1. L’intelligenza artificiale deve essere progettata per assistere l’umanità,
2. L’intelligenza artificiale deve essere trasparente,
3. L’intelligenza artificiale deve massimizzare l’efficienza senza distruggere la dignità delle persone,
4. L’intelligenza artificiale deve essere progettata per una Privacy intelligente,
5. L’intelligenza artificiale deve avere una responsabilità (o “accountability”) algoritmica [Una formulazione alternativa è che *l’uomo deve poter prevenire danni producibili dalla AI*],
6. L’intelligenza artificiale deve proteggersi dai pregiudizi (o “Bias”).

Il problema comune a tutte queste affermazioni è che sono generiche al punto di poter essere ambigue e soggette a interpretazioni diverse da parte di persone diverse. Asimov stesso scrisse che le sue “Leggi” sono una rappresentazione umana di concetti e che la difficoltà risiede nella formulazione logica e matematica che regola il comportamento degli strumenti di AI. Ma prima ancora della difficoltà logica e matematica della formulazione di queste leggi di comportamento degli strumenti AI, è necessario trovarne una formulazione di dettaglio che sia interpretata nell...