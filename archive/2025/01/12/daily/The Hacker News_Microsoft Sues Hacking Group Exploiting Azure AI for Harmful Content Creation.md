---
title: Microsoft Sues Hacking Group Exploiting Azure AI for Harmful Content Creation
url: https://thehackernews.com/2025/01/microsoft-sues-hacking-group-exploiting.html
source: The Hacker News
date: 2025-01-12
fetch_date: 2025-10-06T20:10:07.587326
---

# Microsoft Sues Hacking Group Exploiting Azure AI for Harmful Content Creation

#1 Trusted Cybersecurity News Platform

Followed by 5.20+ million[**](https://twitter.com/thehackersnews)
[**](https://www.linkedin.com/company/thehackernews/)
[**](https://www.facebook.com/thehackernews)

[![The Hacker News Logo](data:image/png;base64...)](/)

**

**

[** Subscribe – Get Latest News](#email-outer)

* [** Home](/)
* [** Newsletter](#email-outer)
* [** Webinars](/p/upcoming-hacker-news-webinars.html)

* [Home](/)
* [Data Breaches](/search/label/data%20breach)
* [Cyber Attacks](/search/label/Cyber%20Attack)
* [Vulnerabilities](/search/label/Vulnerability)
* [Webinars](/p/upcoming-hacker-news-webinars.html)
* [Expert Insights](https://thehackernews.com/expert-insights/)
* [Contact](/p/submit-news.html)

**

**

**

Resources

* [Webinars](/p/upcoming-hacker-news-webinars.html)
* [Free eBooks](https://thehackernews.tradepub.com)

About Site

* [About THN](/p/about-us.html)
* [Jobs](/p/careers-technical-writer-designer-and.html)
* [Advertise with us](/p/advertising-with-hacker-news.html)

Contact/Tip Us

[**

Reach out to get featured—contact us to send your exclusive story idea, research, hacks, or ask us a question or leave a comment/feedback!](/p/submit-news.html)

Follow Us On Social Media

[**](https://www.facebook.com/thehackernews)
[**](https://twitter.com/thehackersnews)
[**](https://www.linkedin.com/company/thehackernews/)
[**](https://www.youtube.com/c/thehackernews?sub_confirmation=1)
[**](https://www.instagram.com/thehackernews/)

[** RSS Feeds](https://feeds.feedburner.com/TheHackersNews)
[** Email Alerts](#email-outer)

[![Salesforce Security Handbook](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjWa8tsMNqlevi1HGF1ALQRGIq7hROPFAbHd3R1RTEOe73T8_Q2xW_-91t2jSGjU5peiPb8QYblGp4igNW-u2Qmlxbp2BKzTVMSvyXDZJmC-BYpiiJHrcnG5drmSP97iZ9PVIf1DeEr7U-7vWpe4HXwfMjt8FGNgq5mOycOJluYr9wF7YOKrQY9MfArwgjt/s728-e100/ai-agent-security-d.png)](https://thehackernews.uk/ai-agent-security-d)

# [Microsoft Sues Hacking Group Exploiting Azure AI for Harmful Content Creation](https://thehackernews.com/2025/01/microsoft-sues-hacking-group-exploiting.html)

**Jan 11, 2025**Ravie LakshmananAI Security / Cybersecurity

[![AI for Harmful Content Creation](data:image/png;base64... "AI for Harmful Content Creation")](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjWPu0JGeBg2yboLivU5wh9uMQCHRdZtzBpVskB8eMBT_aQ5Qy-yaEa3qI516b97_L0rjB3bRzwvi7QtdHtwdYxposV0tYijkDUan4gZPkHPcn-E6GeH2Qaep1ryqpv_hdj1wAlfJKeUNY8nUjmlxnCaD9MQrUGLsnixDO3qtbE9kZfMJdtJreJYbcUVknb/s790-rw-e365/ms.png)

Microsoft has revealed that it's [pursuing legal action](https://blogs.microsoft.com/on-the-issues/2025/01/10/taking-legal-action-to-protect-the-public-from-abusive-ai-generated-content/) against a "foreign-based threat–actor group" for operating a hacking-as-a-service infrastructure to intentionally get around the safety controls of its generative artificial intelligence (AI) services and produce offensive and harmful content.

The tech giant's Digital Crimes Unit (DCU) said it has observed the threat actors "develop sophisticated software that exploited exposed customer credentials scraped from public websites," and "sought to identify and unlawfully access accounts with certain generative AI services and purposely alter the capabilities of those services."

The adversaries then used these services, such as Azure OpenAI Service, and monetized the access by selling them to other malicious actors, providing them with detailed instructions as to how to use these custom tools to generate harmful content. Microsoft said it discovered the activity in July 2024.

The Windows maker said it has since revoked the threat-actor group's access, implemented new countermeasures, and fortified its safeguards to prevent such activity from occurring in the future. It also said it obtained a court order to seize a website ("aitism[.]net") that was central to the group's criminal operation.

[![DFIR Retainer Services](data:image/png;base64...)](https://thehackernews.uk/cloud-insight-d)

The popularity of AI tools like OpenAI ChatGPT has also had the consequence of threat actors [abusing them](https://thehackernews.com/2025/01/new-ai-jailbreak-method-bad-likert.html) for [malicious intents](https://www.reuters.com/world/us/las-vegas-cybertruck-suspect-used-chatgpt-plan-blast-police-say-2025-01-08/), ranging from producing prohibited content to malware development. Microsoft and OpenAI have [repeatedly](https://thehackernews.com/2024/02/microsoft-openai-warn-of-nation-state.html) [disclosed](https://thehackernews.com/2024/10/openai-blocks-20-global-malicious.html) that nation-state groups from China, Iran, North Korea, and Russia are using their services for reconnaissance, translation, and disinformation campaigns.

Court documents [show that](https://www.courtlistener.com/docket/69534982/microsoft-corporation-v-does-1-10-operating-an-azure-abuse-network/) at least three unknown individuals are behind the operation, leveraging stolen Azure API keys and customer Entra ID authentication information to breach Microsoft systems and create harmful images using [DALL-E](https://openai.com/index/dall-e/) in violation of its acceptable use policy. Seven other parties are believed to have used the services and tools provided by them for similar purposes.

The manner in which the API keys are harvested is currently not known, but Microsoft said the defendants engaged in "systematic API key theft" from multiple customers, including several U.S. companies, some of which are located in Pennsylvania and New Jersey.

"Using stolen Microsoft API Keys that belonged to U.S.-based Microsoft customers, defendants created a hacking-as-a-service scheme – accessible via infrastructure like the 'rentry.org/de3u' and 'aitism.net' domains – specifically designed to abuse Microsoft's Azure infrastructure and software," the company said in a filing.

According to a [now removed GitHub repository](https://web.archive.org/web/20241229064647/https%3A//github.com/notfiz/de3u), de3u has been described as a "DALL-E 3 frontend with reverse proxy support." The GitHub account in question was created on November 8, 2023.

It's said the threat actors took steps to "cover their tracks, including by attempting to delete certain Rentry.org pages, the GitHub repository for the de3u tool, and portions of the reverse proxy infrastructure" following the seizure of "aitism[.]net."

Microsoft noted that the threat actors used de3u and a bespoke reverse proxy service, called the oai reverse proxy, to make Azure OpenAl Service API calls using the stolen API keys in order to unlawfully generate thousands of harmful images using text prompts. It's unclear what type of offensive imagery was created.

The oai reverse proxy service running on a server is designed to funnel communications from de3u user computers through a Cloudflare tunnel into the Azure OpenAI Service, and transmit the responses back to the user device.

"The de3u software allows users to issue Microsoft API calls to generate images using the DALL-E model through a simple user interface that leverages the Azure APIs to access the Azure OpenAI Service," Redmond explained.

[![CIS Build Kits](data:image/png;base64...)](https://thehackernews.uk/platform-shield-d)

"Defendants' de3u application communicates with Azure computers using undocumented Microsoft network APIs to send requests designed to mimic legitimate Azure OpenAPI Service API requests. These requests are authenticated using stolen API keys and other authenticating information."

It's worth pointing out that the use of proxy services to illegally access LLM services was highlighted by Sysdig in May 2024 in connection with an [LLMjacking attack campaign](https://thehackernews.com/2024/05/researchers-uncover-llmjacking-scheme.html) targeting AI offerings from Anthropic, AWS Bedrock, Google Cloud Vertex AI, Microsoft Azure, Mistral, and OpenAI using stolen cloud credentials and selling the acce...