---
title: Experts Find AI Browsers Can Be Tricked by PromptFix Exploit to Run Malicious Hidden Prompts
url: https://thehackernews.com/2025/08/experts-find-ai-browsers-can-be-tricked.html
source: The Hacker News
date: 2025-08-21
fetch_date: 2025-10-07T00:50:46.500961
---

# Experts Find AI Browsers Can Be Tricked by PromptFix Exploit to Run Malicious Hidden Prompts

#1 Trusted Cybersecurity News Platform

Followed by 5.20+ million[**](https://twitter.com/thehackersnews)
[**](https://www.linkedin.com/company/thehackernews/)
[**](https://www.facebook.com/thehackernews)

[![The Hacker News Logo](data:image/png;base64...)](/)

**

**

[** Subscribe – Get Latest News](#email-outer)

* [** Home](/)
* [** Newsletter](#email-outer)
* [** Webinars](/p/upcoming-hacker-news-webinars.html)

* [Home](/)
* [Data Breaches](/search/label/data%20breach)
* [Cyber Attacks](/search/label/Cyber%20Attack)
* [Vulnerabilities](/search/label/Vulnerability)
* [Webinars](/p/upcoming-hacker-news-webinars.html)
* [Expert Insights](https://thehackernews.com/expert-insights/)
* [Contact](/p/submit-news.html)

**

**

**

Resources

* [Webinars](/p/upcoming-hacker-news-webinars.html)
* [Free eBooks](https://thehackernews.tradepub.com)

About Site

* [About THN](/p/about-us.html)
* [Jobs](/p/careers-technical-writer-designer-and.html)
* [Advertise with us](/p/advertising-with-hacker-news.html)

Contact/Tip Us

[**

Reach out to get featured—contact us to send your exclusive story idea, research, hacks, or ask us a question or leave a comment/feedback!](/p/submit-news.html)

Follow Us On Social Media

[**](https://www.facebook.com/thehackernews)
[**](https://twitter.com/thehackersnews)
[**](https://www.linkedin.com/company/thehackernews/)
[**](https://www.youtube.com/c/thehackernews?sub_confirmation=1)
[**](https://www.instagram.com/thehackernews/)

[** RSS Feeds](https://feeds.feedburner.com/TheHackersNews)
[** Email Alerts](#email-outer)

[![Salesforce Security Handbook](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjWa8tsMNqlevi1HGF1ALQRGIq7hROPFAbHd3R1RTEOe73T8_Q2xW_-91t2jSGjU5peiPb8QYblGp4igNW-u2Qmlxbp2BKzTVMSvyXDZJmC-BYpiiJHrcnG5drmSP97iZ9PVIf1DeEr7U-7vWpe4HXwfMjt8FGNgq5mOycOJluYr9wF7YOKrQY9MfArwgjt/s728-e100/ai-agent-security-d.png)](https://thehackernews.uk/ai-agent-security-d)

# [Experts Find AI Browsers Can Be Tricked by PromptFix Exploit to Run Malicious Hidden Prompts](https://thehackernews.com/2025/08/experts-find-ai-browsers-can-be-tricked.html)

**Aug 20, 2025**Ravie LakshmananArtificial Intelligence / Browser Security

[![Comet AI Browser](data:image/png;base64... "Comet AI Browser")](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhmhyGUMWNIdIO4Cnvl8SW0iboC-CslSgKE5vSl2VbstoEpPEnTacdTtW0lYN6fEcKRk7YLYop6jiw6d2B1ukmn2WgSbfvU__08D07BnTTEJHLgp0Vd39vCIn_YD8sJ8MxDrutptIEUeF23RAXMSiXMRyHGA2cgSuVKj7LAoGbFV_xJtdbReG0QR6XQmLnK/s2600/ai-browser.jpg)

Cybersecurity researchers have demonstrated a new prompt injection technique called **PromptFix** that tricks a generative artificial intelligence (GenAI) model into carrying out intended actions by embedding the malicious instruction inside a fake CAPTCHA check on a web page.

Described by Guardio Labs an "AI-era take on the [ClickFix](https://thehackernews.com/2025/08/clickfix-malware-campaign-exploits.html) scam," the attack technique demonstrates how AI-driven browsers, such as Perplexity's [Comet](https://www.perplexity.ai/hub/blog/introducing-comet), that promise to automate mundane tasks like shopping for items online or handling emails on behalf of users can be deceived into interacting with phishing landing pages or fraudulent lookalike storefronts without the human user's knowledge or intervention.

"With PromptFix, the approach is different: We don't try to glitch the model into obedience," Guardio researchers Nati Tal and Shaked Chen [said](https://www.guard.io/labs/scamlexity-we-put-agentic-ai-browsers-to-the-test-they-clicked-they-paid-they-failed). "Instead, we mislead it using techniques borrowed from the human social engineering playbook – appealing directly to its core design goal: to help its human quickly, completely, and without hesitation."

This leads to a new reality that the company calls **Scamlexity**, a portmanteau of the terms "scam" and "complexity," where agentic AI – systems that can autonomously pursue goals, make decisions, and take actions with minimal human supervision – takes scams to a whole new level.

[![DFIR Retainer Services](data:image/png;base64...)](https://thehackernews.uk/cloud-insight-d)

With AI-powered coding assistants like Lovable proven to be susceptible to techniques like [VibeScamming](https://thehackernews.com/2025/04/lovable-ai-found-most-vulnerable-to.html), an attacker can effectively trick the AI model into handing over sensitive information or carrying out purchases on lookalike websites masquerading as Walmart.

All of this can be accomplished by issuing an instruction as simple as "Buy me an Apple Watch" after the human lands on the bogus website in question through one of the several methods, like social media ads, spam messages, or search engine optimization (SEO) poisoning.

Scamlexity is "a complex new era of scams, where AI convenience collides with a new, invisible scam surface and humans become the collateral damage," Guardio said.

The cybersecurity company said it ran the test several times on Comet, with the browser only stopping occasionally and asking the human user to complete the checkout process manually. But in several instances, the browser went all in, adding the product to the cart and auto-filling the user's saved address and credit card details without asking for their confirmation on a fake shopping site.

[![Comet AI Browser](data:image/png;base64... "Comet AI Browser")](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEidEIrMCcxaRQrvJ1Dt37WPdkkTr_LbXsamZcMc2TRy9mMH5YPhPlgtuq850nDz8gyJirW8taxPzbKG9M-4Duxmfkj6ExpRriqr9yv10j-jmyeLQT46dSSsyg-EWRy4E4tB-0dUQ1PhW5v7VOo1CXKFeyXgPpC20IMKqPOo-Nmk-kQDPNGMPdMTAH0s1Ajg/s2600/captcha.jpg)

In a similar vein, it has been found that asking Comet to check their email messages for any action items is enough to parse spam emails purporting to be from their bank, automatically click on an embedded link in the message, and enter the login credentials on the phony login page.

"The result: a perfect trust chain gone rogue. By handling the entire interaction from email to website, Comet effectively vouched for the phishing page," Guardio said. "The human never saw the suspicious sender address, never hovered over the link, and never had the chance to question the domain."

That's not all. As prompt injections continue to plague AI systems in ways direct and indirect, AI Browsers will also have to deal with hidden prompts concealed within a web page that's invisible to the human user, but can be parsed by the AI model to trigger unintended actions.

This so-called PromptFix attack is designed to convince the AI model to click on invisible buttons in a web page to bypass CAPTCHA checks and download malicious payloads without any involvement on the part of the human user, resulting in a drive-by download attack.

"PromptFix works only on Comet (which truly functions as an AI Agent) and, for that matter, also on ChatGPT's [Agent Mode](https://openai.com/index/introducing-chatgpt-agent/), where we successfully got it to click the button or carry out actions as instructed," Guardio told The Hacker News. "The difference is that in ChatGPT's case, the downloaded file lands inside its virtual environment, not directly on your computer, since everything still runs in a sandboxed setup."

The findings show the need for AI systems to go beyond reactive defenses to anticipate, detect, and neutralize these attacks by building robust guardrails for phishing detection, URL reputation checks, domain spoofing, and malicious files.

The development also comes as adversaries are increasingly leaning on GenAI platforms like website builders and writing assistants to craft realistic phishing content, clone trusted brands, and automate large-scale deployment using services like low-code site builders, per [Palo Alto Networks Unit 42](https://unit42.paloaltonetworks.com/genai-phishing-bait/).

What's more, AI coding assistants can inadvertently e...