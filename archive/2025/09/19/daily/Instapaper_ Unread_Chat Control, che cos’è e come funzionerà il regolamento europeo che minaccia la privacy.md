---
title: Chat Control, che cos’è e come funzionerà il regolamento europeo che minaccia la privacy
url: https://www.wired.it/article/chat-control-come-funziona-regolamento-europeo-problemi-privacy/
source: Instapaper: Unread
date: 2025-09-19
fetch_date: 2025-10-02T20:24:04.663896
---

# Chat Control, che cos’è e come funzionerà il regolamento europeo che minaccia la privacy

[Skip to main content](#main-content)

Apri il menu di navigazione

Menu

[![Wired Italia](/verso/static/wired-us/assets/logo-header.svg)](/)

Chat Control, che cos’è e come funzionerà il regolamento europeo che minaccia la privacy

* [Scienza](/scienza/)
* [Economia](/economia/)
* [Cultura](/cultura/)
* [Gadget](/gadget/)
* [Security](/security/)
* [Diritti](/diritti/)
* [Idee](/idee/)
* [Video](/video/)
* [Podcast](/podcast-wired/)
* [Wired Consiglia](/wired-consiglia/)

More*Chevron*

[Cerca

Cerca](/search/)

* [Scienza](/scienza/)
* [Economia](/economia/)
* [Cultura](/cultura/)
* [Gadget](/gadget/)
* [Security](/security/)
* [Diritti](/diritti/)
* [Idee](/idee/)
* [Video](/video/)
* [Podcast](/podcast-wired/)
* [Wired Consiglia](/wired-consiglia/)

Close Banner

Close

[![Wired Next Fest](/verso/static/wired/assets/wnf-156x40.png)](https://eventi.wired.it/nextfest25-trentino)

00

Giorni

:

00

Ore

:

00

Minuti

:

00

Secondi

[Iscriviti, ingresso gratuito](https://eventi.wired.it/nextfest25-trentino/ticket)[3-5 ottobre, Rovereto](https://eventi.wired.it/nextfest25-trentino)

[Marco Schiaffino](/contributor/marco-schiaffino/)

[Security](/security/)

16.09.2025

# Chat Control, che cos’è e come funzionerà il regolamento europeo che minaccia la privacy

Il controllo dei contenuti condivisi sulle piattaforme di messaggistica mirerebbe a contrastare la pedopornografia, ma i rischi di sicurezza e di abusi da parte dei governi nazionali suscitano grandi preoccupazioni

![Chat Control che cosè e come funzionerà il regolamento europeo che minaccia la privacy](https://media-assets.wired.it/photos/67af54f36964e5dc3c7b81e8/16:9/w_2560%2Cc_limit/1601776902)

NurPhoto/Getty Images

Il nome ufficiale sarebbe Csar (Child Sexual Abuse Regulation), ma i suoi critici lo hanno ribattezzato più semplicemente “Chat Control”. Il controverso regolamento europeo ha [mosso i primi passi](https://www.wired.it/article/abusi-minori-europa-controllo-chat-rischi-privacy-commissione/) nel 2022 ed è arrivato ora a una fase decisiva, in cui i membri dell’Unione Europea dovranno decidere se sostenere o meno la nuova legge.

In gioco c’è il futuro dei servizi di comunicazione su internet e, in particolare, del livello di privacy che potranno continuare a garantire. L’impatto della sua approvazione su servizi come **Whatsapp, Messenger, Telegram, iMessage e Signal**, che fino a oggi garantiscono un sistema di comunicazione orientato alla riservatezza dei dati, potrebbe essere devastante.

Tutto quello che c'è da sapere:

AccordionItemContainerButton

LargeChevron

* [Una backdoor di stato nelle chat](#una-backdoor-di-stato-nelle-chat)
* [La verifica “a monte”](#la-verifica-a-monte)
* [Caccia a immagini e video con l'AI](#caccia-a-immagini-e-video-con-lai)
* [Il problema dell'adescamento](#il-problema-delladescamento)
* [Adesione volontaria, ma solo di facciata](#adesione-volontaria-ma-solo-di-facciata)

## Una backdoor di stato nelle chat

L’obiettivo del regolamento è quello di fissare una serie di obblighi per i fornitori di servizi internet per contribuire al contrasto della diffusione di materiale pedopornografico online. Se per quanto riguarda i gestori dei servizi di hosting e gli internet provider non c’è nulla di particolarmente nuovo, il tasto dolente riguarda **i servizi di messaggistica**.

A questi, infatti, verrebbe imposto di adottare “misure tecnologiche” che permettano di **individuare, bloccare e segnalare** **l’invio di contenuti pedopornografici**. Un’attività che, però, si scontra frontalmente con i sistemi di crittografia end-to-end, considerati ormai come uno strumento irrinunciabile per garantire la privacy degli utenti. I sistemi di crittografia delle varie applicazioni come Whatsapp garantiscono infatti che i messaggi siano leggibili sono dai singoli utenti, rendendo impossibile anche per i gestori dei servizi accedere ai contenuti.

Non a caso, la proposta di regolamento è stata immediatamente letta come un modo per **smantellare questo tipo di piattaforme**, nei confronti delle quali [molti governi](https://www.wired.it/article/privacy-onu-convenzione-cyber-crime-sicurezza/) (europei e non) dimostrano da tempo una certa allergia. L’accusa è che, respinti i tentativi di proibire la crittografia end-to-end, quella della lotta alla pedopornografia sia una scusa per indebolirne l’efficacia.

Le prime versioni della proposta di regolamento, infatti, prevedevano modifiche tali da pregiudicare l’efficacia dei sistemi di crittazione. Come hanno fatto notare i portavoce delle aziende interessate e tutti gli esperti di sicurezza informatica, la previsione di **una backdoor che consenta di aggirare la crittografia** è un assist clamoroso per i cyber criminali e per chiunque (regimi autoritari in testa) possa aver interesse a spiare le comunicazioni degli utenti. La logica è semplice: se si apre una porta nella fortezza, la sua sicurezza è inevitabilmente compromessa e non importa quanti sforzi si facciano per sorvegliare l’accesso.

## La verifica “a monte”

Lo stallo nel percorso di approvazione del regolamento Chat Control ha portato a un tentativo di compromesso e a una nuova versione della proposta di regolamento che, almeno in teoria, vorrebbe introdurre sistemi di controllo senza intaccare la riservatezza delle comunicazioni. L’idea, in pratica, è quella di passare la patata bollente nelle mani degli operatori, obbligandoli a introdurre **sistemi di verifica dell’età degli utenti** e strumenti che consentano di individuare i materiali pericolosi prima che questi siano inviati. In altre parole, il controllo dei contenuti avverrebbe direttamente sul dispositivo prima che venga crittografato.

In questo modo, secondo gli estensori della proposta, si escluderebbe un’analisi sui server e il conseguente smantellamento della protezione crittografica. **Ma è possibile farlo?** Comunque la si veda, i problemi tecnici e di privacy non mancano. Secondo il nuovo testo, il rilevamento dovrebbe riguardare tre tipi di materiali: i contenuti pedopornografici già noti, i contenuti nuovi e i tentativi di adescamento nei confronti di minori. Ognuna di queste attività pone problemi specifici.

## Caccia a immagini e video con l'AI

Per quanto riguarda i contenuti già conosciuti, l’idea è quella che venga predisposto un database che li identifichi attraverso hash, cioè un’operazione crittografica che permette di **identificare un’immagine o un video con un codice univoco**, più o meno come fanno i software antivirus per identificare i malware. Da un punto di vista tecnico, si tratta di una funzionalità piuttosto semplice da implementare, ma il suo utilizzo apre comunque a qualche preoccupazione sotto il profilo della privacy e dei possibili abusi.

Dal momento che il database sarebbe gestito centralmente dai singoli paesi, l’ipotesi che un sistema del genere possa essere utilizzato per **individuare chi condivide contenuti “sgraditi” al governo di turno**, per esempio, è tutt’altro che remota. Le cose cambiano ulteriormente per quanto riguarda i contenuti “nuovi”. In questo caso l’unica soluzione sarebbe quella di una verifica tramite algoritmi di AI e, come prevedibile, i problemi diventano numerosi.

Prima di tutto perché l’analisi basata su intelligenza artificiale, almeno per il momento, avviene principalmente su cloud. Le immagini, quindi, **dovrebbero essere inviate (in chiaro) su un server**, essere analizzate dall’algoritmo per avere il nulla osta e poi crittografate e inviate al contatto. Insomma: addio a privacy e sicurezza. L’ipotesi di un’elaborazione direttamente sul dispositivo, anche se tecnicamente possibile, richiederebbe invece requisiti hardware e software che non tutti i device hanno. Infine, c’è il tema dell’affidabilità dell’AI. Quanti errori ci si può aspettare e quale impatto può avere un “falso positivo” nella sfera personale di un cittadino europeo vittima di un errore o dell’ennesima allucinazione dell’algoritmo?

## Il problema dell'adescamento
...