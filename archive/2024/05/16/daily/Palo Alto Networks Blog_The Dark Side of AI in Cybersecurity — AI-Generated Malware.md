---
title: The Dark Side of AI in Cybersecurity — AI-Generated Malware
url: https://www.paloaltonetworks.com/blog/2024/05/ai-generated-malware/
source: Palo Alto Networks Blog
date: 2024-05-16
fetch_date: 2025-10-06T17:19:25.075182
---

# The Dark Side of AI in Cybersecurity — AI-Generated Malware

* [Blog](https://www.paloaltonetworks.com/blog)
* [Palo Alto Networks](https://www.paloaltonetworks.com/blog/corporate)
* [Must-Read Articles](https://www.paloaltonetworks.com/blog/security-operations/category/must-read-articles/)
* The Dark Side of AI in Cy...

# The Dark Side of AI in Cybersecurity — AI-Generated Malware

Link copied

By [Dena De Angelo](/blog/author/ddeangelo/ "Posts by Dena De Angelo")

May 15, 2024

8 minutes

[Must-Read Articles](/blog/security-operations/category/must-read-articles/)

[Points of View](/blog/category/points-of-view/)

[Products and Services](/blog/category/products-and-services/)

[AI’s Impact in Cybersecurity](/blog/tag/ais-impact-in-cybersecurity/)

[Cortex XDR](/blog/tag/cortex-xdr/)

[Cortex XSIAM](/blog/tag/cortex-xsiam/)

[Interview](/blog/tag/interview/)

![](/blog/wp-content/themes/panwblog2023/dist/images/audio-icon.svg)

Rem Dudas — AI-Generated Malware

*00:00*
*00:00*

Volume Slider

10s

10s

10s

10s

Seek Slider

[*“AI’s Impact in Cybersecurity”*](/blog/tag/ais-impact-in-cybersecurity/) *is a blog series based on interviews with a variety of experts at Palo Alto Networks and Unit 42, with roles in AI research, product management, consulting, engineering and more. Our objective is to present different viewpoints and predictions on how artificial intelligence is impacting the current threat landscape, how Palo Alto Networks protects itself and its customers, as well as implications for the future of cybersecurity.*

*In a thought-provoking interview on the* [*Threat Vector podcast*](https://thecyberwire.com/podcasts/threat-vector)*, Palo Alto Networks researchers Bar Matalon and Rem Dudas shed light on their groundbreaking research into AI-generated malware and shared their predictions for the future of AI in cybersecurity.*

As artificial intelligence (AI) continues to evolve at an unprecedented pace, its impact on the cybersecurity landscape is becoming increasingly apparent. While AI has the potential to revolutionize threat detection and defense strategies, it can also be exploited by malicious actors to create more sophisticated and evasive threats. In a thought-provoking interview on the [Threat Vector podcast](https://thecyberwire.com/podcasts/threat-vector), Palo Alto Networks researchers, Bar Matalon and Rem Dudas, shed light on their groundbreaking research into AI-generated malware and their predictions for the future of AI in cybersecurity.

## Unraveling the Complexity of AI-Generated Malware

When asked about the possibility of AI generating malware, Dudas responded unequivocally, stating, "The answer is yes. And there is a bit of a longer version for that answer. It's a lot more complex than it seems at first." The researchers embarked on a journey to generate malware samples based on [MITRE ATT&CK](/cortex/cortex-xdr/mitre) techniques, and while the initial results were lackluster, they persevered and eventually generated samples that were both sophisticated and alarming. Dudas explains their process further:

*“The main stage after the basic tinkering with the AI models was trying to generate malware samples that perform specific tasks based on MITRE techniques. If you're familiar with those, for example, we would like to generate a sample that does credential gathering from Chromium browsers. So, we tried generating those, and for each technique that we found interesting, we tried generating a specific sample. We did that for different operating systems – for Windows, macOS and Linux. And, we tested all of those samples against our product [Cortex], as well. That was the first stage I'd say.”*

## Impersonation and Psychological Warfare

One of the most disconcerting discoveries made by the researchers was the ability of AI models to impersonate specific threat actors and malware families with uncanny accuracy. By providing the AI with open-source materials, such as articles analyzing malware campaigns, the researchers were able to generate malware that closely resembled known threats, like the [Bumblebee web shell](https://unit42.paloaltonetworks.com/bumblebee-webshell-xhunt-campaign/).

Dudas predicts that "Impersonation and psychological warfare will be a big thing in the coming years," He cautions:

*"...if you've tried asking generative AI to write a letter like Jane Austen would, the results are scary. Similarly, threat actors can impersonate others and plant false flags for researchers to uncover. I mean, that's purely speculative at this point, but imagine a nation actor with ill intent using psychological warfare, mimicking another nation's arsenal, kit or malware and planting false flags, trying to make it look as if another country or another threat actor made a specific attack. It opens the door for a lot of nasty business and makes attribution and detection pretty difficult for the defending side.”*

## The Perils of Polymorphic Malware

Another alarming trend highlighted by the researchers is the potential for AI to generate a vast array of malware variants with similar functionalities and overwhelming security professionals. Dudas warns, "Polymorphic malware – giving LLMs snippets of malware source code – could lead to a staggering amount of slightly different samples with similar functionalities that will overwhelm researchers."

This proliferation of polymorphic malware, combined with the increasing sophistication of AI-generated threats, could render traditional signature-based detection methods obsolete. As Dudas puts it, "Signature-based engines are dying. Detecting malware based on specific strings or other identifiers is already too wide a net. With the addition of polymorphy and automatically generated malware, this net could be torn completely."

Key characteristics of polymorphic malware include:

* **Mutation** – The malware automatically modifies its code each time it replicates or infects a new system, making it difficult for signature-based detection methods to identify it.
* **Encryption** – Polymorphic malware often uses encryption to hide its payload, further complicating detection and analysis.
* **Obfuscation** – The malware employs various techniques to conceal its true functionality, such as dead code insertion, register renaming and instruction substitution.
* **Functionality Preservation** – Despite the constant changes in its code, polymorphic malware retains its original malicious functionality.
* **Harder to Detect and Analyze** – Due to its changing nature, polymorphic malware is more challenging for antivirus software to detect and for security researchers to analyze and understand.

## The Evolution of Phishing and Scamming

Dudas also foresees a significant transformation in the area of phishing and scamming, due to the advanced natural language capabilities of large language models (LLMs). He explains:

*"Since LLMs usually sound so natural to end users, I'd say the field of phishing and scamming will undergo the biggest alteration. For example, weird grammar, a sense of urgency and pressure, as well as spelling errors are the easiest ways to recognize a phishing email. With LLMs, these telltale signs are a thing of the past. You could generate an entire convincing campaign from scratch in no time with a basic understanding of what makes people tick, even if you do not speak the language."*

AI algorithms can analyze vast amounts of publicly available data to create highly personalized phishing emails, tailored to specific individuals, increasing the likelihood of the recipient falling for the scam. AI-powered natural language generation (NLG) can create convincing and contextually relevant phishing emails that mimic human writing styles, complete with proper grammar and tone, making it harder for recipients to identify them as fraudulent.

Likewise, AI-driven chatbots and voice synthesis can be used to create realistic conversational interactions, tricking victims into divulging sensitive information or performing actions that benef...