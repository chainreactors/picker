---
title: Obligatory ChatGPT Post
url: https://www.schneier.com/blog/archives/2022/12/obligatory-chatgpt-post.html
source: Schneier on Security
date: 2022-12-14
fetch_date: 2025-10-04T01:27:50.390498
---

# Obligatory ChatGPT Post

# [Schneier on Security](https://www.schneier.com/)

Menu

* [Blog](https://www.schneier.com)
* [Newsletter](https://www.schneier.com/crypto-gram/)
* [Books](https://www.schneier.com/books/)
* [Essays](https://www.schneier.com/essays/)
* [News](https://www.schneier.com/news/)
* [Talks](https://www.schneier.com/talks/)
* [Academic](https://www.schneier.com/academic/)
* [About Me](https://www.schneier.com/blog/about/)

### Search

*Powered by [DuckDuckGo](https://duckduckgo.com/)*

Blog

Essays

Whole site

### Subscribe

[![Atom](https://www.schneier.com/wp-content/uploads/2019/10/rss-32px.png)](https://www.schneier.com/feed/atom/)[![Facebook](https://www.schneier.com/wp-content/uploads/2019/10/facebook-32px.png)](https://www.facebook.com/bruce.schneier)[![Twitter](https://www.schneier.com/wp-content/uploads/2019/10/twitter-32px.png)](https://twitter.com/schneierblog)[![Email](https://www.schneier.com/wp-content/uploads/2019/10/email-32px.png)](https://www.schneier.com/crypto-gram)

[Home](https://www.schneier.com)[Blog](https://www.schneier.com/blog/archives/)

## Obligatory ChatGPT Post

[Seems](https://oneusefulthing.substack.com/p/the-mechanical-professor%20) [like](https://www.nytimes.com/2022/12/05/technology/chatgpt-ai-twitter.html) [absolutely](https://www.theatlantic.com/technology/archive/2022/12/openai-chatgpt-writing-high-school-english-essay/672412/) [everyone](https://theconversation.com/the-chatgpt-chatbot-is-blowing-people-away-with-its-writing-skills-an-expert-explains-why-its-so-impressive-195908) [everywhere](https://www.theatlantic.com/technology/archive/2022/12/openai-chatgpt-chatbot-messages/672411/?utm_source=nextdraft&utm_medium=email) [is](https://www.theatlantic.com/technology/archive/2022/12/chatgpt-ai-writing-college-student-essays/672371/) [playing](https://techcrunch.com/2022/12/05/chatgpt-shrugged/) [with](https://www.bleepingcomputer.com/news/technology/openais-new-chatgpt-bot-10-dangerous-things-its-capable-of/) [Chat GPT](https://chat.openai.com/chat).

So I did, too….

*Write an essay in the style of Bruce Schneier on how ChatGPT will affect cybersecurity.*

> As with any new technology, the development and deployment of ChatGPT is likely to have a significant impact on the field of cybersecurity. In many ways, ChatGPT and other AI technologies hold great promise for improving the ability of organizations and individuals to defend against cyber threats. At the same time, however, the use of these technologies also raises important questions and concerns about the potential risks and challenges they may pose.
>
> One of the key ways in which ChatGPT is likely to affect cybersecurity is by enabling organizations to more quickly and accurately identify potential security threats. With its ability to analyze vast amounts of data and identify patterns and trends that might be difficult for humans to spot, ChatGPT could be a valuable tool for detecting and responding to cyberattacks. This could be especially useful in the case of complex, coordinated attacks that might otherwise be difficult to identify and defend against.
>
> Another potential benefit of ChatGPT in the realm of cybersecurity is its ability to improve communication and coordination among different organizations and agencies. By enabling these groups to more easily share information and work together to defend against cyber threats, ChatGPT could help to make the overall cybersecurity landscape more effective and efficient. This could be especially important in the case of large-scale attacks that require a coordinated response from multiple organizations.
>
> Of course, as with any new technology, there are also potential risks and challenges associated with the use of ChatGPT in the field of cybersecurity. One key concern is the potential for ChatGPT to be used by malicious actors to conduct cyberattacks. By automating the process of planning and executing attacks, ChatGPT could make it easier for attackers to carry out sophisticated, coordinated attacks at a much faster pace than would be possible without AI. This could potentially make it more difficult for organizations and individuals to defend against such attacks.
>
> Another potential risk is the possibility that ChatGPT could be used to create fake news or propaganda, which could be used to spread misinformation or confusion. In the context of cybersecurity, the spread of false information could potentially lead to confusion and panic, making it more difficult for organizations and individuals to respond effectively to cyber threats. Additionally, the use of ChatGPT to create fake news or propaganda could also undermine trust in information and communications systems, potentially undermining the overall security of these systems.
>
> Overall, the development and deployment of ChatGPT is likely to have a significant impact on the field of cybersecurity. While ChatGPT and other AI technologies hold great promise for improving the ability of organizations and individuals to defend against cyber threats, it is important to carefully consider the potential risks and challenges they may pose, and to take appropriate measures to mitigate these risks. This may include implementing strict security protocols and safeguards to prevent unauthorized access to ChatGPT and other AI systems, as well as ongoing monitoring and evaluation to ensure that these technologies are being used in a safe and responsible manner.

Not bad. I don’t think I can retire, but I probably can go on vacation for a few days. And, of course, it’s going to get better…a lot better…and probably sooner than we expect. This is a big deal.

Tags: [AI](https://www.schneier.com/tag/ai/), [impersonation](https://www.schneier.com/tag/impersonation/)

[Posted on December 13, 2022 at 7:17 AM](https://www.schneier.com/blog/archives/2022/12/obligatory-chatgpt-post.html) •
[82 Comments](https://www.schneier.com/blog/archives/2022/12/obligatory-chatgpt-post.html#comments)

### Comments

jbmartin6 •
[December 13, 2022 8:08 AM](https://www.schneier.com/blog/archives/2022/12/obligatory-chatgpt-post.html/#comment-413810)

I don’t agree with ‘not bad.’ It reads like a middle school essay desperately trying to meet a word count goal without anything to say. The grammar and spelling are mostly correct, but that’s just some judicious cut and pasting. It’s a long way from being able to generate anything with real meaning.

Stephen Smoogen •
[December 13, 2022 8:25 AM](https://www.schneier.com/blog/archives/2022/12/obligatory-chatgpt-post.html/#comment-413811)

I have come to the conclusion that this is just the sign of the harvesting season of a Tech growth cycle. It seems to me that at the dotcom downturn and the 2009 downturn, a ton of AI companies came out of the woodwork with products which showed a lot of advances over the last generation. These would then get a ton of play in both the hacker and tech-press circles about how it was going to put people out of work, etc. Instead it just lead to various VC’s investments to get paid off as the companies are bought by Google, IBM, and various other large companies to be ‘integrated into existing products’. Then almost nothing more except small press releases until the next tech cycle is about to crash.

I do realize that just like “the boy who cried wolf” eventually the AI wolf is going to take over a lot of the work being done.. but I also think it will take a lot longer than most articles realize.

modus phonins •
[December 13, 2022 8:46 AM](https://www.schneier.com/blog/archives/2022/12/obligatory-chatgpt-post.html/#comment-413814)

Hovering somewhere off the edge of meaning.

Like this

<https://www.thingiverse.com/search?type=things&q=Shivinteger&sort=popular&posted_after=now-30d&page=1>

Or, the ultimate chatbot

<https://www.you-books.com/book/F-Brown/Answer>

Always remember, the “I” in AI is used equivocally. Those who converse with chatbots become like them.

arf'n'arf •
[December 13, 2022 8:58 AM]...