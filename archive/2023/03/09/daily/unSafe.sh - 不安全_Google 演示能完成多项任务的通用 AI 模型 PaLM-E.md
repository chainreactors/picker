---
title: Google 演示能完成多项任务的通用 AI 模型 PaLM-E
url: https://buaq.net/go-152625.html
source: unSafe.sh - 不安全
date: 2023-03-09
fetch_date: 2025-10-04T08:59:31.259108
---

# Google 演示能完成多项任务的通用 AI 模型 PaLM-E

* [unSafe.sh - 不安全](https://unsafe.sh)
* [我的收藏](/user/collects)
* [今日热榜](/?hot=true)
* [公众号文章](/?gzh=true)
* [导航](/nav/index)
* [Github CVE](/cve)
* [Github Tools](/tools)
* [编码/解码](/encode)
* [文件传输](/share/index)
* [Twitter Bot](https://twitter.com/buaqbot)
* [Telegram Bot](https://t.me/aqinfo)
* [Search](/search/search)

[Rss](/rss.xml)

[ ]
黑夜模式

![]()

Google 演示能完成多项任务的通用 AI 模型 PaLM-E

Google 和柏林科技大学的一组研究人员透露了可用于控制机器人的多模态 Embodied 视觉语言模型（VLM）PaLM-E，有 5620 亿个参数，融合了视觉和语言处理。当用户发出“高
*2023-3-8 23:43:34
Author: [www.solidot.org(查看原文)](/jump-152625.htm)
阅读量:15
收藏*

---

Google 和柏林科技大学的一组研究人员透露了可用于控制机器人的多模态 Embodied 视觉语言模型（VLM）PaLM-E，有 5620 亿个参数，融合了视觉和语言处理。当用户发出“高阶指令”，如“将抽屉里的米片拿过我”， PaLM-E 能为装备机械臂的移动机器人平台生成一个行动计划，并自行执行。它执行不同任务不需要预先或重复训练。消除数据预处理或注释给予了机器人更强大的自主控制。PaLM-E 是基于 Google 现有的大语言模型 PaLM，通过加入感觉信息和机器人控制使其有具身性(embodied) 。它能与处理语言的相同方式理解感觉信息。

https://palm-e.github.io/#demo

文章来源: https://www.solidot.org/story?sid=74337
 如有侵权请联系:admin#unsafe.sh

© [unSafe.sh - 不安全](https://unsafe.sh) Powered By [PaperCache](https://github.com/code-scan/PaperCache)

* admin#unsafe.sh
* [安全马克](https://aq.mk)
* [星际黑客](https://xj.hk)
* [T00ls](https://t00ls.net)