---
title: What brain privacy will look like in the age of neurotech
url: https://therecord.media/what-brain-privacy-will-look-like
source: Over Security - Cybersecurity news aggregator
date: 2025-10-27
fetch_date: 2025-10-28T03:00:15.428447
---

# What brain privacy will look like in the age of neurotech

![](https://recordedfuture.matomo.cloud/matomo.php?idsite=2&rec=1)

[![Cyber Security News  | The Record](https://cms.therecord.media/uploads/The_Record_Centered_9b27d79125.svg)](/)

* [Leadership](/news/leadership)
* [Cybercrime](/news/cybercrime)
* [Nation-state](/news/nation-state)
* [Influence Operations](/news/influence-operations)
* [Technology](/news/technology)

* [Cyber Daily®](https://therecord.media/subscribe)
* [Click Here Podcast](/podcast)

Go

Subscribe to The Record

[✉️ Free Newsletter](/subscribe)

![nita farhany](https://cms.therecord.media/uploads/format_webp/large_2025_1023_The_Record_Q_and_A_Nita_Farahany_7fdade1051.jpg)

[Suzanne Smalley](/author/suzanne-smalley)October 27th, 2025

# What brain privacy will look like in the age of neurotech

*Nita Farahany is one of the country’s foremost experts on neural data privacy and is the author of [The Battle for Your Brain:](https://www.amazon.com/Battle-Your-Brain-Defending-Neurotechnology/dp/1250272955) Defending the Right to Think Freely in the Age of Neurotechnology. As chair of the Uniform Laws Commission Study Committee on Mental Privacy she is leading work honing a proposal for how states should regulate neural privacy.*

*Farahany has closely studied the evolution of neural technology and what the implications are for privacy and autonomy. She spoke with Recorded Future News about whether brain data will be commodified, how your brain can be hacked and the role artificial intelligence plays in allowing internal speech to be decoded.*

*This conversation has been edited for length and clarity.*

**Recorded Future News: You've spent a lot of time researching the next frontier of neurotechnology and the privacy implications of the expanding neurotech market. What do you see as the biggest dangers posed, and how should the government think about regulation of this field?**

**Nita Farahany:** In nearly every aspect of our lives we have entered into digital cages [where] we are tracking nearly everything — our movements, everything we say, everything we do, every online purchasing behavior, every online website that we visit.

The biggest risk I see is [the brain] no longer being a safe space — that it suddenly becomes up for grabs, like everything else is up for grabs. It's so fundamental to what it means to be human and the experience of being human, that if we don't safeguard it, if we don't put into place the right set of laws and protections and design principles we risk not just losing our privacy, but losing what it means to be human.

**RFN: I was speaking with an expert who told me that she thinks it will become increasingly hard for people to avoid giving up neural data. She said it is possible that down the road companies could make earbuds, where if you want to use them you have to allow for neural data collection. Do you see the marketplace evolving this way?**

**NF:** It could. What I see, and what I talk about in my book, is the coming age of widespread neural interface. And what I mean by that is up until now, most of the neurotechnology that's been on the market has either been implanted neurotechnology for medical purposes or it has been entertainment and incredibly narrow.

At the same time, the sensor market has been exploding and the capabilities of AI have been exploding and so people are increasingly used to wearing a watch with smart features that pick up their heart rate or temperature. There are rings that do that. Devices that have come to the market, like glasses and virtual reality devices — these are packed with sensors, from cameras to everything else, and the traditional ways that we've interacted with our technology, like using a keyboard or a mouse, doesn't make sense for the new computing platforms that are coming out. If you have on augmented reality glasses, using a keyboard or a joystick or a mouse adds a layer of friction between you and those devices.

What Meta has just introduced, what Apple has now made native as part of its accessibility protocols, is to enable picking up your intentions through neural signals and sensors that AI decodes to allow you to navigate through all of that technology. So I think the first generation of most of these devices will be optional. That is, you can get the smart watch without the neural band, you can get the airpods without the EEG [electroencephalogram] sensors in them. But just like you can't get an Apple watch now without getting an Apple watch with a heart rate sensor, second and third generation of these devices, I think your only option will be to get the devices that have the neural sensors in them. And the only way that you can navigate through using an augmented reality headset or a virtual reality set headset, or eventually, potentially even any other computing platform, will be neural interface technology.

**RFN: An analogy would be how we've all decided we want to use Google, so we'll just allow our data to be tracked.**

**NF:** Yeah, and it's a free service, right? It's a free service that we understand, that we pay for with our data, and it's powering an ad tech ecosystem. Is it necessary for companies to commodify your brain data in order to be able to provide you services? No. We can build different business models. The question is will we. I think it will require that there actually be demand side pressure, both from laws, but also from consumers.

It's notable that the first products on the marketplace aren't doing it that way, right? If you look at Meta’s neural band, they've decided to keep brain data on devices rather than commodifying that data for now. That's a term of service that could quickly change.

**RFN: You have said that in the future wearables may allow bosses to see how workers are reacting to them, or police to see a criminal suspect's reaction to a crime scene photo. Can you talk through these examples and others showing how our thoughts will no longer be private, how emotions will be able to be read?**

**NF:** I don't think every thought you think, through simple EEG sensors, is going to become decodable. But I think a lot of what you think will become decodable, and a lot more than just emotions.

Increasingly there is priming and response that you can see with EEG. One of the examples I use in the book is how there are reports in China where workers who are required to wear these EEG headsets have been presented with communist messaging, and then their reaction to that communist messaging in the workplace is powerful evidence that the state can gather against them to see if they negatively react. Imagine you want to know ‘how does this person react to an image of the boss?’ They claim that they really like that presentation. What's their real time reaction to it? There's a lot of information that you can start to expect, that may be mined from people's brains. Are they paying attention, or is their mind wandering? Metrics, and kind of proxies of productivity, to more granular information about what a person is thinking or feeling.

**RFN: We're already in the place where neural tech can read stress. How far out do you think these more granular capabilities are?**

**NF:** Every time somebody says, ‘Oh, that's five or 10 years away,’ a few months later, there's some leap in capabilities and AI technologies that makes them take it all back.

**RFN: What role is AI playing?**

**NF:** AI predicts the next token. If you've been trained on the entire corpus of human text and knowledge, you know that when a person thinks ‘close the’ that next word is most likely door or window. There's a prediction for what most likely comes next. So if you're decoding a brain state and you're able to reliably decode ‘close’, your ability to predict ‘close the door’ becomes increasingly more powerful as AI becomes more powerful. And so going from having to translate every brain signal to having an incredibly powerful predictive machine that can predict, once you have some brain sig...