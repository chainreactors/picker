---
title: [译] 什么是 GPT？Transformer 工作原理的动画展示（2024）
url: https://arthurchiao.github.io/blog/visual-intro-to-transformers-zh/
source: ArthurChiao's Blog
date: 2024-05-13
fetch_date: 2025-10-06T17:13:44.520437
---

# [译] 什么是 GPT？Transformer 工作原理的动画展示（2024）

# [ArthurChiao's Blog](https://arthurchiao.github.io/)

* [Home](/index.html)
* [Articles (EN)](/articles)
* [Articles (дёӯж–Ү)](/articles-zh)
* [Categories](/categories)
* [About](/about)
* [Donate](/donate)

# [иҜ‘] д»Җд№ҲжҳҜ GPTпјҹTransformer е·ҘдҪңеҺҹзҗҶзҡ„еҠЁз”»еұ•зӨәпјҲ2024пјү

Published at 2024-05-12 | Last Update 2024-05-12

### иҜ‘иҖ…еәҸ

жң¬ж–Үзҝ»иҜ‘иҮӘ 2024 е№ҙзҡ„дёҖдёӘи§Ҷйў‘пјҲеүҚеҚҠйғЁеҲҶпјүпјҢиҝҷжҳҜеҺҹдҪңиҖ… Deep Learning зі»еҲ—зҡ„з¬¬ 5 з« пјҢејәзғҲжҺЁиҚҗеҺҹи§Ҷйў‘пјҡ

* Youtubeпјҡ[But what is a GPT? Visual intro to transformers](https://www.youtube.com/watch?v=wjZofJX0v4M)пјӣ
* B з«ҷпјҡ[е®ҳж–№жҗ¬иҝҗ](https://www.bilibili.com/video/BV13z421U7cs)гҖӮ

![](/assets/img/visual-intro-to-transformers/transformer-modules.gif)

Transformer йў„жөӢдёӢдёҖдёӘеҚ•иҜҚеӣӣйғЁжӣІгҖӮMLP д№ҹз§°дёә feed-forwardгҖӮ

дҪңиҖ…д»Ҙж·ұеҺҡзҡ„жҠҖжңҜз§ҜзҙҜпјҢе°ҶдёҖдәӣеӨҚжқӮзі»з»ҹд»ҘеҸҜи§ҶеҢ–зҡ„ж–№ејҸи®Із»ҷжҷ®йҖҡдәәпјҢиҝҷз§ҚиғҪеҠӣжҳҜжһҒе…¶йҡҫеҫ—зҡ„гҖӮ
жң¬иҜ‘ж–ҮеёҢжңӣйҖҡиҝҮвҖңж–Үеӯ—+еҠЁеӣҫвҖқиҝҷз§ҚеҸҜи§ҶеҢ–еҸҲж–№дҫҝйҡҸж—¶еҒңдёӢжқҘжҖқиҖғзҡ„ж–№ејҸд»Ӣз»Қ Transformer зҡ„еҶ…йғЁе·ҘдҪңеҺҹзҗҶгҖӮ
еҰӮжһңжғіиҝӣдёҖжӯҘд»ҺжҠҖжңҜе’Ңе®һзҺ°дёҠдәҶи§Ј Transformer/GPT/LLMпјҢеҸҜеҸӮиҖғпјҡ

* [GPT жҳҜеҰӮдҪ•е·ҘдҪңзҡ„пјҡ200 иЎҢ Python д»Јз Ғе®һзҺ°дёҖдёӘжһҒз®Җ GPTпјҲ2023пјү](/blog/gpt-as-a-finite-state-markov-chain-zh/)
* [Transformer жҳҜеҰӮдҪ•е·ҘдҪңзҡ„пјҡ600 иЎҢ Python д»Јз Ғе®һзҺ° self-attention е’ҢдёӨзұ» TransformerпјҲ2019пјү](/blog/transformers-from-scratch-zh/)
* [InstructGPTпјҡеҹәдәҺдәәзұ»еҸҚйҰҲи®ӯз»ғиҜӯиЁҖжЁЎеһӢйҒөд»ҺжҢҮд»Өзҡ„иғҪеҠӣпјҲOpenAIпјҢ2022пјү](/blog/instructgpt-paper-zh/)
* [еӨ§иҜӯиЁҖжЁЎеһӢпјҲLLMпјүз»јиҝ°дёҺе®һз”ЁжҢҮеҚ—пјҲAmazonпјҢ2023пјү](/blog/llm-practical-guide-zh/)
* [еҰӮдҪ•и®ӯз»ғдёҖдёӘдјҒдёҡзә§ GPT еҠ©жүӢпјҲOpenAIпјҢ2023пјү](/blog/how-to-train-a-gpt-assistant-zh/)

ж°ҙе№іеҸҠз»ҙжҠӨзІҫеҠӣжүҖйҷҗпјҢиҜ‘ж–ҮдёҚе…ҚеӯҳеңЁй”ҷиҜҜжҲ–иҝҮж—¶д№ӢеӨ„пјҢеҰӮжңүз–‘й—®пјҢиҜ·жҹҘйҳ…еҺҹи§Ҷйў‘гҖӮ
**дј ж’ӯзҹҘиҜҶпјҢе°ҠйҮҚеҠіеҠЁпјҢе№ҙж»ЎеҚҒе…«е‘ЁеІҒпјҢиҪ¬иҪҪиҜ·жіЁжҳҺ[еҮәеӨ„](https://arthurchiao.art)**гҖӮ

д»ҘдёӢжҳҜиҜ‘ж–ҮгҖӮ

---

* [иҜ‘иҖ…еәҸ](#иҜ‘иҖ…еәҸ)
* [1 еӣҫи§Ј вҖңGenerative Pre-trained TransformerвҖқпјҲGPTпјү](#1-еӣҫи§Ј-generative-pre-trained-transformergpt)
  + [1.1 Generativeпјҡз”ҹжҲҗејҸ](#11-generativeз”ҹжҲҗејҸ)
    - [1.1.1 еҸҜи§ҶеҢ–](#111-еҸҜи§ҶеҢ–)
    - [1.1.2 з”ҹжҲҗејҸ vs. еҲӨеҲ«ејҸпјҲиҜ‘жіЁпјү](#112-з”ҹжҲҗејҸ-vs-еҲӨеҲ«ејҸиҜ‘жіЁ)
  + [1.2 Pre-trainedпјҡйў„и®ӯз»ғ](#12-pre-trainedйў„и®ӯз»ғ)
    - [1.2.1 еҸҜи§ҶеҢ–](#121-еҸҜи§ҶеҢ–)
    - [1.2.2 йў„и®ӯз»ғ vs. еўһйҮҸи®ӯз»ғпјҲеҫ®и°ғпјү](#122-йў„и®ӯз»ғ-vs-еўһйҮҸи®ӯз»ғеҫ®и°ғ)
  + [1.3 TransformerпјҡдёҖзұ»зҘһз»ҸзҪ‘з»ңжһ¶жһ„](#13-transformerдёҖзұ»зҘһз»ҸзҪ‘з»ңжһ¶жһ„)
  + [1.4 е°Ҹз»“](#14-е°Ҹз»“)
* [2 Transformer иө·жәҗдёҺеә”з”Ё](#2-transformer-иө·жәҗдёҺеә”з”Ё)
  + [2.1 Attention Is All You Need, Google, 2017пјҢжңәеҷЁзҝ»иҜ‘](#21-attention-is-all-you-need-google-2017жңәеҷЁзҝ»иҜ‘)
  + [2.2 **`Generative`** Transformer](#22-generative-transformer)
  + [2.3 **`GPT-2/GPT-3`** з”ҹжҲҗж•ҲжһңпјҲж–Үжң¬з»ӯеҶҷпјүйў„и§Ҳ](#23-gpt-2gpt-3-з”ҹжҲҗж•Ҳжһңж–Үжң¬з»ӯеҶҷйў„и§Ҳ)
  + [2.4 **`ChatGPT`** зӯүдәӨдә’ејҸеӨ§жЁЎеһӢ](#24-chatgpt-зӯүдәӨдә’ејҸеӨ§жЁЎеһӢ)
  + [2.5 е°Ҹз»“](#25-е°Ҹз»“)
* [3 Transformer ж•°жҚ®еӨ„зҗҶеӣӣйғЁжӣІ](#3-transformer-ж•°жҚ®еӨ„зҗҶеӣӣйғЁжӣІ)
  + [3.1 EmbeddingпјҡеҲҶиҜҚдёҺеҗ‘йҮҸиЎЁзӨә](#31-embeddingеҲҶиҜҚдёҺеҗ‘йҮҸиЎЁзӨә)
    - [3.1.1 token зҡ„еҗ‘йҮҸиЎЁзӨә](#311-token-зҡ„еҗ‘йҮҸиЎЁзӨә)
    - [3.1.2 еҗ‘йҮҸиЎЁзӨәзҡ„зӣҙи§Ӯи§ЈйҮҠ](#312-еҗ‘йҮҸиЎЁзӨәзҡ„зӣҙи§Ӯи§ЈйҮҠ)
  + [3.2 Attentionпјҡembedding еҗ‘йҮҸй—ҙзҡ„иҜӯд№үдәӨжөҒ](#32-attentionembedding-еҗ‘йҮҸй—ҙзҡ„иҜӯд№үдәӨжөҒ)
    - [3.2.1 иҜӯд№үдәӨжөҒ](#321-иҜӯд№үдәӨжөҒ)
    - [3.2.2 дҫӢеӯҗпјҡвҖқmachine learning **`model`**вҖқ / вҖңfashion **`model`**вҖқ](#322-дҫӢеӯҗmachine-learning-model--fashion-model)
  + [3.3 Feed-forward / MLPпјҡеҗ‘йҮҸд№Ӣй—ҙж— дәӨжөҒ](#33-feed-forward--mlpеҗ‘йҮҸд№Ӣй—ҙж— дәӨжөҒ)
    - [3.3.1 й’ҲеҜ№жүҖжңүеҗ‘йҮҸеҒҡдёҖж¬ЎжҖ§еҸҳжҚў](#331-й’ҲеҜ№жүҖжңүеҗ‘йҮҸеҒҡдёҖж¬ЎжҖ§еҸҳжҚў)
    - [3.3.2 зӣҙи§Ӯи§ЈйҮҠ](#332-зӣҙи§Ӯи§ЈйҮҠ)
    - [3.3.3 йҮҚеӨҚ Attention + Feed-forward жЁЎеқ—пјҢз»„жҲҗеӨҡеұӮзҪ‘з»ң](#333-йҮҚеӨҚ-attention--feed-forward-жЁЎеқ—з»„жҲҗеӨҡеұӮзҪ‘з»ң)
  + [3.4 UnembeddingпјҡжҰӮзҺҮ](#34-unembeddingжҰӮзҺҮ)
    - [3.4.1 жңҖеҗҺдёҖеұӮ feed-forward иҫ“еҮәдёӯзҡ„жңҖеҗҺдёҖдёӘеҗ‘йҮҸ](#341-жңҖеҗҺдёҖеұӮ-feed-forward-иҫ“еҮәдёӯзҡ„жңҖеҗҺдёҖдёӘеҗ‘йҮҸ)
    - [3.4.2 дёӢдёҖдёӘеҚ•иҜҚзҡ„йҖүжӢ©](#342-дёӢдёҖдёӘеҚ•иҜҚзҡ„йҖүжӢ©)
  + [3.5 е°Ҹз»“](#35-е°Ҹз»“)
* [4 GPT -> ChatGPTпјҡд»Һж–Үжң¬иЎҘе…ЁеҲ°дәӨдә’ејҸиҒҠеӨ©еҠ©жүӢ](#4-gpt---chatgptд»Һж–Үжң¬иЎҘе…ЁеҲ°дәӨдә’ејҸиҒҠеӨ©еҠ©жүӢ)
  + [4.1 зі»з»ҹжҸҗзӨәиҜҚпјҢдјӘиЈ…жҲҗиҒҠеӨ©](#41-зі»з»ҹжҸҗзӨәиҜҚдјӘиЈ…жҲҗиҒҠеӨ©)
  + [4.2 еҰӮдҪ•и®ӯз»ғдёҖдёӘдјҒдёҡзә§ GPT еҠ©жүӢпјҲиҜ‘жіЁпјү](#42-еҰӮдҪ•и®ӯз»ғдёҖдёӘдјҒдёҡзә§-gpt-еҠ©жүӢиҜ‘жіЁ)
* [5 жҖ»з»“](#5-жҖ»з»“)

---

# 1 еӣҫи§Ј вҖңGenerative Pre-trained TransformerвҖқпјҲGPTпјү

GPT жҳҜ Generative Pre-trained Transformer зҡ„зј©еҶҷпјҢзӣҙиҜ‘дёәвҖңз”ҹжҲҗејҸйў„и®ӯз»ғ transformerвҖқпјҢ
жҲ‘д»¬е…Ҳд»Һеӯ—йқўдёҠи§ЈйҮҠдёҖдёӢе®ғд»¬еҲҶеҲ«жҳҜд»Җд№Ҳж„ҸжҖқгҖӮ

## 1.1 Generativeпјҡз”ҹжҲҗејҸ

вҖңGenerativeвҖқпјҲ**з”ҹжҲҗејҸ**пјүж„ҸжҖқеҫҲзӣҙзҷҪпјҢе°ұжҳҜз»ҷе®ҡдёҖж®өиҫ“е…ҘпјҲдҫӢеҰӮпјҢжңҖеёёи§Ғзҡ„ж–Үжң¬иҫ“е…ҘпјүпјҢ
жЁЎеһӢе°ұиғҪ**з»ӯеҶҷ**пјҲвҖңзј–вҖқпјүдёӢеҺ»гҖӮ

### 1.1.1 еҸҜи§ҶеҢ–

дёӢйқўжҳҜдёӘдҫӢеӯҗпјҢз»ҷе®ҡ вҖңThe most effective way to learn computer science isвҖқ дҪңдёәиҫ“е…ҘпјҢ
жЁЎеһӢе°ұејҖе§Ӣз»ӯеҶҷеҗҺйқўзҡ„еҶ…е®№дәҶгҖӮ

![](/assets/img/visual-intro-to-transformers/generative-meaning.gif)

вҖңGenerativeвҖқпјҡз”ҹжҲҗпјҲз»ӯеҶҷпјүж–Үжң¬зҡ„иғҪеҠӣгҖӮ

### 1.1.2 з”ҹжҲҗејҸ vs. еҲӨеҲ«ејҸпјҲиҜ‘жіЁпјү

ж–Үжң¬з»ӯеҶҷиҝҷз§Қз”ҹжҲҗејҸжЁЎеһӢпјҢеҢәеҲ«дәҺ BERT йӮЈз§Қ**еҲӨеҲ«ејҸ**жЁЎеһӢпјҲз”ЁдәҺеҲҶзұ»гҖҒе®ҢеҪўеЎ«з©әзӯүзӯүпјүпјҢ

* [BERTпјҡйў„и®ӯз»ғж·ұеәҰеҸҢеҗ‘ Transformers еҒҡиҜӯиЁҖзҗҶи§ЈпјҲGoogleпјҢ2019пјү](/blog/bert-paper-zh/)

## 1.2 Pre-trainedпјҡйў„и®ӯз»ғ

вҖңPre-trainedвҖқпјҲйў„и®ӯз»ғпјүжҢҮзҡ„жҳҜжЁЎеһӢжҳҜ**з”ЁеӨ§йҮҸж•°жҚ®и®ӯз»ғеҮәжқҘзҡ„**гҖӮ

### 1.2.1 еҸҜи§ҶеҢ–

![](/assets/img/visual-intro-to-transformers/pre-trained-meaning.gif)

вҖңPre-trainedвҖқпјҡз”ЁеӨ§йҮҸж•°жҚ®иҝӣиЎҢи®ӯз»ғгҖӮ
еӣҫдёӯзҡ„еӨ§йҮҸж—Ӣй’®/д»ӘиЎЁзӣҳе°ұжҳҜжүҖи°“зҡ„вҖңжЁЎеһӢеҸӮж•°вҖқпјҢи®ӯз»ғиҝҮзЁӢе°ұжҳҜеңЁдёҚж–ӯдјҳеҢ–иҝҷдәӣеҸӮж•°пјҢеҗҺйқўдјҡиҜҰз»Ҷд»Ӣз»ҚгҖӮ

### 1.2.2 йў„и®ӯз»ғ vs. еўһйҮҸи®ӯз»ғпјҲеҫ®и°ғпјү

**вҖңйў„вҖқ**иҝҷдёӘеӯ—д№ҹжҡ—зӨәдәҶжЁЎеһӢиҝҳжңүеңЁзү№е®ҡд»»еҠЎдёӯ**иҝӣдёҖжӯҘи®ӯз»ғ**зҡ„еҸҜиғҪ вҖ”вҖ”
д№ҹе°ұжҳҜжҲ‘д»¬еёёиҜҙзҡ„**вҖңеҫ®и°ғвҖқ**пјҲfinetuningпјүгҖӮ

> еҰӮдҪ•еҜ№йў„и®ӯз»ғжЁЎеһӢиҝӣиЎҢеҫ®и°ғпјҡ
> [InstructGPTпјҡеҹәдәҺдәәзұ»еҸҚйҰҲи®ӯз»ғиҜӯиЁҖжЁЎеһӢйҒөд»ҺжҢҮд»Өзҡ„иғҪеҠӣпјҲOpenAIпјҢ2022пјү](/blog/instructgpt-paper-zh/)гҖӮ
> иҜ‘жіЁгҖӮ

## 1.3 TransformerпјҡдёҖзұ»зҘһз»ҸзҪ‘з»ңжһ¶жһ„

вҖңGPTвҖқ дёүдёӘиҜҚдёӯжңҖйҮҚиҰҒзҡ„е…¶е®һжҳҜжңҖеҗҺдёҖдёӘиҜҚ TransformerгҖӮ
Transformer жҳҜдёҖзұ»**зҘһз»ҸзҪ‘з»ң**/жңәеҷЁеӯҰд№ жЁЎеһӢпјҢдҪңдёәиҝ‘жңҹ AI йўҶеҹҹзҡ„ж ёеҝғеҲӣж–°пјҢ
жҺЁеҠЁзқҖиҝҷдёӘйўҶеҹҹиҝ‘еҮ е№ҙзҡ„жһҒйҖҹеҸ‘еұ•гҖӮ

> Transformer зӣҙиҜ‘дёә**вҖңеҸҳжҚўеҷЁвҖқ**жҲ–вҖңиҪ¬жҚўеҷЁвҖқпјҢйҖҡиҝҮж•°еӯҰиҝҗз®—дёҚж–ӯеҜ№иҫ“е…Ҙж•°жҚ®иҝӣиЎҢеҸҳжҚў/иҪ¬жҚўгҖӮеҸҰеӨ–пјҢеҸҳеҺӢеҷЁгҖҒеҸҳеҪўйҮ‘еҲҡд№ҹжҳҜиҝҷдёӘиҜҚгҖӮ
> иҜ‘жіЁгҖӮ

![](/assets/img/visual-intro-to-transformers/transformer-detailed-1.gif)

TransformerпјҡдёҖзұ»зҘһз»ҸзҪ‘з»ңжһ¶жһ„зҡ„з»ҹз§°гҖӮ

![](/assets/img/visual-intro-to-transformers/transformer-detailed-2.gif)

Transformer жңҖеҗҺзҡ„иҫ“еҮәеұӮгҖӮеҗҺйқўиҝҳдјҡиҜҰз»Ҷд»Ӣз»Қ

## 1.4 е°Ҹз»“

еҰӮд»Ҡе·Із»ҸеҸҜд»ҘеҹәдәҺ Transformer жһ„е»әи®ёеӨҡдёҚеҗҢзұ»еһӢзҡ„жЁЎеһӢпјҢдёҚйҷҗдәҺж–Үжң¬пјҢдҫӢеҰӮпјҢ

* иҜӯйҹіиҪ¬ж–Үеӯ—
* ж–Үеӯ—иҪ¬иҜӯйҹі
* ж–Үз”ҹеӣҫпјҲtext-to-imageпјүпјҡDALLВ·EгҖҒMidJourney зӯүеңЁ 2022 е№ҙйЈҺйқЎе…Ёзҗғзҡ„е·Ҙе…·пјҢйғҪжҳҜеҹәдәҺ TransformerгҖӮ

  [ж–Үз”ҹеӣҫпјҲtext-to-imageпјүз®ҖеҸІпјҡжү©ж•ЈжЁЎеһӢпјҲdiffusion modelsпјүзҡ„еҙӣиө·дёҺеҸ‘еұ•пјҲ2022пјү](/blog/rise-of-diffusion-based-models-zh/)

  ![](/assets/img/visual-intro-to-transformers/dalle-pi.gif)

  иҷҪз„¶ж— жі•и®©жЁЎеһӢзңҹжӯЈзҗҶи§Ј "зү©з§Қ ПҖ"жҳҜд»Җд№ҲпјҲжң¬жқҘе°ұжҳҜзһҺзј–зҡ„пјүпјҢдҪҶе®ғз«ҹз„¶иғҪз”ҹжҲҗеҮәжқҘпјҢиҖҢдё”ж•ҲжһңеҫҲжғҠиүігҖӮ

жң¬ж–ҮеёҢжңӣйҖҡиҝҮвҖңж–Үеӯ—+еҠЁеӣҫвҖқиҝҷз§ҚеҸҜи§ҶеҢ–еҸҲж–№дҫҝйҡҸж—¶еҒңдёӢжқҘжҖқиҖғзҡ„ж–№ејҸпјҢи§ЈйҮҠ Transformer зҡ„еҶ…йғЁе·ҘдҪңеҺҹзҗҶгҖӮ

# 2 Transformer иө...