---
title: 复制型人工智能平台存在严重缺陷，导致专有数据泄露
url: https://www.anquanke.com/post/id/296768
source: 安全客-有思想的安全新媒体
date: 2024-05-25
fetch_date: 2025-10-06T17:17:12.411851
---

# 复制型人工智能平台存在严重缺陷，导致专有数据泄露

首页

阅读

* [安全资讯](https://www.anquanke.com/news)
* [安全知识](https://www.anquanke.com/knowledge)
* [安全工具](https://www.anquanke.com/tool)

活动

社区

学院

安全导航

内容精选

* [专栏](/column/index.html)
* [精选专题](https://www.anquanke.com/subject-list)
* [安全KER季刊](https://www.anquanke.com/discovery)
* [360网络安全周报](https://www.anquanke.com/week-list)

# 复制型人工智能平台存在严重缺陷，导致专有数据泄露

阅读量**116267**

发布时间 : 2024-05-24 11:22:45

**x**

##### 译文声明

本文是翻译文章

原文地址：<https://www.darkreading.com/cloud-security/critical-flaw-in-replicate-ai-platform-exposes-customer-models-proprietary-data>

译文仅供参考，具体内容表达以及含义原文为准。

Replicate AI 平台中的一个严重漏洞可能允许攻击者在平台内执行恶意 AI 模型以进行跨租户攻击——允许访问客户的私有 AI 模型并可能暴露专有知识或敏感数据。

Wiz 的研究人员在与 AI 即服务提供商合作调查其平台安全性的过程中发现了这一漏洞。这一漏洞的发现表明，在 AI 即服务解决方案之间实现租户分离非常困难，尤其是在运行来自不受信任来源的 AI 模型的环境中。

Wiz 的 Shir Tamari 和 Sagi Tzadik 在今天发表的一篇博客文章中写道：“利用此漏洞将允许未经授权访问所有 Replicate 平台客户的 AI 提示和结果”，并可能改变这些结果。此前，Wiz 的研究人员在 HuggingFace AI 平台上发现了导致类似结果的缺陷。

Wiz 首席技术官兼联合创始人 Ami Luttwak 告诉 Dark Reading：“正如我们与Hugging Face以及现在的 Replicate 这两家领先的 AI 即服务提供商合作的结果所看到的那样，在云环境中运行 AI 模型时，必须记住 AI 模型实际上是代码。”“与所有代码一样，必须验证来源，并扫描内容以查找恶意负载。”

事实上，该漏洞对 AI 即服务提供商构成了直接威胁，这些提供商通常允许其客户在共享环境中以 AI 模型的形式执行不受信任的代码（其中有其他客户的数据）。研究人员指出，它还会影响 AI 团队，当他们采用来自不受信任来源的 AI 模型并在其工作站或公司服务器上运行它们时，他们可能会受到影响。

Wiz Research 于 2023 年 1 月负责任地向 AI 模型共享供应商 Replicate 披露了该漏洞；该公司迅速缓解了该漏洞，因此没有泄露任何客户数据。目前，客户无需采取进一步行动。

**利用漏洞**
该漏洞通过创建 Cog 格式的恶意容器来实现 Replicate 平台上的远程代码执行，Cog 格式是 Replicate 上用于容器化模型的专有格式。使用 Cog 容器化模型后，用户可以将生成的图像上传到 Replicate 平台并开始与其交互。

Wiz 研究人员创建了一个恶意的 Cog 容器并将其上传到平台，然后以 root 权限使用它在 Replicate 基础设施上执行代码。

研究人员在文章中写道：“我们怀疑这种代码执行技术是一种模式，公司和组织会运行来自不受信任来源的 AI 模型，即使这些模型是可能具有恶意的代码。”类似的技术也被用于利用 HuggingFace 平台上发现的漏洞。

这项利用让研究人员能够调查环境横向移动，最终超出他们正在运行的节点，该节点位于托管在 Google Cloud Platform 上的Kubernetes 集群内。尽管这个过程很有挑战性，但他们最终能够进行跨租户攻击，从而可以查询其他模型，甚至修改这些模型的输出。

研究人员写道：“利用此漏洞将对 Replicate 平台及其用户构成重大风险。”“攻击者可能会查询客户的私人 AI 模型，从而可能暴露模型训练过程中涉及的专有知识或敏感数据。此外，拦截提示可能会暴露敏感数据，包括个人身份信息 (PII)。”

事实上，这种改变人工智能模型的提示和响应的能力对人工智能应用程序的功能构成了严重威胁，让攻击者可以操纵人工智能行为并破坏这些模型的决策过程。

研究人员写道：“这种行为直接威胁到人工智能驱动输出的准确性和可靠性，破坏了自动决策的完整性，并可能对依赖受损模型的用户产生深远影响。”

**需要采取新的缓解措施**
Luttwak 表示，目前还没有简单的方法来验证模型的真实性，或者扫描模型中的威胁，因此恶意的人工智能模型为需要其他形式缓解措施的防御者提供了新的攻击面。

实现此目标的最佳方式是确保生产工作负载仅使用安全格式的AI 模型，例如所谓的安全张量。“我们建议安全团队监控不安全模型的使用情况，并与他们的 AI 团队合作过渡到安全张量或类似格式，”他说。

仅使用安全的 AI 格式就可以“显著”地减少攻击，因为“这些格式旨在防止攻击者接管 AI 模型实例”，Luttwak 说。

此外，在共享环境中运行客户模型的云提供商应该实施租户隔离措施，以确保设法执行恶意模型的潜在攻击者无法访问其他客户的数据或服务本身，他补充道。

本文翻译自 [原文链接](https://www.darkreading.com/cloud-security/critical-flaw-in-replicate-ai-platform-exposes-customer-models-proprietary-data)。如若转载请注明出处。

商务合作，文章发布请联系 anquanke@360.cn

本文由**安全客**原创发布

转载，请参考[转载声明](https://www.anquanke.com/note/repost)，注明出处： [https://www.anquanke.com/post/id/296768](/post/id/296768)

安全KER - 有思想的安全新媒体

本文转载自:

如若转载,请注明出处： <https://www.darkreading.com/cloud-security/critical-flaw-in-replicate-ai-platform-exposes-customer-models-proprietary-data>

安全KER - 有思想的安全新媒体

分享到：![微信](https://p0.ssl.qhimg.com/sdm/28_28_100/t01e29062a5dcd13c10.png)

* [人工智能](/tag/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD)

**+1**2赞

收藏

![](https://p1.ssl.qhimg.com/t010857340ce46bb672.jpg)安全客

分享到：![微信](https://p0.ssl.qhimg.com/sdm/28_28_100/t01e29062a5dcd13c10.png)

## 发表评论

您还未登录，请先登录。

[登录](/login/index.html)

![](https://p3.ssl.qhimg.com/t014757b72460d855bf.png)

[![](https://p1.ssl.qhimg.com/t010857340ce46bb672.jpg)](/member.html?memberId=170061)

[安全客](/member.html?memberId=170061)

这个人太懒了，签名都懒得写一个

* 文章
* **2096**

* 粉丝
* **6**

### TA的文章

* ##### [英国通过数据访问和使用监管法案](/post/id/308719)

  2025-06-20 17:11:10
* ##### [CISA警告：严重缺陷（CVE-2025-5310）暴露加油站设备](/post/id/308715)

  2025-06-20 17:09:03
* ##### [大多数公司高估了AI治理，因为隐私风险激增](/post/id/308708)

  2025-06-20 17:05:02
* ##### [研究人员发现了有史以来最大的数据泄露事件，暴露了160亿个登录凭证](/post/id/308704)

  2025-06-20 17:02:15
* ##### [CVE-2025-6018和CVE-2025-6019漏洞利用：链接本地特权升级缺陷让攻击者获得大多数Linux发行版的根访问权限](/post/id/308701)

  2025-06-20 16:59:36

### 相关文章

* ##### [人工智能可能修复帮助传播了 15 年的漏洞](/post/id/308401)

  2025-06-12 15:19:33
* ##### [浅析新型网络犯罪DeepSeek AI实战应用](/post/id/305102)

  2025-03-18 10:38:20
* ##### [360SRC x Hacking Group丨「奇御」AI安全技术沙龙议题征集！](/post/id/302279)

  2024-11-28 17:43:31
* ##### [从误用到滥用： 人工智能风险与攻击](/post/id/300992)

  2024-10-17 11:00:07
* ##### [一种用于网络钓鱼攻击的生成式人工智能恶意软件](/post/id/300410)

  2024-09-25 14:16:34
* ##### [苹果加入美国政府对人工智能安全的自愿承诺](/post/id/298565)

  2024-07-31 11:23:56
* ##### [Vanta筹集1.5亿美元，加速其AI产品创新](/post/id/298358)

  2024-07-25 15:02:41

### 热门推荐

文章目录

![](https://p0.qhimg.com/t11098f6bcd5614af4bf21ef9b5.png)

安全KER

* [关于我们](/about)
* [联系我们](/note/contact)
* [用户协议](/note/protocol)
* [隐私协议](/note/privacy)

商务合作

* [合作内容](/note/business)
* [联系方式](/note/contact)
* [友情链接](/link)

内容需知

* [投稿须知](https://www.anquanke.com/contribute/tips)
* [转载须知](/note/repost)
* 官网QQ群：568681302

合作单位

* [![安全KER](https://p0.ssl.qhimg.com/t01592a959354157bc0.png)](http://www.cert.org.cn/)
* [![安全KER](https://p0.ssl.qhimg.com/t014f76fcea94035e47.png)](http://www.cnnvd.org.cn/)

Copyright © 北京奇虎科技有限公司 三六零数字安全科技集团有限公司 安全KER All Rights Reserved [京ICP备08010314号-66](https://beian.miit.gov.cn/)[![](https://icon.cnzz.com/img/pic.gif)](https://www.cnzz.com/stat/website.php?web_id=1271278035 "站长统计")

微信二维码

**X**![安全KER](https://p0.ssl.qhimg.com/t0151209205b47f2270.jpg)