---
title: Bias nell’Intelligenza Artificiale: Strategie e Norme ISO per la Valutazione e il Controllo
url: https://www.ictsecuritymagazine.com/articoli/bias-nellintelligenza-artificiale-strategie-e-norme-iso-per-la-valutazione-e-il-controllo/
source: ICT Security Magazine
date: 2024-05-11
fetch_date: 2025-10-06T17:18:02.104419
---

# Bias nell’Intelligenza Artificiale: Strategie e Norme ISO per la Valutazione e il Controllo

[Salta al contenuto](#main)

[![ICT Security Magazine](https://www.ictsecuritymagazine.com/wp-content/uploads/2016/01/logo-ict-security.jpg)](https://www.ictsecuritymagazine.com/)

* [Home](https://www.ictsecuritymagazine.com/)
* [Articoli](https://www.ictsecuritymagazine.com/argomenti/articoli/)
* RubricheEspandi
  + [Cyber Security](https://www.ictsecuritymagazine.com/argomenti/cyber-security/)
  + [Cyber Crime](https://www.ictsecuritymagazine.com/argomenti/cyber-crime/)
  + [Cyber Risk](https://www.ictsecuritymagazine.com/argomenti/cyber-risk/)
  + [Cyber Law](https://www.ictsecuritymagazine.com/argomenti/cyber-law/)
  + [Digital Forensic](https://www.ictsecuritymagazine.com/argomenti/digital-forensic/)
  + [Digital ID Security](https://www.ictsecuritymagazine.com/argomenti/digital-id-security/)
  + [Business Continuity](https://www.ictsecuritymagazine.com/argomenti/business-continuity/)
  + [Digital Transformation](https://www.ictsecuritymagazine.com/argomenti/digital-transformation/)
  + [Cyber Warfare](https://www.ictsecuritymagazine.com/argomenti/cyber-warfare/)
  + [Ethical Hacking](https://www.ictsecuritymagazine.com/argomenti/ethical-hacking/)
  + [GDPR e Privacy](https://www.ictsecuritymagazine.com/argomenti/gdpr-e-privacy/)
  + [IoT Security](https://www.ictsecuritymagazine.com/argomenti/iot-security/)
  + [Industrial Cyber Security](https://www.ictsecuritymagazine.com/argomenti/industrial-cyber-security/)
  + [Blockchain e Criptovalute](https://www.ictsecuritymagazine.com/argomenti/blockchain-e-criptovalute/)
  + [Intelligenza Artificiale](https://www.ictsecuritymagazine.com/argomenti/intelligenza-artificiale/)
  + [Geopolitica e Cyberspazio](https://www.ictsecuritymagazine.com/argomenti/geopolitica-cyberspazio/)
  + [Interviste](https://www.ictsecuritymagazine.com/argomenti/interviste/)
* [Notizie](https://www.ictsecuritymagazine.com/argomenti/notizie/)
* [Pubblicazioni](https://www.ictsecuritymagazine.com/pubblicazioni/)
* [Cybersecurity Video](https://www.ictsecuritymagazine.com/argomenti/cybersecurity-video/)
* [Eventi](https://www.ictsecuritymagazine.com/eventi/)
* [Newsletter](https://www.ictsecuritymagazine.com/newsletter/)

[Linkedin](https://www.linkedin.com/company/ict-security-magazine/) [YouTube](https://www.youtube.com/%40ictsecuritymagazine1403) [RSS](https://www.ictsecuritymagazine.com/feed/)

[![ICT Security Magazine](https://www.ictsecuritymagazine.com/wp-content/uploads/2016/01/logo-ict-security.jpg)](https://www.ictsecuritymagazine.com/)

Attiva/disattiva menu

[![Forum ICT Security 2025](https://www.ictsecuritymagazine.com/wp-content/uploads/banner-header-2025.jpg)](https://www.ictsecuritymagazine.com/eventi/forumictsecurity2025)

![](https://www.ictsecuritymagazine.com/wp-content/uploads/bias-ai.jpg)

# Bias nell’Intelligenza Artificiale: Strategie e Norme ISO per la Valutazione e il Controllo

A cura di:[Stefano Gorla e Anna Capoluongo](#molongui-disabled-link)  Ore 10 Maggio 202410 Maggio 2024

I sistemi AI trovano ormai dilagante applicazione in ogni ambito della nostra vita e cultura attraverso, ad esempio, i modelli di *Machine Learning (ML)*, ma, come molte volte accade, non si hanno informazioni chiare su come il modello abbia “imparato” e prodotto un determinato *output*.

Ecco, quindi, come un sistema di gestione dedicato all’AI può costituire un importante strumento a supporto di una corretta *governance* e controllo di tali modelli.

A tal proposito, la norma ISO 42001:2023 introduce molti di questi concetti, come nel caso della clausola 9.1, che individua proprio gli indicatori dedicati, o dei controlli previsti dall’Allegato A, che riportano la necessità di avere la contezza dei risultati: i controlli della classe A.6.2, da esempio, richiedono la verifica e la validazione delle misure.

Altro punto focale, sempre oggetto di richiamo quando si ragiona in punto di sistemi intelligenti, è quello che va a toccare i concetti di analisi dei rischi e di valutazione d’impatto.

A supporto dello standard ISO/IEC 42001:2023 Sistema di Gestione dell’AI ci sono altre norme che guidano ad una corretta analisi e implementazione dei controlli, quali

* la norma ISO/IEC 42005 – Tecnologia dell’informazione — Intelligenza artificiale (AI) Valutazione d’impatto dei sistemi IA, e
* la ISO/IEC 23894, Information technology — Artificial intelligence — Risk Management.

Con riferimento, specificamente, ai modelli di ML e alla loro verifica, possono venire in aiuto alcune norme dedicate, comprese quelle sulla qualità dei dati, come ad esempio:

* ISO/IEC 4213 Information technology — Artificial intelligence — Assessment of machine learning classification performance,
* ISO/IEC 6254 Information technology — Artificial intelligence — Objectives and approaches for explainability of ML models and AI systems,
* ISO/IEC 23053 Framework for Artificial Intelligence (AI) Systems Using Machine Learning (ML), e
* ISO/IEC 5259 1-5 Data quality for analytics and machine learning (ML) ISO/IEC 5339.

Dal momento che, come si è accennato ed è ormai noto, una delle problematiche intrinseche più rilevanti dei sistemi algoritmici è – a tutt’oggi – costituita dalla loro opacità e scarsa comprensibilità, è evidente come sia sempre più necessario affidarsi a specifiche metodologie al fine di meglio comprendere la correttezza del modello in uso.

Ancora di più se si pensa ad un ulteriore aspetto di complessità dell’AI, ossia quello che coinvolge la distorsione algoritmica o *bias*, intesa come forma di distorsione cognitiva causata dal pregiudizio in grado di influenzare ideologie, opinioni e comportamenti. Il *bias* è, per semplificare, un errore nel processo di apprendimento che deriva da assunzioni errate.

Con il precipuo scopo di indagare tale specifico aspetto è nata la ISO 24027:2021, che descrive metodologie e meccanismi per scoprire e trattare i *bias* nei sistemi di intelligenza artificiale, che vengono descritti, nelle definizioni, come:

* “*bias*”, ossia una differenza sistematica nel trattamento[[1]](#_ftn1) di determinati oggetti, persone o gruppi rispetto ad altri;
* “*bias cognitivo umano*”[[2]](#_ftn2), che si verifica quando gli esseri umani elaborano e interpretano le informazioni;
* “*bias di conferma*”, quel tipo di *bias* cognitivo umano che favorisce le previsioni dei sistemi di intelligenza artificiale che confermano credenze o ipotesi preesistenti.

Nel documento si analizzano varie fonti di distorsioni indesiderate nei sistemi di AI, ricondotte a 3 categorie principali (distorsioni cognitive umane; distorsioni dei dati; distorsioni introdotte da decisioni ingegneristiche), così come il trattamento delle stesse durante i singoli stadi del ciclo di vita del sistema intelligente, a partire dalla raccolta dei dati, per passare alla progettazione, allo sviluppo, alle fasi di test e. arrivare al monitoraggio e alla validazione continui.

Sebbene si tenda ad attribuire al concetto di distorsione sempre un’accezione negativa, la norma in oggetto apre spiegando che, in realtà, gli effetti dei *bias* possono essere positivi, neutri o negativi, come si è cercato di sintetizzare nella tabella che segue:

|  |  |  |
| --- | --- | --- |
| Effetto positivo | L’introduzione di errori/bias può servire a raggiungere un risultato equo. | Ad esempio, l’introduzione di una distorsione nella fase decisionale di un processo di selezione di personale con date caratteristiche al fine di compensare “tare” nei data set dovute alla sottorappresentazione consolidata nel tempo di tali professionalità. |
| Effetto neutro | La distorsione porta il sistema intelligente a classificare erroneamente un dato elemento, ma senza impatti particolari. | Ad esempio, una vettura a guida autonoma riconosce come ostacolo un cassonetto, ma lo classifica erroneamente come idrante. |
| Effetto negativo | Il bias porta con sé conseguenze indesiderate (etici o non ricadenti su profili etici) | Ad esempio, può limitare le opportunità delle persone interessate (distorsion...