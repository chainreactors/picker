---
title: Truffa deepfake da 25 milioni: come riconoscere i video falsi e proteggere la tua azienda
url: https://www.ictsecuritymagazine.com/notizie/truffa-deepfake/
source: ICT Security Magazine
date: 2025-09-19
fetch_date: 2025-10-02T20:23:31.480623
---

# Truffa deepfake da 25 milioni: come riconoscere i video falsi e proteggere la tua azienda

[Salta al contenuto](#main)

[![ICT Security Magazine](https://www.ictsecuritymagazine.com/wp-content/uploads/2016/01/logo-ict-security.jpg)](https://www.ictsecuritymagazine.com/)

* [Home](https://www.ictsecuritymagazine.com/)
* [Articoli](https://www.ictsecuritymagazine.com/argomenti/articoli/)
* RubricheEspandi
  + [Cyber Security](https://www.ictsecuritymagazine.com/argomenti/cyber-security/)
  + [Cyber Crime](https://www.ictsecuritymagazine.com/argomenti/cyber-crime/)
  + [Cyber Risk](https://www.ictsecuritymagazine.com/argomenti/cyber-risk/)
  + [Cyber Law](https://www.ictsecuritymagazine.com/argomenti/cyber-law/)
  + [Digital Forensic](https://www.ictsecuritymagazine.com/argomenti/digital-forensic/)
  + [Digital ID Security](https://www.ictsecuritymagazine.com/argomenti/digital-id-security/)
  + [Business Continuity](https://www.ictsecuritymagazine.com/argomenti/business-continuity/)
  + [Digital Transformation](https://www.ictsecuritymagazine.com/argomenti/digital-transformation/)
  + [Cyber Warfare](https://www.ictsecuritymagazine.com/argomenti/cyber-warfare/)
  + [Ethical Hacking](https://www.ictsecuritymagazine.com/argomenti/ethical-hacking/)
  + [GDPR e Privacy](https://www.ictsecuritymagazine.com/argomenti/gdpr-e-privacy/)
  + [IoT Security](https://www.ictsecuritymagazine.com/argomenti/iot-security/)
  + [Industrial Cyber Security](https://www.ictsecuritymagazine.com/argomenti/industrial-cyber-security/)
  + [Blockchain e Criptovalute](https://www.ictsecuritymagazine.com/argomenti/blockchain-e-criptovalute/)
  + [Intelligenza Artificiale](https://www.ictsecuritymagazine.com/argomenti/intelligenza-artificiale/)
  + [Geopolitica Digitale](https://www.ictsecuritymagazine.com/argomenti/geopolitica-digitale/)
  + [Interviste](https://www.ictsecuritymagazine.com/argomenti/interviste/)
* [Notizie](https://www.ictsecuritymagazine.com/argomenti/notizie/)
* [Pubblicazioni](https://www.ictsecuritymagazine.com/pubblicazioni/)
* [Cybersecurity Video](https://www.ictsecuritymagazine.com/argomenti/cybersecurity-video/)
* [Eventi](https://www.ictsecuritymagazine.com/eventi/)
* [Newsletter](https://www.ictsecuritymagazine.com/newsletter/)

[Linkedin](https://www.linkedin.com/company/ict-security-magazine/) [YouTube](https://www.youtube.com/%40ictsecuritymagazine1403) [RSS](https://www.ictsecuritymagazine.com/feed/)

[![ICT Security Magazine](https://www.ictsecuritymagazine.com/wp-content/uploads/2016/01/logo-ict-security.jpg)](https://www.ictsecuritymagazine.com/)

Attiva/disattiva menu

[![Forum ICT Security 2025](https://www.ictsecuritymagazine.com/wp-content/uploads/banner-header-2025.jpg)](https://www.ictsecuritymagazine.com/eventi/forumictsecurity2025)

![Illustrazione drammatica di una videoconferenza aziendale in cui i partecipanti, in realtà deepfake, mostrano volti che si deformano e glitch digitali, simbolo di una truffa deepfake multimilionaria connessa a Hong Kong.](https://www.ictsecuritymagazine.com/wp-content/uploads/truffe-deepfake.jpeg)

# Truffa deepfake da 25 milioni: come riconoscere i video falsi e proteggere la tua azienda

A cura di:[Redazione](#molongui-disabled-link)  Ore 18 Settembre 202516 Settembre 2025

La truffa deepfake che ha colpito Arup a Hong Kong non è solo un caso di cronaca, ma il segnale di un cambiamento epocale: l’uso dell’intelligenza artificiale per inganni sofisticati che ridefiniscono fiducia, verità e sicurezza digitale. In questo articolo analizziamo l’anatomia della frode, l’impatto globale e le strategie difensive per affrontare il futuro della cybersicurezza.

## Frode con intelligenza artificiale ad Arup

Il messaggio arriva come tanti altri: urgente, riservato, apparentemente dal direttore finanziario. Ma quando il dipendente della filiale di Hong Kong di Arup si collega alla videochiamata di verifica, non immagina di trovarsi davanti a quello che diventerà il più clamoroso caso di frode con intelligenza artificiale della storia recente. Sullo schermo, volti familiari, voci riconoscibili, espressioni convincenti. Eppure, ogni singola persona presente alla riunione è un fake digitale, un’illusione creata dall’AI.

Quando la videoconferenza si conclude, 200 milioni di dollari di Hong Kong — circa 25,6 milioni di dollari americani — hanno già preso la strada dei conti correnti dei truffatori attraverso 15 transazioni separate. È gennaio 2024, e il mondo della cybersicurezza sta per cambiare per sempre.

## **L’anatomia dell’inganno perfetto**

La sofisticazione dell’attacco lascia gli esperti senza parole. Secondo la polizia di Hong Kong, i perpetratori hanno sviluppato [deepfake](https://www.ictsecuritymagazine.com/articoli/deepfake-storia-ed-evoluzione/) generati dall’intelligenza artificiale utilizzando file video e audio esistenti raccolti da conferenze online e riunioni aziendali virtuali. La vittima, inizialmente sospettosa del messaggio email ricevuto, abbandona ogni cautela durante la videochiamata.

Secondo la polizia di Hong Kong, il lavoratore aveva inizialmente sospettato di aver ricevuto un’email di phishing dall’ufficio britannico dell’azienda, ma ha messo da parte i suoi dubbi dopo la videochiamata perché le altre persone presenti sembravano e suonavano proprio come i colleghi che riconosceva.

L’intera operazione fraudolenta si è svolta nell’arco di una settimana, dal primo contatto alla scoperta della truffa quando l’azienda ha iniziato a indagare sulla questione. Il raggiro è stato scoperto soltanto quando il dipendente ha successivamente verificato la richiesta con la sede centrale dell’azienda nel Regno Unito.

## Truffa deepfake: l’esplosione globale del fenomeno

I numeri dipingono un quadro inquietante dell’evoluzione delle minacce digitali. Secondo i dati di iProov, gli attacchi deepfake utilizzanti tecnologia “face swap” per tentare di aggirare la verifica remota dell’identità sono aumentati del 704% nel 2023.

Parallelamente, il rapporto di Onfido evidenzia un aumento di 31 volte delle frodi deepfake, indicando un incremento del 3000% degli tentativi di deepfake tra il 2022 e il 2023. Secondo Andrew Newell, Chief Scientific Officer di iProov: “L’intelligenza artificiale generativa ha fornito un enorme impulso ai livelli di produttività degli attori delle minacce: questi strumenti sono relativamente economici, facilmente accessibili e possono essere utilizzati per creare media sintetici altamente convincenti”.

I dati di Chainabuse, piattaforma di segnalazione delle frodi di TRM Labs, mostrano che le segnalazioni di truffe abilitate dall’intelligenza artificiale generativa tra maggio 2024 e aprile 2025 sono aumentate del 456% rispetto allo stesso periodo dell’anno precedente.

## L’Impatto sistemico sulle organizzazioni

Un recente studio di TitanHQ e Osterman Research ha rilevato che l’11% delle organizzazioni intervistate ha subito un attacco abilitato da deepfake nell’ultimo anno. Sebbene questa percentuale possa apparire contenuta, gli esperti la considerano solo l’inizio di un fenomeno destinato a crescere esponenzialmente.

Rob Greig, Chief Information Officer di Arup, ha dichiarato: “Come molte altre aziende nel mondo, le nostre operazioni sono soggette ad attacchi regolari, incluse frodi su fatture, truffe di phishing, spoofing vocale WhatsApp e deepfake. Quello che abbiamo osservato è che il numero e la sofisticatezza di questi attacchi è aumentato drasticamente negli ultimi mesi”.

## La sfida della rilevazione

Una ricerca di iProov su 2.000 consumatori nel Regno Unito e negli Stati Uniti ha rivelato risultati allarmanti: solo lo 0,1% dei partecipanti è riuscito a distinguere accuratamente i contenuti reali da quelli falsi in tutti gli stimoli presentati, che includevano immagini e video.

Lo studio ha anche scoperto che i video deepfake si sono rivelati più difficili da identificare rispetto alle immagini deepfake, con i partecipanti che avevano il 36% in meno di probabilità di identificare correttamente un video sintetico rispetto a un’immagine sintetica.

Le ricerc...