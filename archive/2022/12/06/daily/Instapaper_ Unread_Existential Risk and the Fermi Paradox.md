---
title: Existential Risk and the Fermi Paradox
url: https://www.schneier.com/blog/archives/2022/12/existential-risk-and-the-fermi-paradox.html
source: Instapaper: Unread
date: 2022-12-06
fetch_date: 2025-10-04T00:36:50.785567
---

# Existential Risk and the Fermi Paradox

# [Schneier on Security](https://www.schneier.com/)

Menu

* [Blog](https://www.schneier.com)
* [Newsletter](https://www.schneier.com/crypto-gram/)
* [Books](https://www.schneier.com/books/)
* [Essays](https://www.schneier.com/essays/)
* [News](https://www.schneier.com/news/)
* [Talks](https://www.schneier.com/talks/)
* [Academic](https://www.schneier.com/academic/)
* [About Me](https://www.schneier.com/blog/about/)

### Search

*Powered by [DuckDuckGo](https://duckduckgo.com/)*

Blog

Essays

Whole site

### Subscribe

[![Atom](https://www.schneier.com/wp-content/uploads/2019/10/rss-32px.png)](https://www.schneier.com/feed/atom/)[![Facebook](https://www.schneier.com/wp-content/uploads/2019/10/facebook-32px.png)](https://www.facebook.com/bruce.schneier)[![Twitter](https://www.schneier.com/wp-content/uploads/2019/10/twitter-32px.png)](https://twitter.com/schneierblog)[![Email](https://www.schneier.com/wp-content/uploads/2019/10/email-32px.png)](https://www.schneier.com/crypto-gram)

[Home](https://www.schneier.com)[Blog](https://www.schneier.com/blog/archives/)

## Existential Risk and the Fermi Paradox

We know that complexity is the worst enemy of security, because it makes attack easier and defense harder. This becomes catastrophic as the effects of that attack become greater.

In [*A Hacker’s Mind*](https://www.schneier.com/books/a-hackers-mind/) (coming in February 2023), I write:

> Our societal systems, in general, may have grown fairer and more just over the centuries, but progress isn’t linear or equitable. The trajectory may appear to be upwards when viewed in hindsight, but from a more granular point of view there are a lot of ups and downs. It’s a “noisy” process.
>
> Technology changes the amplitude of the noise. Those near-term ups and downs are getting more severe. And while that might not affect the long-term trajectories, they drastically affect all of us living in the short term. This is how the twentieth century could—statistically—both be the most peaceful in human history and also contain the most deadly wars.
>
> Ignoring this noise was only possible when the damage wasn’t potentially fatal on a global scale; that is, if a world war didn’t have the potential to kill everybody or destroy society, or occur in places and to people that the West wasn’t especially worried about. We can’t be sure of that anymore. The risks we face today are existential in a way they never have been before. The magnifying effects of technology enable short-term damage to cause long-term planet-wide systemic damage. We’ve lived for half a century under the potential specter of nuclear war and the life-ending catastrophe that could have been. Fast global travel allowed local outbreaks to quickly become the COVID-19 pandemic, costing millions of lives and billions of dollars while increasing political and social instability. Our rapid, technologically enabled changes to the atmosphere, compounded through feedback loops and tipping points, may make Earth much less hospitable for the coming centuries. Today, individual hacking decisions can have planet-wide effects. Sociobiologist Edward O. Wilson [once described](https://www.nytimes.com/2019/12/05/opinion/digital-technology-brain.html) the fundamental problem with humanity is that “we have Paleolithic emotions, medieval institutions, and godlike technology.”

Technology could easily get to the point where the effects of a successful attack could be existential. Think biotech, nanotech, global climate change, maybe someday cyberattack—everything that people like Nick Bostrom [study](https://nickbostrom.com/existential/risks). In these areas, like everywhere else in past and present society, the technologies of attack develop faster the technologies of defending against attack. But suddenly, our inability to be proactive becomes fatal. As the noise due to technological power increases, we reach a threshold where a small group of people can irrecoverably destroy the species. The six-sigma guy can ruin it for everyone. And if they can, sooner or later they will. It’s possible that I have just explained the [Fermi paradox](https://en.wikipedia.org/wiki/Fermi_paradox).

Tags: [complexity](https://www.schneier.com/tag/complexity/), [risks](https://www.schneier.com/tag/risks/), [security analysis](https://www.schneier.com/tag/security-analysis/)

[Posted on December 2, 2022 at 3:07 PM](https://www.schneier.com/blog/archives/2022/12/existential-risk-and-the-fermi-paradox.html) •
[40 Comments](https://www.schneier.com/blog/archives/2022/12/existential-risk-and-the-fermi-paradox.html#comments)

### Comments

Jon •
[December 2, 2022 3:21 PM](https://www.schneier.com/blog/archives/2022/12/existential-risk-and-the-fermi-paradox.html/#comment-413258)

Except there’s an awful lot of boys and girls furiously beavering away to stop it being a problem. Some paid, some volunteer, who are putting their backs into making this not happen.

They get no press, those who fixed the Y2k problem – and won’t, in 2038 either, but their work is as essential as those who came before.

J.

ian •
[December 2, 2022 5:01 PM](https://www.schneier.com/blog/archives/2022/12/existential-risk-and-the-fermi-paradox.html/#comment-413261)

Yep. I think this should be obvious (Although you explain it wonderfully). We are doomed.

Clive Robinson •
[December 2, 2022 5:03 PM](https://www.schneier.com/blog/archives/2022/12/existential-risk-and-the-fermi-paradox.html/#comment-413262)

We have a saying that appears in one form or another in most cultures and it’s English version is

“There are two sides to a coin”

That is the literal sides of Obverse (heads) and Reverse (tails) but also the idea of “an upside” and “a downside” after it has been flipped and the hand of fate has intervened.

But as I point out about technology it has function but that is not inerently good or bad. That is a “good” or “upside” occures when an observer thinks the results of the technology put to use by a directing mind are in some way benificial. Likewise “bad” or “downside” when an observer sees the results as non benificial.

That is a singular event can be both good or bad, the scope or degree almost irrelevant in the observers eye.

Even “death” be it of an individual, group, race, or global population will always be seen by some as “bad” and others as “good”.

But humans are not the only creatures on this planet, which gives rise to an interesting set of issues.

Take a pathogen it has no “agency” it mearly infects hosts that come into contact with it. Yet we tend to ascribe malice or bad to it as we’ve seen with C-19.

The fact a pathogen that originates from a bat in a cave in some wilderness area becomes an existential risk to mankind, is very much down to the actions stupid or othereise of humans who do have agency, so can prevent it if they act. But more importantly unlike most crearures humans have the ability to see into the future thus assess “risk” and make plans that have choices within them.

The risk of C-19 had been “talked to death” years if not decades before it was known to exist. You can look up the science papers and healtcare contingency planning for epidemics and pandenics.

So the obvious question is,

“Why did we let it happen?”

Find the answer to that, and you will find the answer to why humanity may never get off this planet let alone out of the solar system.

Appart from a few predictable “natural events” that have always been with us as the clock ticks round thus slowly become more likely, nearly every existential threat to mankind is entirely avoidable and mostly down to human failings to start with.

Thus lets assume it is a charecter flaw, in humans, I rather suspect it is, then why has evolution not removed it from humans?

It could be that “risk taking” has an “upside” that under certain conditions out weights the “downside”.

The mere fact we have “technology” when other creatures do not, and we have become one of the few creatures that c...