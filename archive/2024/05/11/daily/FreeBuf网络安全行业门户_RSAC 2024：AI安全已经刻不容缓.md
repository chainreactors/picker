---
title: RSAC 2024：AI安全已经刻不容缓
url: https://www.freebuf.com/news/400461.html
source: FreeBuf网络安全行业门户
date: 2024-05-11
fetch_date: 2025-10-06T17:16:56.598806
---

# RSAC 2024：AI安全已经刻不容缓

[![freeBuf](/images/logoMax.png)](/)

主站

分类

云安全

AI安全

开发安全

终端安全

数据安全

Web安全

基础安全

企业安全

关基安全

移动安全

系统安全

其他安全

特色

热点

工具

漏洞

人物志

活动

安全招聘

攻防演练

政策法规

[报告](https://www.freebuf.com/report)[专辑](/column)

* ···
* [公开课](https://live.freebuf.com)
* ···
* [商城](https://shop.freebuf.com)
* ···
* 用户服务
* ···

行业服务

政 府

CNCERT
CNNVD

会员体系（甲方）
会员体系（厂商）
产品名录
企业空间

[知识大陆](https://wiki.freebuf.com/page)

搜索

![](/freebuf/img/7aa3bf7.svg) ![](/freebuf/img/181d733.svg)

创作中心

[登录](https://www.freebuf.com/oauth)[注册](https://www.freebuf.com/oauth)

官方公众号企业安全新浪微博

![](/images/gzh_code.jpg)

FreeBuf.COM网络安全行业门户，每日发布专业的安全资讯、技术剖析。

![FreeBuf+小程序](/images/xcx-code.jpg)

FreeBuf+小程序把安全装进口袋

[![](https://image.3001.net/images/20231020/1697804527_653270ef7570cc7356ba8.png)](https://wiki.freebuf.com)

RSAC 2024：AI安全已经刻不容缓

* ![]()
* 关注

* [资讯](https://www.freebuf.com/news)

RSAC 2024：AI安全已经刻不容缓

2024-05-10 10:53:11

所属地 上海

网络安全专业人员在确保人工智能工具安全方面责无旁贷，确保这些技术仅用于社会公益，这是 RSA 2024 大会发出的强烈信息。

![](https://image.3001.net/images/20240510/1715311256_663d9298bda464a66ff59.jpg!small)人工智能在现实世界中大有可为，例如可以更快、更准确地诊断健康状况。然而，随着人工智能的创新和应用步伐以前所未有的速度加快，许多人呼吁必须及早建立安全防护措施，以确保人工智能发挥其巨大潜力。

在这一过程中，必须考虑到隐私和公平等概念。

微软负责安全、合规、身份和管理的副总裁 Vasu Jakkal 强调说：”我们有责任在人工智能快速发展的时代探索创造一个安全可靠的空间。“

另外，人工智能安全中心创始人 Dan Hendrycks 表示，人工智能存在着巨大的风险，鉴于其在物理世界中日益增长的影响力和潜力，这些风险既是社会性的，也是技术性的。也就是说，人工智能的安全保护是一个更广泛的社会技术问题，而不仅仅是技术问题。

哈佛大学肯尼迪学院安全技术专家、研究员兼讲师 Bruce Schneier 指出，现在，人工智能安全和我们的安全紧密相连，因此我们必须更广泛地思考这些问题。

## 对人工智能完整性的威胁

员工正在利用 ChatGPT 等公开可用的生成式人工智能工具开展工作，Presidio 公司的 CISO Dan Lohrmann 将这种现象称为 “自带人工智能”。

Secureworks 的首席技术官 Mike Aiello 认为，这与 SASE 服务刚出现时的情况类似，当时企业中的许多员工都订阅了这些服务。现在，企业在使用人工智能方面也面临同样的情况，比如注册 ChatGPT，对于企业来说已经有点不受控制。

这种趋势给企业带来了许多安全和隐私方面的问题，比如敏感的公司数据被输入到这些模型中，可能会导致信息公开。

其他问题也威胁着人工智能工具输出结果的完整性。这些问题包括数据中毒，即通过改变模型所训练的数据无意或有意地改变模型的行为；以及提示注入攻击，即操纵人工智能模型执行非预期的操作。

这些问题有可能破坏人们对人工智能技术的信任，造成模糊、偏见和歧视等问题。反过来看，这将限制人工智能技术的应用和解决重大社会问题的潜力。

## 人工智能是一项治理问题

在 RSA 大会上发言的专家们主张，企业应像对待其他需要确保安全的应用程序一样对待人工智能工具。

谷歌安全工程副总裁 Heather Adkins 指出，从本质上讲，人工智能系统和其他应用程序一样，都有输入和输出，过去 30 年里开发的很多技术在这里也同样适用。

Jakkal 认为，确保人工智能系统安全的核心是建立一个强大的风险管理治理体系。她阐述了微软在这方面的三大支柱：

* 发现： 了解环境中使用了哪些人工智能工具，以及员工是如何使用它们的
* 保护： 降低整个系统的风险，并加以实施
* 治理： 遵守监管和行为准则政策，培训员工安全使用人工智能工具

Lohrmann 强调，企业要采取的第一步是让员工了解人工智能的使用情况，在采取行动之前，必须知道发生了什么。

Secureworks 的 Aiello 还主张，在将工作委托给人工智能模型时，员工应该保持高度参与。他解释说，公司使用工具进行数据分析，析师也要检查这些数据，并在出现模糊等问题时提供反馈。

## 结论

目前，我们还处于了解人工智能对社会真正影响的早期阶段。要发掘人工智能的巨大潜力，这些保护系统必须具备强大的安全性，否则可能面临跨组织和跨国家的限制甚至禁令。

如今，企业仍在努力应对工作场所生成式人工智能工具的激增，必须迅速制定能够安全可靠地管理这种使用的政策和工具，而网络安全行业对这一问题的处理方式很可能会对人工智能未来的角色产生重大影响。

参考来源：

> https://www.infosecurity-magazine.com/news/why-cybersecurity-professionals/

# 人工智能 # 人工智能安全

本文为 独立观点，未经授权禁止转载。
如需授权、对文章有疑问或需删除稿件，请联系 FreeBuf
客服小蜜蜂（微信：freebee1024）

被以下专辑收录，发现更多精彩内容

+ 收入我的专辑

+ 加入我的收藏

展开更多

相关推荐

![]()

关 注

* 0 文章数
* 0 关注者

文章目录

对人工智能完整性的威胁

人工智能是一项治理问题

结论

![](/images/logo_b.png)

本站由阿里云 提供计算与安全服务

### 用户服务

* [有奖投稿](https://www.freebuf.com/write)
* [提交漏洞](https://www.vulbox.com/bounties/detail-72)
* [参与众测](https://www.vulbox.com/projects/list)
* [商城](https://shop.freebuf.com)

### 企业服务

* [安全咨询](https://company.freebuf.com)
* [产业全景图](https://www.freebuf.com/news/307349.html)
* [企业SRC](https://www.vulbox.com/service/src)
* [安全众测](https://www.vulbox.com/)

### 合作信息

* [斗象官网](https://www.tophant.com/)
* [广告投放](https://www.freebuf.com/articles/444331.html)
* [联系我们](https://www.freebuf.com/articles/444332.html)

### 关于我们

* [关于我们](https://www.freebuf.com/news/others/864.html)
* 微信公众号
* [新浪微博](http://weibo.com/freebuf)

### 战略伙伴

* [![](https://image.3001.net/images/20191017/1571306518_5da83c1686dd9.png)](http://www.aliyun.com/?freebuf)

### FreeBuf知识大陆

![](https://image.3001.net/images/20250703/1751535036_68664dbcae34ac40bb9e7.png)

扫码把安全装进口袋

* [斗象科技](https://www.tophant.com/)
* [FreeBuf](https://www.freebuf.com)
* [漏洞盒子](https://www.vulbox.com/)
* [斗象智能安全](https://ai.tophant.com/)
* [免责条款](https://www.freebuf.com/dis)
* [协议条款](https://my.freebuf.com/AgreeProtocol/duty)

Copyright © 2025 WWW.FREEBUF.COM All Rights Reserved
[沪ICP备2024099014号](https://beian.miit.gov.cn/#/Integrated/index) | [沪公安网备
![](https://image.3001.net/images/20200106/1578291342_5e12d08ec2379.png)](http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=31011502009321)