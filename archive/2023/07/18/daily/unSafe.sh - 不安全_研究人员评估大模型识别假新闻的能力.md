---
title: 研究人员评估大模型识别假新闻的能力
url: https://buaq.net/go-172275.html
source: unSafe.sh - 不安全
date: 2023-07-18
fetch_date: 2025-10-04T11:52:37.522396
---

# 研究人员评估大模型识别假新闻的能力

* [unSafe.sh - 不安全](https://unsafe.sh)
* [我的收藏](/user/collects)
* [今日热榜](/?hot=true)
* [公众号文章](/?gzh=true)
* [导航](/nav/index)
* [Github CVE](/cve)
* [Github Tools](/tools)
* [编码/解码](/encode)
* [文件传输](/share/index)
* [Twitter Bot](https://twitter.com/buaqbot)
* [Telegram Bot](https://t.me/aqinfo)
* [Search](/search/search)

[Rss](/rss.xml)

[ ]
黑夜模式

![]()

研究人员评估大模型识别假新闻的能力

威斯康星大学斯托特分校的研究员 Kevin Matthe Caramancion 评估了流行大语言模型识别假新闻的能力。他评估了四个大模型，包括 Open AI 的 Chat GPT-3.
*2023-7-17 23:1:40
Author: [www.solidot.org(查看原文)](/jump-172275.htm)
阅读量:7
收藏*

---

威斯康星大学斯托特分校的研究员 Kevin Matthe Caramancion 评估了流行大语言模型识别假新闻的能力。他评估了四个大模型，包括 Open AI 的 Chat GPT-3.0 和 Chat GPT-4.0，Google 的 Bard/LaMDA 以及微软的 Bing AI。他向这些模式输入了已经过人类事实核查的新闻。结果显示，OpenAI 的 GPT-4.0 表现最出色。但所有四种大模型都落后于人类事实核查人员，突出了人类认知的不可替代价值。研究报告发表在预印本平台 arxiv 上。

https://techxplore.com/news/2023-07-ability-chatgpt-large-language-fake.html

文章来源: https://www.solidot.org/story?sid=75539
 如有侵权请联系:admin#unsafe.sh

© [unSafe.sh - 不安全](https://unsafe.sh) Powered By [PaperCache](https://github.com/code-scan/PaperCache)

* admin#unsafe.sh
* [安全马克](https://aq.mk)
* [星际黑客](https://xj.hk)
* [T00ls](https://t00ls.net)