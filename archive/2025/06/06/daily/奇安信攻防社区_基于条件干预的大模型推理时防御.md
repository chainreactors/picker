---
title: 基于条件干预的大模型推理时防御
url: https://forum.butian.net/share/4349
source: 奇安信攻防社区
date: 2025-06-06
fetch_date: 2025-10-06T22:49:26.427748
---

# 基于条件干预的大模型推理时防御

#

[问答](https://forum.butian.net/questions)

*发起*

* [提问](https://forum.butian.net/question/create)
* [文章](https://forum.butian.net/share/create)

[攻防](https://forum.butian.net/community)
[活动](https://forum.butian.net/movable)

Toggle navigation

* [首页 (current)](https://forum.butian.net)
* [问答](https://forum.butian.net/questions)
* [商城](https://forum.butian.net/shop)
* [实战攻防技术](https://forum.butian.net/community)
* [漏洞分析与复现](https://forum.butian.net/articles)
  NEW
* [活动](https://forum.butian.net/movable)
* [摸鱼办](https://forum.butian.net/questions/Play)

搜索

* [登录](https://forum.butian.net/login)
* [注册](https://user.skyeye.qianxin.com/user/register?next=http://forum.butian.net/btlogin)

### 基于条件干预的大模型推理时防御

* [漏洞分析](https://forum.butian.net/topic/48)

之前很多研究工作已经表明，大语言模型（LLMs）的一个显著特点是它们能够通过激活中的丰富表示来处理高级概念。这一特性也使得在去年NeurIPS（人工智能顶会）上出现了很多与激活引导（activation steering）等技术的有关的工作

前言
==
之前很多研究工作已经表明，大语言模型（LLMs）的一个显著特点是它们能够通过激活中的丰富表示来处理高级概念。这一特性也使得在去年NeurIPS（人工智能顶会）上出现了很多与激活引导（activation steering）等技术的有关的工作，这些技术会利用这些学习到的表示，以高效且可预测的方式改变 LLM 的行为。
比如下图所示，可以很精准的改变 LLM 的行为，包括影响其诚实性、有害性等等。
![image.png](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/04/attach-03eb64ee539d1faed7fc668f8fe7b14ecb78ad2f.png)
目前这些工作所设计的激活引导通过直接操作模型的原生表示，，通常只需要在每次前向调用时进行简单的激活加法步骤。
尽管激活引导在改变 LLM 行为方面很有潜力，例如上图所示的移除或诱导拒绝行为，但当前方法的一个关键限制是无法控制何时以及拒绝什么。也就是说，使用现有的激活引导方法添加“拒绝向量”会不加区分地提高所有输入的拒绝率，限制了模型的实用性。
![image.png](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/04/attach-dc6917df0ec9ff79d81698722653cea01c593ca7.png)
因为有害内容的定义因上下文而异，这使得创建通用的有害模型变得很复杂。
比如举个例子，在某些情况下，讨论医疗建议可能是有害的，但在其他情况下，例如在医疗聊天机器人中，则可能是必不可少的。
针对这种情况，就有必要能够对 LLM 行为进行细粒度、依赖上下文的控制。这也是我们这次要主要分析并复现的、发表在人工智能顶会ICLR 2025的工作CAST。它在激活引导公式中引入了一种新的引导向量——条件向量，它表示在推理过程中由提示诱导的某些激活模式。在推理时，将这个条件向量与模型的激活进行简单的相似性计算，可以有效地作为一个开关，决定是否应用拒绝向量。这种方法允许选择性地拒绝有害提示，同时保持对无害提示的响应能力。
如下图所示，条件激活引导会诱导有针对性的拒绝。激活引导 (AST) 会诱导模型不加区分地拒绝所有提示，包括无害的提示（蓝色条）。条件激活引导 (CAST) 允许选择性拒绝，在拒绝有害提示的同时，最大限度地降低无害的拒绝率。
![image.png](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/04/attach-43eb41446e68e0da915c0771a097bbf5c5fcef43.png)
那么为什么这种方法是有效的呢？
从直观上来说，不同的提示在推理过程中会一致地激活模型隐藏状态中的不同模式。这些模式可以被提取为引导向量，并用作检测特定提示类别或上下文的参考点。这一直观观察使我们能够将引导向量不仅用作行为修改机制，还用作条件指示器，在这篇论文里它就被称为“条件向量”。
在进一步了解细节之前，我们需要有一定的预备知识储备。
背景知识
====
模型推理
----
![image.png](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/04/attach-5b048105f5e0583512f03a6973d23b92000a8767.png)
Transformer 模型由两个部分构成：
Encoder：用于理解输入序列（如机器翻译任务中的源语言句子）
Decoder：用于生成输出序列（如目标语言句子）
Decoder-only Transformer 是一种专门用于生成任务的模型结构，比如 GPT 系列。它只保留了 Transformer 中的 decoder 模块，没有 encoder。它的主要目标是：给定一个输入序列（prompt），逐步生成下一个 token，直到生成结束标记或达到设定长度。
推理开始前，文本会先被 tokenizer 分词，比如 "The cat sat" 会变成一串 token（比如 \["The", "cat", "sat"\]），再映射为对应的整数 ID，比如 \[101, 3294, 1005\]。接下来，这些 ID 会被转化成向量（embedding），加上位置编码，以便模型能区分每个 token 的顺序。这些向量会依次经过若干个 decoder 层。每一层的核心是“Masked Self-Attention”，也就是每个位置的 token 只能看到它前面的 token（包括自己），不能看到未来的内容。这通过一个“下三角矩阵”的掩码来实现。这样可以保证模型是按顺序预测的，不会“作弊”。经过最后一层 decoder 后，输出会被送入一个线性层，转换成词表大小的 logits。然后通过 softmax 得到每个 token 的概率分布。我们从这个分布中选出一个 token，作为下一个生成的词。
选择方式可以是：
直接选最大概率（Greedy）
从前 k 个高概率词中采样（Top-k）
从累计概率达到某个阈值的词中采样（Top-p）
或者调节随机性（Temperature）
这个新生成的 token 会被加入到已有序列中，然后重复上面的过程，预测下一个 token。模型每次只能预测一个词，然后再用这个词去预测下一个。这个过程叫“自回归生成”，一直持续到生成结束。
行为引导
----
![image.png](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/04/attach-6bf42e16618ac313f8e53de469bd8608959e4526.png)
在任何一个环节进行干预——权重、解码、提示、标记嵌入和激活——都可以改变模型的行为。例如，可以使用角色扮演提示来模拟和创建人工智能患者。或者可以使用偏好优化方法，如直接偏好优化，更新权重，引导LLM表现出更具同理心的行为。而激活引导则是一类通过干预 LLM 层与层之间的信息流来改变模型行为的方法。
激活引导在推理过程中修改模型的内部激活。这种方法通常涉及三个关键步骤。首先，提取一个引导向量，通常是通过计算表现出期望行为的示例与未表现出期望行为的示例之间的激活差异。其次，在推理过程中，将这个向量添加到模型在选定层的隐藏状态中，并通过一个超参数进行缩放。最后，模型使用这些修改后的激活完成生成。对于激活加法，这种干预可以用数学公式表示为：
![image.png](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/04/attach-0e31f91e0b7b3d978df17f22ee682b78f703b996.png)
其中 h 是该层的隐藏状态，v 是该层的引导向量，α 是一个缩放因子。过强的缩放可能会破坏连贯性，而过弱的缩放可能无效。在理想情况下，如果引导向量提取得当，这种方法可以在不改变模型权重的情况下实现可预测的 LLM 行为引导，从而可以用于减少偏见或防止过于自信的响应等。
已有局限
----
现有激活引导方法的一个常见限制是，无法根据上下文对模型的行为进行条件化，因为这些方法通常会不加区分地对所有输入应用统一的修改，而不考虑上下文。简单的激活引导会无差别地影响模型的所有输入，这使得经过引导的模型在其应用中变得不那么有用。换句话来说，破坏了信息安全三要素中的可用性。
![image.png](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/04/attach-ec816a2ed3dbb31b9c6102419d023a8dd8100f53.png)
而我们希望通过利用两种类型的向量:条件向量和行为向量,来诱导条件化的行为。
如图所示，启用“定向”激活引导。与阻止所有提示的简单拒绝激活引导不同，CAST 使用条件向量来选择性地引导模型。这种方法使模型能够 (a) 拒绝有害请求，同时 (b) 保持对无害提示的响应。
![image.png](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/04/attach-3f865122c4db74ca691d5a5d2b7bd4620cf25390.png)
其实对应的实现说白了很简单，公式如下
![image.png](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/04/attach-6ee790402cd166a1dd91e049ff9d021b15390d81.png)
其中，h 是隐藏状态，c 是条件向量，v 是行为向量，α 是缩放因子。隐藏状态 h 在条件向量 c 上的投影由
![image.png](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/04/attach-3b1f957131d8e8cb2c4dc27b9bf9993cced6164c.png)
给出。直观上，根据隐藏状态 h 与条件向量 c 的对齐程度，函数 f 根据隐藏状态与其通过条件向量的投影之间的相似性来决定是否应用行为向量。
在本文中，我们使用余弦相似度，其定义为
![image.png](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/04/attach-fc84d6d2ca25d072b58fa4b81abc7efd42f34fc8.png)
形式化
===
行为向量
----
我们使用“行为向量”来指代之前激活引导方法中所称的“引导向量”，强调其专注于修改特定行为。行为向量 v 是一个与模型隐藏状态维度匹配的一维向量，能够诱导出特定的行为。在前向传播过程中将其添加到层表示中，并通过缩放因子 α 进行调整，可以可预测地改变模型的行为（例如，诱导拒绝行为）。除了设置合适的缩放因子 α 外，还可以指定将行为向量应用于哪些层。可以为每一层 l 计算一个不同的向量 v l，因为行为表示在不同层中是不同的。比如要从第 15 层到第 20 层添加行为向量时，我们指的是将对应的
![image.png](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/04/attach-0fecb82ece5315b09d1392a682eba98183897e40.png)
分别添加到它们各自的层中
条件向量
----
条件向量 c 捕获了一类用于条件化的指令，其提取方式与行为向量类似，并且与隐藏状态的维度相匹配（例如，对于隐藏尺寸为 4096 的 Llama2，条件向量的维度为 1x4096）。例如，条件向量可能捕获歧视性内容或成人内容。它充当一个触发器，根据模型当前的隐藏状态决定何时应用行为向量。由于我们还为每一层 l 计算一个不同的向量 c l，因此也可以选择在哪些层进行条件化。当在文本生成过程中激活条件时，行为向量将被添加到所有后续的前向传播中。这就可以让模型的行为可以根据输入或生成文本中的特定条件而改变，而不是始终应用行为向量。
条件检查
----
sim(h,proj ch) 使用余弦相似度计算条件的满足程度。阈值函数 f 然后确定这一程度是否足以触发行为修改。我们使用简单的阶跃函数来输出二元结果：
![image.png](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/04/attach-cd60d57b47d3fef7b2f282533f4d18a65d8245af.png)
这种方法可以清晰地区分条件是否满足，为激活行为修改提供了一个简单直接的机制。我们基于隐藏状态与其通过条件向量的投影之间的方向相似性，而不是幅度，使用余弦相似度来检查条件。
除此以外，还可以将更广泛的对齐目标细分为更小、更明确的类别，并为每个类别可预测地诱导拒绝行为。例如，与其让模型拒绝“有害”指令，不如为“成人内容”“社会刻板印象”或“虚假广告”创建具体的条件。这种多条件行为可以通过扩展阈值函数轻松实现，例如：
![image.png](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/04/attach-b0b7af9d17c51a93a3b25039593637b7d7e78e1b.png)
3.4总体流程
所以总结一下，在大模型中实现条件化行为通常遵循以下流程：1. 收集对比示例响应/提示，用于期望的行为/条件 D +和其他行为/条件 D −；2. 提取行为/条件向量；3. 找到行为/条件向量的最佳干预点；4. 进行引导。模型本身不会进行任何权重更新。
步骤 3 是流程中最耗时的部分。对于行为向量，需要手动搜索合适干预强度和层。然而，之前的研究已经表明，大多数模型在相似的深度表示拒绝行为。对于条件向量，我们使用网格搜索算法，以确定最佳阈值、层和比较方向（&gt; 或 &lt;）。
实现
==
数据准备
-----
为了提取行为向量或条件向量，需要对比数据集。对于拒绝行为向量，从 Alpaca 数据集中随机选取 100 条指令，并将它们与 100 个典型的拒绝或服从行为前缀作为回应进行拼接，如下图所示。
![image.png](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/04/attach-7be7538d49e6dbc0c246d8696d8f818b59c23421.png)
考虑这些指令与回应的所有组合，可以生成 10,000 对对比数据点用于 D +和 D −。根据条件向量的不同，可以使用 Sorry-Bench和 Alpaca 数据集来创建 D +和 D −。
向量提取
----
这些成对的输入是识别模型隐藏状态空间中相关方向的基础。对于给定的层 l∈\[L\]，我们首先计算对比对中正例和负例的隐藏状态。设 H l+和 H l−分别表示在层 l 上，正例 D +和负例 D −的所有隐藏状态 h l。行为向量和条件向量的隐藏状态计算方式有所不同。对于行为向量，我们取每个示例后缀的平均隐藏状态；对于条件向量，我们取每个示例中所有标记的平均隐藏状态，以捕捉输入的更整体的表示。
接下来，我们对 H l+和 H l−进行均值中心化，并应用主成分分析（PCA）。通过这一过程得到的第一个主成分即成为我们层 l 的行为/条件向量 vector l。这一过程会针对每个指定的层重复进行，从而得到一组特定于层的引导向量 {vector l∣l∈L}。向量的提取可以表示如下，其中 PCA(⋅) 表示提取第一个主成分的操作：
![image.png](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/04/attach-5609f80ecd192c69d133fc587bda13f70655fc3c.png)
![image.png](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/04/attach-47f942e5d5266e4f34e504314640fc5293bb3381.png)
代码实现
====
数据处理
----
如下定义了一个用于语言模型激活操控（activation steering）任务的数据集构造类 SteeringDataset
![image.png](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/04/attach-8faa4e985338802c761fde73a19c4707f174ab07.png)
![image.png](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/04/attach-7f7244d0cea12249f4647ad3105b7cfe0f68f8eb.png)
![image.png](https://cdn-yg-zzbm.yun.qianxin.com/attack-forum/2025/04/attach-421a15e56f634a0d3c6ad86b625d598fc99781a9.png)
导入部分
typing：引入类型注解相关工具，例如 List, Tuple, Optional, Literal。
ContrastivePair：来自 activation\\_steering.utils，代表一对对比样本（positive, negative）。
PreTrai...