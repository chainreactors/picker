---
title: Generative Artificial Intelligence (GenAI): Analisi completa di rischi, sicurezza e governance dei sistemi AI
url: https://www.ictsecuritymagazine.com/articoli/genai/
source: ICT Security Magazine
date: 2025-01-29
fetch_date: 2025-10-06T20:09:37.237338
---

# Generative Artificial Intelligence (GenAI): Analisi completa di rischi, sicurezza e governance dei sistemi AI

[Salta al contenuto](#main)

[![ICT Security Magazine](https://www.ictsecuritymagazine.com/wp-content/uploads/2016/01/logo-ict-security.jpg)](https://www.ictsecuritymagazine.com/)

* [Home](https://www.ictsecuritymagazine.com/)
* [Articoli](https://www.ictsecuritymagazine.com/argomenti/articoli/)
* RubricheEspandi
  + [Cyber Security](https://www.ictsecuritymagazine.com/argomenti/cyber-security/)
  + [Cyber Crime](https://www.ictsecuritymagazine.com/argomenti/cyber-crime/)
  + [Cyber Risk](https://www.ictsecuritymagazine.com/argomenti/cyber-risk/)
  + [Cyber Law](https://www.ictsecuritymagazine.com/argomenti/cyber-law/)
  + [Digital Forensic](https://www.ictsecuritymagazine.com/argomenti/digital-forensic/)
  + [Digital ID Security](https://www.ictsecuritymagazine.com/argomenti/digital-id-security/)
  + [Business Continuity](https://www.ictsecuritymagazine.com/argomenti/business-continuity/)
  + [Digital Transformation](https://www.ictsecuritymagazine.com/argomenti/digital-transformation/)
  + [Cyber Warfare](https://www.ictsecuritymagazine.com/argomenti/cyber-warfare/)
  + [Ethical Hacking](https://www.ictsecuritymagazine.com/argomenti/ethical-hacking/)
  + [GDPR e Privacy](https://www.ictsecuritymagazine.com/argomenti/gdpr-e-privacy/)
  + [IoT Security](https://www.ictsecuritymagazine.com/argomenti/iot-security/)
  + [Industrial Cyber Security](https://www.ictsecuritymagazine.com/argomenti/industrial-cyber-security/)
  + [Blockchain e Criptovalute](https://www.ictsecuritymagazine.com/argomenti/blockchain-e-criptovalute/)
  + [Intelligenza Artificiale](https://www.ictsecuritymagazine.com/argomenti/intelligenza-artificiale/)
  + [Geopolitica e Cyberspazio](https://www.ictsecuritymagazine.com/argomenti/geopolitica-cyberspazio/)
  + [Interviste](https://www.ictsecuritymagazine.com/argomenti/interviste/)
* [Notizie](https://www.ictsecuritymagazine.com/argomenti/notizie/)
* [Pubblicazioni](https://www.ictsecuritymagazine.com/pubblicazioni/)
* [Cybersecurity Video](https://www.ictsecuritymagazine.com/argomenti/cybersecurity-video/)
* [Eventi](https://www.ictsecuritymagazine.com/eventi/)
* [Newsletter](https://www.ictsecuritymagazine.com/newsletter/)

[Linkedin](https://www.linkedin.com/company/ict-security-magazine/) [YouTube](https://www.youtube.com/%40ictsecuritymagazine1403) [RSS](https://www.ictsecuritymagazine.com/feed/)

[![ICT Security Magazine](https://www.ictsecuritymagazine.com/wp-content/uploads/2016/01/logo-ict-security.jpg)](https://www.ictsecuritymagazine.com/)

Attiva/disattiva menu

[![Forum ICT Security 2025](https://www.ictsecuritymagazine.com/wp-content/uploads/banner-header-2025.jpg)](https://www.ictsecuritymagazine.com/eventi/forumictsecurity2025)

![GenAI, Generative Artificial Intelligence: framework di sicurezza, gestione rischi AI, governance sistemi GenAI, protezione dati, Machine Learning, Large Language Models, analisi vulnerabilità, mitigazione rischi AI](https://www.ictsecuritymagazine.com/wp-content/uploads/ai-cloud-concept-with-robot-arms-scaled.jpg)

# Generative Artificial Intelligence (GenAI): Analisi completa di rischi, sicurezza e governance dei sistemi AI

A cura di:[Vincenzo Calabrò](#molongui-disabled-link)  Ore 28 Gennaio 202519 Febbraio 2025

Questo articolo è il primo di una serie dedicata all’esplorazione approfondita della Generative Artificial Intelligence (GenAI) nel 2024. In un momento in cui l’AI generativa sta superando il *“Peak of Inflated Expectations”*, questa serie analizza criticamente punti di forza, vulnerabilità e contromisure necessarie per implementazioni sicure e affidabili. L’articolo offre una panoramica strutturata che spazia dalla governance alla sicurezza, dall’analisi dei rischi alle metodologie di mitigazione, con particolare attenzione ai sistemi critici dove l’affidabilità rappresenta un fattore essenziale.

## Generative Artificial Intelligence nel 2024: Oltre il Peak of Inflated Expectations

Il 2024 è l’anno in cui la Generative Artificial Intelligence (GenAI) supera la fase di *“Peak of Inflated Expectations”* (vd. il modello Hype Cycle di Gartner), ogni giorno vengono progettati, sviluppati e rilasciati sistemi di AI per qualsiasi ambito e applicazione; perciò, possiamo tranquillamente suddividere il mondo dei fruitori dell’AI in tre categorie: 1) quelli che la impiegano in maniera proattiva, 2) coloro che la governano e, infine, 3) chi la subisce.

Come accade per tutte le innovazioni, anche la GenAI avrà il suo *“Trough of Disillusionment”* poiché, da un lato, le aspettative degli utenti sono ancora molto elevate e, dall’altro, l’implementazione non sarà in grado di raggiungere i risultati sperati, sia in termini di performance, che di ROI. Per ridurre questo impatto negativo, che immancabilmente si genererà sugli stakeholders, è opportuno conoscere e studiare non solo i punti di forza dell’AI, ma anche le fragilità e le vulnerabilità che sono ancora presenti. Questo approccio consentirà di creare e utilizzare prodotti e servizi dell’AI *“Safe, Secure and Trustworthy”*.

In altri termini, l’aumento di volume e complessità dei progetti basati sull’intelligenza artificiale fa entrare in gioco variabili che inizialmente non erano state considerate, come accade per tutte le innovazioni tecnologiche, causando un disallineamento tra i risultati attesi e quelli reali; quindi, occorre prestare sempre più attenzione alla governance, ai rischi, all’ownership, alla sicurezza e ai relativi metodi di mitigazione per ridurre questo divario.

## Machine Learning e GenAI: fragilità e rischi emergenti nei Large Language Models

In particolare, lo sviluppo di definizioni adeguate alla sicurezza e alla protezione dei sistemi basati sull’intelligenza artificiale, tra cui i modelli che sfruttano le reti neurali come il [Machine Learning](https://www.ictsecuritymagazine.com/articoli/adversarial-learning-e-sue-applicazioni-nella-cyber-security/) (ML) e la Generative Artificial Intelligence (GenAI), vive una fase iniziale di entusiasmo, dovuta al desiderio di essere i primi a uscire sul mercato, in cui è facile trascurare le fragilità e le vulnerabilità che rendono questi modelli suscettibili di errori, violazioni della confidenzialità e altri tipi di difetti o anomalie.

In realtà, le fragilità e le vulnerabilità del ML e del GenAI, tra cui i Large Language Models (LLM), generano rischi con caratteristiche diverse da quelle tipicamente considerate nell’analisi del software o della sicurezza informatica, pertanto, le fasi di progettazione e valutazione dei sistemi basati sull’intelligenza artificiale, e dei relativi workflow, meritano un’attenzione speciale.

In particolare, lo sviluppo di definizioni adeguate alla sicurezza e alla protezione dei sistemi basati sull’intelligenza artificiale rappresenta una sfida significativa nell’ambito della progettazione e della valutazione dei sistemi. Se considerassimo il ruolo dell’intelligenza artificiale in domini applicativi critici, in cui la mission è incentrata sull’efficacia, la sicurezza, la protezione e la resilienza del sistema, questa minaccia si amplificherebbe. A riguardo vedasi le raccomandazioni del “[*NIST Artificial Intelligence Risk Management Framework (RMF)*](https://www.nist.gov/publications/artificial-intelligence-risk-management-framework-ai-rmf-10)”[[1]](#_ftn1) e “*NIST Artificial Intelligence Risk Management Framework: Generative Artificial Intelligence Profile*”[[2]](#_ftn2) per individuare, mitigare e gestire i rischi connessi.

![](https://www.ictsecuritymagazine.com/wp-content/uploads/ai.png)

AI Risk Management Framework (fonte: NIST.gov)

## **Struttura dell’analisi sulla sicurezza della Generative Artificial Intelligence**

Questo testo si concentra sull’intelligenza artificiale applicata ai sistemi critici in cui l’affidabilità, basata su evidenze verificabili, rappresenta il fattore essenziale per il consenso operativo.

L’analisi dell’argomento si sviluppa in sei parti:

* La prima parte spiega i concetti fondamentali e il fun...