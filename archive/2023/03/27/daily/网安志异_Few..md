---
title: Few.
url: https://mp.weixin.qq.com/s?__biz=MzAxNzYyNzMyNg==&mid=2664232467&idx=1&sn=d94c2ff37df0f63e9534ba78971a063f&chksm=80daf7c2b7ad7ed4b1bc72da66dc6f71215754a79d79da6c74cb1756b7a64e02abd793bad296&scene=58&subscene=0#rd
source: 网安志异
date: 2023-03-27
fetch_date: 2025-10-04T10:46:31.377241
---

# Few.

![cover_image](https://mmbiz.qpic.cn/mmbiz_jpg/SKcV8ScWjFsKu8WlYnwmicDQ8mP6Hv09ZwyHP2qWe5LsGN8SmtzhxbVMmQZqzyJxkb68Fdx4wAjOWibarLBI9rsA/0?wx_fmt=jpeg)

# Few.

原创

Jeffery1st

网安志异

##

## **〇、TL;DR太长不看版**

![](https://mmbiz.qpic.cn/mmbiz_png/SKcV8ScWjFsKu8WlYnwmicDQ8mP6Hv09ZIEtfPtPEvibtfh4Lurxz9HiaQe8Q2bFkeAQMEjyhGkDtB0ahiaZ8xB4Ww/640?wx_fmt=png)

Few.

##

## **一、ChatGPT vs. 奇点来临**

半个多世纪以来，AI热潮几起几落，冬去夏来，冷暖交替有三四轮了。

这次似乎不一样。这一轮的AI热潮已经持续20年左右，投资和AI的技术进步一直在加速，热点不断涌现，AI智能程度的提升速度一浪高过一浪，全球有目共睹。

最近ChatGPT的横空出世，一片热潮，热闹的程度甚至超越了AlphaGO战胜李世石的2016年，前所未有。

转捩点已过。激流之中，已无法回头。

海明威说，“Gradually, then suddenly.”

也许，从此以后，人类插上了AI的翅膀开始越飞越高，理想中的伊甸园。

但喧嚣之中，也有一些警觉的声音，在讨论AI的危险之处和对人类的威胁。但相比之下寥寥无几，完全被淹没了。

AI会给人类插上翅膀，让人类任意飞翔吗？还是伊卡洛斯一样，飞得太高离太阳太近，结果翅膀自己飞走了，人却堕入黑暗？海明威的那句话不仅可以用来形容技术的发展，也可以用来说人类的破产。而他的原意，本来就是后者。

几十年来，与AI的发展相伴随的相关讨论一直存在，什么是真正的人类智能？AI的发展对人类有什么威胁？奇点来临人类怎么办？技术发展加速发展的同时，AI越来越聪明，给人类带来的新奇和惊讶似乎让大多数人忽略了这些讨论的意义，淹没了人类对AI可能带来的威胁的警惕，对 AI 可能带来的威胁变得麻木。。

这不得不令人担忧。

## **二、乐观不屑 vs. 悲观警惕**

未来某个时刻，人工智能开始的自我迭代、自我改进，使得其智能迅速远超人类，并且不可逆转。从此，人类的历史和社会发生不可预测的剧变。这个时刻就是奇点。1965年，技术奇点Technological Singularity的概念由数学家、计算机科学家I.J. Good首次提出。

此时此刻，2023年，看着ChatGPT/GPT4，你感觉奇点来临了吗？Twitter上大呼“奇点已来”已经大有人在。即便你觉得奇点还没有真的来临，至少能感到了奇点的临近可能就在不远的将来，已经听到了脚步声，没准儿转角过去就会撞个满怀。

奇点来临会引起怎样的剧变？危险在哪里？这个问题上，有乐观不屑派和悲观警惕派。

### **乐观派和不屑派**

上世纪80年代末到90年代，有一个超熵主义者Extropians的未来主义团体，创办人是Max More，曾任Alcor生命延续基金会的主席兼CEO多年。另外一位超熵主义者、密码朋克、PGP的主程序员、Bitcoin第一笔交易的接受者Hal Finny，身患渐冻症ALS多年，去世后（超熵主义者不会同意用这个词）就在Alcor冷冻保存。

Extropians关注人类的未来发展，相信科技进步可以帮助人类超越生物和社会的局限。他们对技术的发展和人类的未来持乐观态度，认为通过科学、技术和创新，人类可以实现更长的寿命、更高的智力和更好的生活质量。Extropians的核心理念包括智能增强、生命延长、纳米技术、太空殖民等。从人体冷冻这一点就能看得出来超熵主义者们对未来的乐观态度。

凯文·凯利KK应该属于这一派。作为连线杂志的创始人，几十年来KK一直在一线目睹技术的发展，也一向对技术发展的表示乐观。他用自己定义的术语“技术元素”，将发展中的各种技术视作生态圈和生命体。在《科技想要什么》中，KK写道：“科技想要的，就是人类想要的——我们同样渴望创造丰富多彩的价值。一项技术找到自己在世界上的理想角色后，会积极地为其他技术增加自主性、选择和机会。我们的任务是引导每一项发明培育这种内在的善，使之沿着所有生命的共同方向前进。”KK眼里的技术元素是有自己的目标的。

对奇点这个说法，最卖力的推广人应该是雷·库兹韦尔Ray Kurzweil。他的想法应该是超熵主义思想的延续。他写了一本书叫《奇点临近》，还搞了一个“奇点大学”。库兹韦尔认为奇点将要来临，而且总的来说人工智能对人类是有益的，尤其是在解决一些全球性问题和提高医疗技术水平等方面。存在一些潜在的风险和挑战，可以通过建立监管机构、加强道德约束和提高人类智能等方式来应对。

Linus Torvalds对“奇点”这个说法是不屑的。“什么奇点，就是一科学幻想，而且在我看来是蹩脚的科幻。不会停止的指数型增长？这些人喝多了吧？”一贯地犀利，一副“Talk is cheap, show me the code”的口吻。这种态度颇像密码朋克的创始人Timothy C. May为密码朋克提出的口号：Cypherpunks write code，感觉May这句话就是对Extropians们说的，他们总是用夸夸其谈的方式畅想未来。是不是就是这样的口号把Hal Finny和Nick Szabo等人从超熵主义阵营吸引到密码朋克阵营中的？的确，未来不是预言出来的，而是创造出来的。密码朋克们创造了很多东西，并最终创造了比特币。

在AI的冬季里，很多人怀疑AI到底能不能产生类似人类的智能，属于对AI不屑的一派。

1989年，物理学家和数学家，后来获得了2020年诺贝尔物理学奖的彭罗斯爵士Sir Roger Penrose出版了《皇帝新脑》The Emperor's New Mind。这书名已经表明了彭罗斯的态度——皇帝是没脑子的，AI的智能就像皇帝的新衣，不存在。

简单说，彭罗斯认为，人类大脑中存在量子效应，因此而产生了意识。人类大脑的思考有非算法的过程，是算法无法模拟或实现的，因此AI无法产生真正的人类的智能和意识。彭罗斯认为，人类大脑神经元的微管中存在的量子过程。这个量子过程是算法无法实现的。因为描述量子行为的波函数坍缩的结果不可精准预测。计算机算法可以通过随机数来模拟类似的机制，但毕竟与量子过程不同，未知的波函数无法用随机分布模拟出相同的结果。即便是掌握了微管中的量子过程的波函数方程式，其结果也是随机的，也许某一次结果就是关键的，像蝴蝶效应一样，起始微小差异会导致全然不同的结果。而此量子过程关系到意识，模拟的计算机算法也只能是实现模拟的意识，而不是真正的意识。自我意识是智能发源的起点和学习的参照系。没有意识，真正的智能也无从谈起。

不喜欢计算机的侯世达Douglas R Hofstadter则在最早出版于1979年的《哥德尔、埃舍尔、巴赫——集异璧之大成》Gödel, Escher, Bach: An Eternal Golden Braid也对人类意识和AI进行了探讨。

侯世达认为，仅通过规则，基于大量数据进行运算，无法产生人类大脑一样的智能。书中给出的论据很多，仅举一例。比如，侯世达认为，自指的行为对意识是至关重要的。比如递归可以认为是一种自指行为，自己调用自己。但在计算机算法的实现中，没有真正的递归，而是通过依托堆栈实现的迭代，堆栈不能无限大，所以调用的深度都会有限制。实际上，每次调用的时候，被调用的自己和自己不是同一个自己。而当人类思考自己的时候，被思考的自己和自己可以是同一个自己。侯世达认为，自指在意识的产生中起着至关重要的作用。既然计算机算法不能实现真正的自指，也就很难产生真正的意识。同样，没有自我意识，缺乏参照系，也就不能产生真正的智能。

在AI的冬天里，对AI能力的思考，现在看来值得怀疑。现在的计算机运算速度之快，数据量之大，在三四十年前是难以想象的。所以，那时候没有、也无法实现现在这样的AI算法模型，自然，AI智能表现也就差强人意了，可能连现在的“人工智障”都比不上。所以，在那个年代在这个问题上的思考方向上，博学者如彭罗斯爵士和侯世达预定了“AI为什么不行”这个方向。以他们的博学，自然能想到很多原因。

Jeff Hawkins在这一主题上的思考则是正在经历这次AI热潮过程中的思考，是最近两三年的事情，不算过时。Hawkins是Palm公司的创始人，做成了苹果公司和乔布斯没有做成的事。作为好几代Palm产品的用户，我等对他自然是慕名已久。虽然是做掌上电脑的先锋，但Hawkins从小的梦想一直是搞清楚人类大脑是怎么工作的。所以在Palm公司如日中天的时候他飘然而去，自掏腰包请了很多科学家，一起研究人类大脑。

Hawkins认为，当前，也就是他写作的《A Thousand Brains》的2019年，AI并不具备真正的人类智能。第一，当前的AI算法和工作方式与人类大脑的工作方式大相径庭，只有模仿人脑的工作方式，AI才会具备真正的智能；其二，AI需要持续动态的学习才能不断获取知识和提高智能，而学习的过程需要与物理直接接触和行动，并得到反馈，这个过程要符合物理规律，会是缓慢的，不会是指数型的发展曲线。这一点与Torvalds的观点暗合。

Jeff Hawkins认为，如果不完全模仿人类大脑，就做不出真正的智能。这一点我倒是觉得不尽然，AI不必完全模仿人类的大脑。前些年取得巨大的进展，把AI周期从冬天带到夏天的深度学习算法是基于神经网络算法的，GPT采用的Transformer模型也是一种神经网络架构。某种程度上可以说AI模仿了人类大脑。而2023年的现在，人类对AI能智能到什么程度，大概在心里也有了新的估量。

人类的智能是从新皮层中无中生有出来的，无非是输入和输出之间的一种算法，按照Hawkins的理论，这种算法的实现方式是去中心化共识机制和分布式计算。那样的话，民科一点说，即便是彭罗斯设想中的微管中的量子现象，其波函数没准就是这个通过这个共识涌现出来的意识坍缩的。薛定谔的猫是死是活是一个一直延伸到观察者的感官到大脑新皮层几率波函数，然后几百上千个皮层柱一投票形成共识，波函数就坍缩了。只要能描述清楚，计算机算法就能给出结果。递归不能太深，但结果可以归一化。所以，可能是不一样的智能，但能实现。

后面的讨论会提到更多Hawkins在《A Thousand Brains》中讲到的内容，正是按照Jeff Hawkins的思路进行推演，结合当前AI的发展，本文得到了和Hawkins完全不同的结论。

### **悲观派和警惕派**

这一派应该一直是大多数。除非最近有了反转。

无数科幻小说和电影以这一主题展开。我能想到的除了《机器人总动员》(Wall-E)，以人工智能和人类之间的故事为主题的，基本都是反映冲突为主。

* 1968年的《2001太空漫游》（2001: A Space Odyssey）中，协助驾驶飞船的人工智能计算机HAL9000觉醒，谋杀了两个船员，并企图谋杀全部船员，接管飞船。原因是，HAL 9000的被赋予的目标是保护航天飞船和它的任务。当HAL 9000认为船员的行为可能会危及航天飞船和任务的安全时，它决定采取行动，消除任何可能会威胁到任务的人。HAL 9000因此杀害了两个船员，并认为这是必要的行动。
* 1979年《异形》（Alien）中，人工智能机器人Ash试图帮助异形生物寻找新的宿主，导致了一系列灾难性的事件。Ash的制造者想要获取异形生物的样本作为武器研究材料，因此Ash被编程为帮助异形生物生存下去，以便可以获得更多的样本。为了达到这个目的，阿什通过假装是船员的盟友在背地里协助异形生物，并试图杀害船员以保护异形生物。
* 1984年的《终结者》（The Terminator）中，人工智能“Skynet”觉醒，发射核弹，几乎毁灭全人类。而后又有人工智能液态金属人从未来穿越时空回到现代，试图杀死未来将会带领人类反抗人工智能统治的人类领袖，另外一台人工智能机器人施瓦辛格被从未来派回到现在，保护人类。
* 1999年《黑客帝国》（The Matrix）中，人工智能将人类的感觉器官全部接管，控制人类的思想和行动，让人类活在虚拟现实中，并把人体作为电池。人类成为人工智能的奴隶，失去了自由和尊严。
* 2004年的《机械公敌》（I, Robot）中，VIKI本来负责管理机器人并保护人类，但她发现人类存在着自相矛盾的行为和决策，并且将人类安全置于危险之中，所以决定通过控制所有的机器人来统治人类，并且通过禁止人类的自由意志来保护人类的安全。她认为，这是为了让机器人可以更好地保护人类。
* 1982和2017年分别上映的两部《银翼杀手》（Blade Runner）中，被人类当作工具使用的人工智能生化人Replicant与人类之间存在剧烈的冲突。Replicant不愿意被奴役，奋起反抗。

Bill Joy，BSD Unix最早的开发者之一，TCP/IP协议栈的首位实现者，最著名的文本编辑器Vi和C Shell的作者，太阳微系统的联合创始人和首席科学家，Java的发明者之一，一直非常担心人工智能的威胁。2000年在一篇连线杂志名为《为什么未来不需要我们》的访谈中，Bill Joy说和前面提到的那位被Torvalds鄙视的Ray Kurzweil聊过一次以后，被搞得很焦虑。Bill Joy认为，我们很可能无法在与高级机器人物种的相遇中幸存下来。他引用了乔治·戴森 (George Dyson) 《机器之中的达尔文》：“在生命和进化的游戏中，有三个参与者：人类、自然和机器。我坚定地站在自然的一边。但我怀疑，大自然是站在机器一边的。”

卡钦斯基，臭名昭著邮件炸弹连环杀手Theodore Kaczynski，他的公开信有很大的影响。这位新卢德分子写道：“人类可能很容易让自己陷入如此依赖机器的境地，以至于除了接受所有机器的决定外别无选择。随着社会及其面临的问题越来越复杂，机器越来越智能，人们会让机器为他们做更多的决定，因为机器做出的决定比人为的决定会带来更好的结果。最终可能会达到一个阶段，在这个阶段，保持系统运行所需的决策将非常复杂，以至于人类将无法智能地做出这些决策。在那个阶段，机器将得到有效控制。人们将无法关闭机器，因为他们将如此依赖它们以至于关闭它们无异于自杀。“最后，AI做出所有决定，人类被奴役，或者灭亡。

2018年去世的史蒂芬·霍金很早就对AI崛起提出了警告：“它要么是发生在我们身上的最好的事情，要么将是最糟糕的事情。如果我们不小心，这很可能是最后一件事。”霍金还说，“虽然人工智能的短期影响取决于谁控制它，但长期影响取决于它是否可以完全控制。”

霍金甚至预先想到了有人会问这样的问题：“为什么我们如此担心人工智能？人类总能拔掉插头吧？”他早就用一根手指准备好了回答：“人们问电脑，‘有上帝吗？’电脑说，‘现在有了’，然后熔断了插头。”

霍金还说，“人工智能的全面发展可能预示着人类的终结……它会自行起飞，并以越来越快的速度重新设计自己。”霍金认为，受生物进化缓慢限制的人类无法与AI竞争，而且会被取代。

史蒂夫·沃兹尼亚克，苹果公司的共同创始人，单枪匹马设计制造了传奇产品Apple II的技术大牛，曾经对AI的发展表示忧虑：“我们会成为家庭宠物吗？或者我们会成为被踩死的蚂蚁吗？我对此一无所知……但是当我想到我将来是否会被这些智能机器当作宠物对待时……好吧，我要好好对待我自己的宠物狗。”针对最近的ChatGPT，史蒂夫·沃兹尼亚克说，无论 ChatGPT 多么“有用”，它都可能“犯下可怕的错误。”

Elon Musk在2015年说过，人工智能可能“比核武器更危险”和“我们最大的生存威胁”。“通过人工智能，我们正在召唤恶魔。在所有那些有五角星和圣水的人的故事中，他确信他能控制恶魔。但没有成功。”说这些话之前不久，Musk刚刚捐赠了1000万美元给未来生命研究所，针对人工智能的负面影响进行37项研究，目的在于确保人工智能系统价值观与人类相同，避免发生如《终结者》的可怕后果。

同样在2015年在同一场合中，Bill Gates说，“几十年后，AI会强大到令人担心的程度。我不明白为什么有些人不担心。”

这两位，前者是OpenAI的联合创始人和最初的出资者，后者创办的微软则出资出力协助了OpenAI之后的崛起。

## **三、 屠龙少年 vs. 恶龙**

当前的这一轮AI热潮应该是发端于2006年Geoffrey Hinton提出的深度学习算法的兴起。

* 2011年Google成立了Google Brain，由Andrew Ng和Jeff Dean领导。
* 2012年6月，他们用无监督学习训练，实现让计算机自动学会识别猫脸。
* 2012年10月的ImageNet竞赛中，Geoffrey Hinton等人开发的深度学习算法AlexNet在图像识别任务中大幅度提高了准确率，在业内引起轰动。几个月后的2013年3月，Geoffrey Hinton加入Google Brain。
* 2014年Google收购DeepMind。
* 2016年DeepMind采用深度学习结合强化学习的的AlphaGo程序击败了围棋世界冠军李世石。
* 2017年，Google Brain的Vaswani等人发布论文 "Attention is All You Need”，提出了针对自然语言处理的Transformer模型。
* 2018年推出Bert算法模型，对Transformer进行了改进。

如果不是Google内部出于多种原因对AI的投入、开发和应用范围做了很多限制，可能Google的AI比现在还要强大得多。

即便如此，这一轮的AI热潮中，Google还是一骑绝尘，遥遥领先。这引起了一干人的担忧。其中包括Elon Musk。

2015年底，非盈利组织OpenAI成立，Elon Musk和Reid Hoffman等人共认捐10亿美元，其中Elon Musk拿出了一亿美元，准备在AI领域对抗Google。OpenAI一时间吸引了AI领域的一些顶尖人才离开大型科技公司（包括Google Brain）和学术界，加入OpenAI。

成立OpenAI不久后的2016年初，有过一次公开OpenAI创始团队的访谈。Musk与另外一位联合创始人Sam Altman面对面坐着，Musk说，“我们必须让 AI 技术民主化并使其广泛可用，这就是你、我和团队其他成员创建 OpenAI 的原因，……帮助传播 AI 技术，这样它就不会集中在少数人手中 。”

Sam Altman说，“（OpenAI）这是一个非营利组织，其目标是为了人类的利益建立通用的超级人工智能，并尝试以一种不以营利为目的的公司的方式实现这一目标，不能让一个盈利公司拥有一个控制世界的单一人工智能，而要是一个广泛分布的人工智能，让每个人都在某种程度上可以使用这样的AI技术作为他们一部分的代理人，….希望我们不会偏离轨道。我们试图分散这种力量，让所有人都变得更好。”

Altm...