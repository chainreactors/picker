---
title: AI and the 2024 US Elections
url: https://www.schneier.com/blog/archives/2024/09/ai-and-the-2024-us-elections.html
source: Schneier on Security
date: 2024-10-01
fetch_date: 2025-10-06T18:54:41.073487
---

# AI and the 2024 US Elections

# [Schneier on Security](https://www.schneier.com/)

Menu

* [Blog](https://www.schneier.com)
* [Newsletter](https://www.schneier.com/crypto-gram/)
* [Books](https://www.schneier.com/books/)
* [Essays](https://www.schneier.com/essays/)
* [News](https://www.schneier.com/news/)
* [Talks](https://www.schneier.com/talks/)
* [Academic](https://www.schneier.com/academic/)
* [About Me](https://www.schneier.com/blog/about/)

### Search

*Powered by [DuckDuckGo](https://duckduckgo.com/)*

Blog

Essays

Whole site

### Subscribe

[![Atom](https://www.schneier.com/wp-content/uploads/2019/10/rss-32px.png)](https://www.schneier.com/feed/atom/)[![Facebook](https://www.schneier.com/wp-content/uploads/2019/10/facebook-32px.png)](https://www.facebook.com/bruce.schneier)[![Twitter](https://www.schneier.com/wp-content/uploads/2019/10/twitter-32px.png)](https://twitter.com/schneierblog)[![Email](https://www.schneier.com/wp-content/uploads/2019/10/email-32px.png)](https://www.schneier.com/crypto-gram)

[Home](https://www.schneier.com)[Blog](https://www.schneier.com/blog/archives/)

## AI and the 2024 US Elections

For years now, AI has undermined the public’s ability to trust what it sees, hears, and reads. The [Republican National Committee](https://www.theatlantic.com/technology/archive/2023/04/ai-generated-political-ads-election-candidate-voter-interaction-transparency/673893/) released a provocative ad offering an “AI-generated look into the country’s possible future if Joe Biden is re-elected,” showing apocalyptic, machine-made images of ruined cityscapes and chaos at the border. [Fake robocalls](https://www.nbcnews.com/politics/2024-election/biden-robocall-new-hampshire-strategist-rcna139760) purporting to be from Biden urged New Hampshire residents not to vote in the 2024 primary election. This summer, the Department of Justice cracked down on a [Russian bot farm](https://www.npr.org/2024/07/09/g-s1-9010/russia-bot-farm-ai-disinformation) that was using AI to impersonate Americans on social media, and OpenAI disrupted an [Iranian group](https://www.npr.org/2024/08/17/nx-s1-5079397/openai-chatgpt-iranian-group-us-election) using ChatGPT to generate fake social-media comments.

It’s not altogether clear what damage AI itself may cause, though the reasons for concern are obvious—the technology makes it easier for bad actors to construct [highly persuasive](https://www.theatlantic.com/technology/archive/2024/08/chatbots-false-memories/679660/) and misleading content. With that risk in mind, there has been some movement toward constraining the use of AI, yet progress has been painstakingly slow in the area where it may count most: the 2024 election.

Two years ago, the Biden administration issued a blueprint for an [AI Bill of Rights aiming to address](https://www.whitehouse.gov/ostp/ai-bill-of-rights/) “unsafe or ineffective systems,” “algorithmic discrimination,” and “abusive data practices,” among other things. Then, last year, Biden built on that document when he issued his [executive order on AI](https://www.whitehouse.gov/briefing-room/statements-releases/2023/10/30/fact-sheet-president-biden-issues-executive-order-on-safe-secure-and-trustworthy-artificial-intelligence/). Also in 2023, Senate Majority Leader Chuck Schumer held an [AI summit](https://www.cnn.com/2023/09/13/tech/schumer-tech-companies-ai-regulations/index.html) in Washington that included the centibillionaires Bill Gates, Mark Zuckerberg, and Elon Musk. Several weeks later, the United Kingdom hosted an international AI Safety Summit that led to the serious-sounding “[Bletchley Declaration](https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023),” which urged international cooperation on AI regulation. The risks of AI fakery in elections have not sneaked up on anybody.

Yet none of this has resulted in changes that would resolve the use of AI in U.S. political campaigns. Even worse, the two federal agencies with a chance to do something about it have punted the ball, very likely until after the election.

On July 25, the Federal Communications Commission issued a [proposal](https://www.fcc.gov/document/fcc-proposes-disclosure-rules-use-ai-political-ads) that would require political advertisements on TV and radio to disclose if they used AI. (The FCC has no jurisdiction over streaming, social media, or web ads.) That seems like a step forward, but there are two big problems. First, the proposed rules, even if enacted, [are unlikely to](https://apnews.com/article/artificial-intelligence-political-ads-fec-fcc-18080082b2a81b3aad4897b4c4b5c84b) take effect before [early voting](https://www.usnews.com/news/elections/articles/2024-08-16/which-states-start-early-voting-first-in-the-2024-presidential-election) starts in this year’s election. Second, the proposal immediately devolved into a partisan slugfest. A Republican FCC commissioner [alleged](https://docs.fcc.gov/public/attachments/FCC-24-74A3.pdf) that the Democratic National Committee was orchestrating the rule change because Democrats are falling behind the GOP in using AI in elections. Plus, he argued, this was the Federal Election Commission’s job to do.

Yet last month, the FEC [announced](https://www.fec.gov/resources/cms-content/documents/mtgdoc-24-29-A.pdf) that it won’t even try making new rules against using AI to impersonate candidates in campaign ads through deepfaked audio or video. The FEC also said that it lacks the statutory authority to make rules about misrepresentations using deepfaked audio or video. And it lamented that it lacks the technical expertise to do so, anyway. Then, last week, the FEC [compromised](https://www.fec.gov/resources/cms-content/documents/mtgdoc-24-39-A.pdf), announcing that it intends to enforce its existing rules against fraudulent misrepresentation regardless of what technology it is conducted with. Advocates for stronger rules on AI in campaign ads, such as [Public Citizen](https://www.citizen.org/news/fec-inaction-betrays-its-mission-leaves-elections-vulnerable/), did not find this nearly sufficient, characterizing it as a “wait-and-see approach” to handling “electoral chaos.”

Perhaps this is to be expected: The freedom of speech guaranteed by the First Amendment generally permits [lying](https://www.npr.org/2022/03/17/1087047638/the-truth-in-political-advertising-youre-allowed-to-lie) in political ads. But the American public has signaled that it would like some rules governing AI’s use in campaigns. In 2023, more than half of Americans polled [responded](https://apnorc.org/wp-content/uploads/2023/11/Harris-AI-Poll-Topline-FINAL-10.30.pdf) that the federal government should outlaw all uses of AI-generated content in political ads. Going further, in 2024, about half of [surveyed](https://imaginingthedigitalfuture.org/wp-content/uploads/2024/05/Politics-and-AI-topline-5.3.24.pdf) Americans said they thought that political candidates who intentionally manipulated audio, images, or video should be prevented from holding office or removed if they had won an election. Only 4 percent thought there should be no penalty at all.

The underlying problem is that Congress has not clearly given any agency the responsibility to keep political advertisements grounded in reality, whether in response to AI or old-fashioned forms of disinformation. The Federal Trade Commission has jurisdiction over truth in advertising, but political ads are largely [exempt](https://www.brookings.edu/articles/regulating-fact-from-fiction-disinformation-in-political-advertising/)—again, part of our First Amendment tradition. The FEC’s remit is campaign finance, but the Supreme Court has progressively [stripped](https://www.ncsl.org/elections-and-campaigns/campaign-finance-and-the-supreme-court) its authorities. Even where it could act, the commission is often stymied by political [deadlock](https://campaignlegal.org/...