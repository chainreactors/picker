---
title: Artificial Intelligence in National Security: Acquisition and Integration
url: https://www.sei.cmu.edu/blog/artificial-intelligence-in-national-security-acquisition-and-integration/
source: SEI Blog
date: 2025-08-06
fetch_date: 2025-10-07T00:49:17.578349
---

# Artificial Intelligence in National Security: Acquisition and Integration

icon-carat-right

menu

search

cmu-wordmark

[Carnegie Mellon University](https://www.cmu.edu)

[Software Engineering Institute](https://www.sei.cmu.edu)

[SEI Blog](/blog/)

1. [Home](/)
2. [Publications](/publications/)
3. [Blog](/blog/)
4. Artificial Intelligence in National Security: Acquisition and Integration

[ ]

### Cite This Post

×

* [AMS](#amsTab)
* [APA](#apaTab)
* [Chicago](#chicagoTab)
* [IEEE](#ieeeTab)
* [BibTeX](#bibTextTab)

AMS Citation

Rishel, P., Smith, C., O'Hearn, B., and Creel, R., 2025: Artificial Intelligence in National Security: Acquisition and Integration. Carnegie Mellon University, Software Engineering Institute's Insights (blog), Accessed October 3, 2025, https://doi.org/10.58012/gfnb-pr02.

Copy

APA Citation

Rishel, P., Smith, C., O'Hearn, B., & Creel, R. (2025, August 5). Artificial Intelligence in National Security: Acquisition and Integration. Retrieved October 3, 2025, from https://doi.org/10.58012/gfnb-pr02.

Copy

Chicago Citation

Rishel, Paige, Carol Smith, Brigid O'Hearn, and Rita Creel. "Artificial Intelligence in National Security: Acquisition and Integration." *Carnegie Mellon University, Software Engineering Institute's Insights (blog)*. Carnegie Mellon's Software Engineering Institute, August 5, 2025. https://doi.org/10.58012/gfnb-pr02.

Copy

IEEE Citation

P. Rishel, C. Smith, B. O'Hearn, and R. Creel, "Artificial Intelligence in National Security: Acquisition and Integration," *Carnegie Mellon University, Software Engineering Institute's Insights (blog)*. Carnegie Mellon's Software Engineering Institute, 5-Aug-2025 [Online]. Available: https://doi.org/10.58012/gfnb-pr02. [Accessed: 3-Oct-2025].

Copy

BibTeX Code

@misc{rishel\_2025,
author={Rishel, Paige and Smith, Carol and O'Hearn, Brigid and Creel, Rita},
title={Artificial Intelligence in National Security: Acquisition and Integration},
month={{Aug},
year={{2025},
howpublished={Carnegie Mellon University, Software Engineering Institute's Insights (blog)},
url={https://doi.org/10.58012/gfnb-pr02},
note={Accessed: 2025-Oct-3}
}

Copy

# Artificial Intelligence in National Security: Acquisition and Integration

![Paige Rishel](/media/images/prishel.max-180x180.format-webp.webp)
![Headshot of Carol Smith.](/media/images/Smith_Carol_069_230111.max-180x180.format-webp.webp)

###### [Paige Rishel](/authors/paige-rishel), [Carol J. Smith](/authors/carol-smith-2), [Brigid O'Hearn](/authors/brigid-ohearn), and [Rita C. Creel](/authors/rita-creel)

###### August 5, 2025

##### PUBLISHED IN

[Artificial Intelligence Engineering](/blog/topics/artificial-intelligence-engineering/)

##### CITE

<https://doi.org/10.58012/gfnb-pr02>

Get Citation

##### SHARE

As defense and national security organizations consider integrating AI into their operations, many acquisition teams are unsure of where to start. In June, the SEI hosted an AI Acquisition workshop. Invited participants from government, academia, and industry described both the promise and the confusion surrounding AI acquisition, including how to choose the right tools to meet their mission needs. This blog post details practitioner insights from the workshop, including challenges in differentiating AI systems, guidance on when to use AI, and matching AI tools to mission needs.

This workshop was part of the SEI’s year-long National AI Engineering Study to identify progress and challenges in the discipline of AI Engineering. As the U.S. Department of Defense moves to gain advantage from AI systems, AI Engineering is an essential discipline for enabling the acquisition, development, deployment, and maintenance of those systems. The National AI Engineering Study will collect and clarify the highest-impact approaches to AI Engineering to date and will prioritize the most pressing challenges for the near future. In this spirit, the workshop highlighted what acquirers are learning and the challenges they still face.

Some workshop participants shared that they are already realizing benefits from AI, using it to generate code and to triage documents, enabling team members to focus their time and effort in ways that were not previously possible. However, participants reported common challenges that ranged from general to specific, for example, determining which AI tools can support their mission, how to test those tools, and how to identify the provenance of AI-generated information. These challenges show that AI acquisition is not just about picking a tool that looks advanced. It is about choosing tools that meet real operational needs, are trustworthy, and fit within existing systems and workflows.

## **Challenges of AI in Defense and Government**

AI adoption in national security has special challenges that do not appear in commercial settings. For example:

* The risk is higher and the consequences of failure are more serious. A mistake in a commercial chatbot might cause confusion. A mistake in an intelligence summary could lead to a mission failure.
* AI tools must integrate with legacy systems, which may not support modern software.
* Most data used in defense is sensitive or classified. It should be safeguarded at all phases of the AI lifecycle.

## **Assessing AI as a Solution**

AI should not be viewed as a universal solution for every situation. Workshop leaders and attendees shared the following guidelines for evaluating whether and how to use AI:

* **Start with a mission need.** Choose a solution that addresses the requirement or will improve a specific problem. It may not be an AI-enabled solution.
* **Ask how the model works.** Avoid systems that function as black boxes. Vendors need to describe the training process of the model, the data it uses, and how it makes decisions.
* **Run a pilot before scaling.** Start with a small-scale experiment in a real mission setting before issuing a contract, when possible. Use this pilot to refine requirements and contract language, evaluate performance, and manage risk.
* **Choose modular systems.** Instead of seeking versatile solutions, identify tools that can be added or removed easily. This improves the chances of system effectiveness and prevents being tied to one vendor.
* **Build in human oversight.** AI systems are dynamic by nature and, along with testing and evaluation efforts, they need continuous monitoring—particularly in higher risk, sensitive, or classified environments.
* **Look for trustworthy systems.** AI systems are not reliable in the same way traditional software is, and the people interacting with them need to be able to tell when a system is working as intended and when it is not. A trustworthy system provides an experience that matches end-users’ expectations and meets performance metrics.
* **Plan for failure.** Even high-performing models will make mistakes. AI systems should be designed to be resilient so that they detect and recover from issues.

## **Matching AI Tools to Mission Needs**

The specific mission need should drive the selection of a solution, and improvement from the status quo should determine a solution’s appropriateness. Acquisition teams should make sure that AI systems meet the needs of the operators and that the system will work in the context of their environment. For example, many commercial tools are built for cloud-based systems that assume constant internet access. In contrast, defense environments are often subject to limited connectivity and higher security requirements. Key considerations include:

* Make sure the AI system fits within the existing operating environment. Avoid assuming that infrastructure can be rebuilt from scratch.
* Evaluate the system in the target environment and circumstances before deployment.
* Verify the quality, variance, and source of training data and its applicability to the situation. Low-quality or imbalanced data will reduce model reliability.
* Set up feedback processes. Analysts and operators must be capable of identifying and reporting mistakes so that they can...