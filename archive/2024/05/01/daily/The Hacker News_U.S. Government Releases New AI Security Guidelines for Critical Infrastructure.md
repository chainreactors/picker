---
title: U.S. Government Releases New AI Security Guidelines for Critical Infrastructure
url: https://thehackernews.com/2024/04/us-government-releases-new-ai-security.html
source: The Hacker News
date: 2024-05-01
fetch_date: 2025-10-06T17:27:24.534816
---

# U.S. Government Releases New AI Security Guidelines for Critical Infrastructure

#1 Trusted Cybersecurity News Platform

Followed by 5.20+ million[**](https://twitter.com/thehackersnews)
[**](https://www.linkedin.com/company/thehackernews/)
[**](https://www.facebook.com/thehackernews)

[![The Hacker News Logo](data:image/png;base64...)](/)

**

**

[** Subscribe – Get Latest News](#email-outer)

* [** Home](/)
* [** Newsletter](#email-outer)
* [** Webinars](/p/upcoming-hacker-news-webinars.html)

* [Home](/)
* [Data Breaches](/search/label/data%20breach)
* [Cyber Attacks](/search/label/Cyber%20Attack)
* [Vulnerabilities](/search/label/Vulnerability)
* [Webinars](/p/upcoming-hacker-news-webinars.html)
* [Expert Insights](https://thehackernews.com/expert-insights/)
* [Contact](/p/submit-news.html)

**

**

**

Resources

* [Webinars](/p/upcoming-hacker-news-webinars.html)
* [Free eBooks](https://thehackernews.tradepub.com)

About Site

* [About THN](/p/about-us.html)
* [Jobs](/p/careers-technical-writer-designer-and.html)
* [Advertise with us](/p/advertising-with-hacker-news.html)

Contact/Tip Us

[**

Reach out to get featured—contact us to send your exclusive story idea, research, hacks, or ask us a question or leave a comment/feedback!](/p/submit-news.html)

Follow Us On Social Media

[**](https://www.facebook.com/thehackernews)
[**](https://twitter.com/thehackersnews)
[**](https://www.linkedin.com/company/thehackernews/)
[**](https://www.youtube.com/c/thehackernews?sub_confirmation=1)
[**](https://www.instagram.com/thehackernews/)

[** RSS Feeds](https://feeds.feedburner.com/TheHackersNews)
[** Email Alerts](#email-outer)

[![Salesforce Security Handbook](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjWa8tsMNqlevi1HGF1ALQRGIq7hROPFAbHd3R1RTEOe73T8_Q2xW_-91t2jSGjU5peiPb8QYblGp4igNW-u2Qmlxbp2BKzTVMSvyXDZJmC-BYpiiJHrcnG5drmSP97iZ9PVIf1DeEr7U-7vWpe4HXwfMjt8FGNgq5mOycOJluYr9wF7YOKrQY9MfArwgjt/s728-e100/ai-agent-security-d.png)](https://thehackernews.uk/ai-agent-security-d)

# [U.S. Government Releases New AI Security Guidelines for Critical Infrastructure](https://thehackernews.com/2024/04/us-government-releases-new-ai-security.html)

**Apr 30, 2024**Ravie LakshmananMachine Learning / National Security

[![AI Security](data:image/png;base64... "AI Security")](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjFg-I75TPQ8p3EkXgIz6jAlyowo-W2L1Rb-59BMGZDZHsSinyo-U9cK4YLirmjPLT2wMecWBcZE3q138xUxiuWPCpjaOjghCqD2kVZp0YO2S3DB3qeSH6HEpYJxqJqCQMs6mjiDtDKLwo1a4o73mOEPFJs0MxhN9KaagVK7nuORcNQ8ATTsK6kvF3QDZW_/s790-rw-e365/ai.png)

The U.S. government has unveiled new security guidelines aimed at bolstering critical infrastructure against artificial intelligence (AI)-related threats.

"These guidelines are informed by the whole-of-government effort to assess AI risks across all sixteen critical infrastructure sectors, and address threats both to and from, and involving AI systems," the Department of Homeland Security (DHS) [said](https://www.dhs.gov/news/2024/04/29/fact-sheet-dhs-facilitates-safe-and-responsible-deployment-and-use-artificial) Monday.

In addition, the agency said it's working to facilitate safe, responsible, and trustworthy use of the technology in a manner that does not infringe on individuals' privacy, civil rights, and civil liberties.

The new guidance concerns the use of AI to augment and scale attacks on critical infrastructure, adversarial manipulation of AI systems, and shortcomings in such tools that could result in unintended consequences, necessitating the need for transparency and secure by design practices to evaluate and mitigate AI risks.

[![DFIR Retainer Services](data:image/png;base64...)](https://thehackernews.uk/cloud-insight-d)

Specifically, this spans four different functions such as govern, map, measure, and manage that cover different aspects of the AI lifecycle -

* Establish an organizational culture of AI risk management
* Understand your individual AI use context and risk profile
* Develop systems to assess, analyze, and track AI risks
* Prioritize and act upon AI risks to safety and security

"Critical infrastructure owners and operators should account for their own sector-specific and context-specific use of AI when assessing AI risks and selecting appropriate mitigations," the agency [said](https://www.dhs.gov/news/2024/04/29/dhs-publishes-guidelines-and-report-secure-critical-infrastructure-and-weapons-mass).

"Critical infrastructure owners and operators should understand where these dependencies on AI vendors exist and work to share and delineate mitigation responsibilities accordingly."

The development arrives weeks after the Five Eyes (FVEY) intelligence alliance comprising Australia, Canada, New Zealand, the U.K., and the U.S. released a cybersecurity information sheet noting the careful setup and configuration required for deploying AI systems.

"The rapid adoption, deployment, and use of AI capabilities can make them highly valuable targets for malicious cyber actors," the governments [said](https://www.nsa.gov/Press-Room/Press-Releases-Statements/Press-Release-View/Article/3741371/nsa-publishes-guidance-for-strengthening-ai-system-security/).

"Actors, who have historically used data theft of sensitive information and intellectual property to advance their interests, may seek to co-opt deployed AI systems and apply them to malicious ends."

The recommended best practices include taking steps to secure the deployment environment, review the source of AI models and supply chain security, ensure a robust deployment environment architecture, harden deployment environment configurations, validate the AI system to ensure its integrity, protect model weights, enforce strict access controls, conduct external audits, and implement robust logging.

A failure to adhere to robust security measures can have severe consequences, allowing nefarious parties to stage [model inversion attacks](https://owasp.org/www-project-machine-learning-security-top-10/docs/ML03_2023-Model_Inversion_Attack) and corrupt AI models with an aim to deliberately tamper with expected behavior such that it can trigger cascading downstream impacts.

Earlier this month, the CERT Coordination Center (CERT/CC) [detailed](https://kb.cert.org/vuls/id/253266) a shortcoming in the Keras 2 neural network library that could be exploited by an attacker to trojanize a popular AI model and redistribute it, effectively poisoning the supply chain of dependent applications.

Recent research has also found AI systems to be [vulnerable](https://hiddenlayer.com/research/prompt-injection-attacks-on-llms/) to a wide range of [prompt injection attacks](https://labs.withsecure.com/publications/detecting-prompt-injection-bert-based-classifier) that induce the AI model to circumvent safety mechanisms and produce harmful outputs.

[![CIS Build Kits](data:image/png;base64...)](https://thehackernews.uk/platform-shield-d)

"Prompt injection attacks through poisoned content are a major security risk because an attacker who does this can potentially issue commands to the AI system as if they were the user," Microsoft [noted](https://www.microsoft.com/en-us/security/blog/2024/04/11/how-microsoft-discovers-and-mitigates-evolving-attacks-against-ai-guardrails/) in a report published two weeks ago.

One such technique, dubbed Crescendo, has been described as a multiturn large language model (LLM) jailbreak, which, like Anthropic's [many-shot jailbreaking](https://thehackernews.com/2024/04/ai-as-service-providers-vulnerable-to.html), tricks the model into generating malicious content by "asking carefully crafted questions or prompts that gradually lead the LLM to a desired outcome, rather than asking for the goal all at once."

LLM jailbreak prompts have become [popular among cybercriminals](https://abnormalsecurity.com/blog/2023-ai-generated-email-attacks) looking to craft effective phishing lures, even as nation-state actors have begun [weaponizing generative AI](https://thehackernews.com/2024/04/microsoft-warns-nort...