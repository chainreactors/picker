---
title: Podcast RSI - Le IA danno voce a vittime di stragi e imbarazzano le aziende, Avast spiona
url: http://attivissimo.blogspot.com/2024/03/podcast-rsi-le-ia-danno-voce-vittime-di.html
source: Il Disinformatico
date: 2024-03-02
fetch_date: 2025-10-04T12:13:33.477894
---

# Podcast RSI - Le IA danno voce a vittime di stragi e imbarazzano le aziende, Avast spiona

# [Il Disinformatico](https://attivissimo.blogspot.com/)

Un blog di Paolo Attivissimo, giornalista informatico e cacciatore di bufale

**Informativa privacy e cookie:** Questo blog include cookie di terze parti. Non miei ([dettagli](https://tinyurl.com/2p9apfu5))

[Prossimi eventi pubblici](https://attivissimo.me/disinformaticalendario/prossimi/) – [Donazioni](https://attivissimo.me/donazioni/) – [Sci-Fi Universe](https://scifiuniverse.it)

## Cerca nel blog

|  |  |
| --- | --- |
|  |  |

## 2024/03/01

### Podcast RSI - Le IA danno voce a vittime di stragi e imbarazzano le aziende, Avast spiona

[![logo del Disinformatico](https://blogger.googleusercontent.com/img/a/AVvXsEgLKyKCnDBWHOWzQyRyIaCUDkpP2fHygIFp5X6KdZBQ_3U4KET1t5s_QY8Bkpdjvp9gYs1s1KbGjT0QUAlu4eIW2PFXmu1Jy-ub_qWnBRiwPLS9uokARrkjYylWMgYeiqi-YzDI7nMCzDMWdQUHhlirE6MtOAFKpr_ocZmCL4EczL0avELuFYg)](https://blogger.googleusercontent.com/img/a/AVvXsEgLKyKCnDBWHOWzQyRyIaCUDkpP2fHygIFp5X6KdZBQ_3U4KET1t5s_QY8Bkpdjvp9gYs1s1KbGjT0QUAlu4eIW2PFXmu1Jy-ub_qWnBRiwPLS9uokARrkjYylWMgYeiqi-YzDI7nMCzDMWdQUHhlirE6MtOAFKpr_ocZmCL4EczL0avELuFYg)

È disponibile subito il podcast di oggi de
[*Il Disinformatico*](https://www.rsi.ch/ildisinformatico/)
della Radiotelevisione Svizzera, scritto, montato e condotto dal sottoscritto:
lo trovate
[qui sul sito della RSI](https://www.rsi.ch/web/podcast/il-disinformatico/Le-IA-danno-voce-a-vittime-di-stragi-e-imbarazzano-le-aziende-Avast-spiona--2083942.html)
(si apre in una finestra/scheda separata) e lo potete scaricare
[qui](https://rsi-aod-il-dd.akamaized.net/ww/2083942.mp3?ts=1709276212&fname=Le_IA_danno_voce_a_vittime_di_stragi_e_imbarazzano_le_aziende_Avast_spiona.mp3).

Le puntate del *Disinformatico* sono ascoltabili anche tramite
[iTunes](https://podcasts.apple.com/ch/podcast/il-disinformatico/id203842628),
[Google Podcasts](https://podcasts.google.com/feed/aHR0cHM6Ly93d3cucnNpLmNoL3JldGUtdHJlL3Byb2dyYW1taS9pbnRyYXR0ZW5pbWVudG8vaWwtZGlzaW5mb3JtYXRpY28vP2Y9cG9kY2FzdC14bWw),
[Spotify](https://open.spotify.com/show/20uK3XvVxdNxFHreEepr8k)
e
[feed RSS](https://www.rsi.ch/web/podcast/il-disinformatico/?f=podcast-xml).

Buon ascolto, e se vi interessano il testo di accompagnamento e i link alle
fonti di questa puntata, sono qui sotto.

---

*[CLIP: Joaquin che parla]*

Questa è la voce di Joaquin Oliver, un diciassettenne morto in una sparatoria
di massa negli Stati Uniti, che racconta al passato i dettagli di come è stato
ucciso. Una voce resa possibile dall’intelligenza artificiale nella speranza
di muovere i cuori dei politici statunitensi sulla questione annosa del
controllo delle armi da guerra.

È una delle storie della puntata del primo marzo 2024 del
*Disinformatico*, il podcast della Radiotelevisione Svizzera dedicato
alle notizie e alle storie strane dell’informatica: le altre notizie
riguardano un software di intelligenza artificiale che ha dato informazioni
sbagliate a un cliente di una compagnia aerea canadese, facendogli perdere
parecchi soldi, e quando il cliente ha contestato il fatto la compagnia ha
risposto che lei non era responsabile delle azioni della sua intelligenza
artificiale. Non è andata finire molto bene, soprattutto per il software. E
poi c’è la scoperta che Avast, un noto produttore di applicazioni per tutelare
la sicurezza informatica e la privacy, ha in realtà venduto a oltre cento
aziende i dati degli utenti che diceva di proteggere. Anche in questo caso la
storia non è finita bene, ma contiene una lezione interessante.

Benvenuti a questo podcast. Io sono Paolo Attivissimo.

*[SIGLA di apertura]*

### Air Canada e il suo chatbot “responsabile delle proprie azioni”

L’intelligenza artificiale ormai è dappertutto, e quindi qualche caso di
applicazione maldestra è normale e inevitabile. Quello che non è normale è
l’applicazione *arrogante*. Questa vicenda arriva dal Canada, dove la
compagnia aerea Air Canada ha pensato di adottare l’intelligenza artificiale
per rispondere automaticamente alle domande dei clienti sul proprio sito di
prenotazioni di voli.

Uno di questi clienti, il signor Moffatt, si è rivolto a questo sistema di
risposta automatica tramite chat per chiedere informazioni sulle tariffe
speciali riservate ai voli prenotati all’ultimo momento a causa di lutti in
famiglia, visto che aveva appena saputo del decesso della nonna.

Il sistema di chat o *chatbot* gestito dall’intelligenza artificiale gli
ha fornito informazioni dettagliate su come procedere alla richiesta di
riduzione del prezzo del biglietto, spiegando che questa richiesta andava
inviata alla compagnia aerea entro tre mesi dalla data di rilascio del
biglietto, compilando l’apposito modulo di rimborso. Istruzioni chiare,
semplici e non ambigue. Ma completamente sbagliate.

In realtà il regolamento di Air Canada prevede che le richieste di riduzione
debbano essere inviate *prima* della prenotazione, e quindi quando il
signor Moffatt ha poi chiesto il rimborso si è sentito rispondere dal
personale della compagnia che non ne aveva diritto, nonostante il chatbot di
Air Canada gli avesse detto che lo aveva eccome. La conciliazione amichevole è
fallita, e così il cliente fuorviato dall’intelligenza artificiale ha portato
la compagnia aerea dal giudice di pace. Ed è qui che è arrivata l’arroganza.

Air Canada, infatti, si è difesa dicendo che il cliente non avrebbe mai dovuto
fidarsi del chatbot presente sul sito della compagnia aerea e ha aggiunto che,
cito testualmente dagli
[atti](https://www.canlii.org/en/bc/bccrt/doc/2024/2024bccrt149/2024bccrt149.html),
*“il chatbot è un’entità legale separata che è responsabile delle proprie
azioni”*.

Che un software sia responsabile delle proprie azioni è già piuttosto
surreale, ma che la compagnia prenda le distanze da un servizio che lei stessa
offre e oltretutto dia la colpa al cliente per essersi fidato del
*chatbot* senza aver controllato le condizioni di rimborso effettive è
una vetta di arroganza che probabilmente non ha precedenti nella storia degli
inciampi delle intelligenze artificiali, e infatti il giudice di pace ha
deciso pienamente in favore del cliente, dicendo che la compagnia è
responsabile di *tutte* le informazioni presenti sul proprio sito: che
siano offerte da una pagina statica o da un chatbot non fa alcuna differenza,
e i clienti non sono tenuti a sapere che il chatbot potrebbe dare risposte
sbagliate.

A quanto risulta il chatbot è stato rimosso dal sito della compagnia, che fra
l’altro aveva dichiarato che il costo dell’investimento iniziale
nell’intelligenza artificiale per l’assistenza clienti era stato largamente
superiore al costo di continuare a pagare dei lavoratori in carne e ossa. La
speranza era che l’intelligenza artificiale *riducesse* i costi e
migliorasse l’interazione con i clienti, ma in questo caso è successo l’esatto
contrario, con l’aggiunta di una figuraccia pubblica non da poco. Una lezione
che potrebbe essere preziosa anche per molte altre aziende che pensano di
poter risparmiare semplicemente sostituendo in blocco i lavoratori con
un’intelligenza artificiale esposta al pubblico senza adeguata supervisione.

*Fonte aggiuntiva:
[Ars Technica](https://arstechnica.com/tech-policy/2024/02/air-canada-must-honor-refund-policy-invented-by-airlines-chatbot/).*

### Avast ha fatto la spia, dice la FTC

Avast (o *a-VAST*, secondo la pronuncia inglese corretta, che però in italiano
non usa praticamente nessuno) è un nome molto noto nel campo della sicurezza
informatica, in particolare per i suoi antivirus. Ma è emerso che mentre
diceva pubblicamente di proteggere la privacy dei propri clienti in realtà
stava vendendo i loro dati a oltre cento aziende.

Secondo le indagini e la
[decisione](https://www.ftc.gov/system/files/ftc_gov/pdf/D%26O-Avast.pdf)
della Federal Trade Commission, l’agenzia federale statunitense di vigilanza
sul commercio, fra il 2014 e il 2020, mentre Avast dichiarava pubblicamente
che i suoi prodotti avrebbero *impedito* il tracciamento delle attività
online di chi li usava, i...