---
title: 「人均 DeepSeek」之后，AI 应用还能怎么做？
url: https://mp.weixin.qq.com/s?__biz=MTMwNDMwODQ0MQ==&mid=2653073906&idx=1&sn=d426132e93c33bd26679d27039088c9c&chksm=7e57cc4449204552eb4bbca16a1f4eb222cf155f305d4ff6c82f01df70a2afe8af5304217790&scene=58&subscene=0#rd
source: 极客公园
date: 2025-02-18
fetch_date: 2025-10-06T20:47:16.400165
---

# 「人均 DeepSeek」之后，AI 应用还能怎么做？

![cover_image](https://mmbiz.qpic.cn/mmbiz_jpg/8cu01Kavc5YZhiasTGkkJZ96dico3nbveJoSY9s7RYJp3u55kejw3zRPUw45Yuea1HY6iaHzQH6vA4ZSfwOhs2qxQ/0?wx_fmt=jpeg)

# 「人均 DeepSeek」之后，AI 应用还能怎么做？

极客公园

![](https://mmbiz.qpic.cn/mmbiz_jpg/8cu01Kavc5YZhiasTGkkJZ96dico3nbveJyo2zzDtxiciaDX695k04kwviayIiaChoLQ9iaKTajGk5aoZ3Vxg47mf1ibzw/640?wx_fmt=jpeg&from=appmsg)

Deepseek 冲击波之后，如何复盘它的成功、预测它的未来？

**整理 | 宛辰****编辑**| 靖宇****

2025 年开年，迎来了「中国的 ChatGPT 时刻」。

由于 DeepSeek-R1 模型能力带来的震撼，从硅谷到中国、从老人到小孩、从 AI 创业者到各行各业的从业者、从小红书到抖音，都在「玩」DeepSeek。

DeepSeek 最新的「朋友圈」是百度和微信。前者即便面对传统搜索带来的丰厚商业回报，也接入 R1 主动变革；而从不激进的微信也罕见地积极了一把，接入 R1 升级了微信中的「AI 搜索」

很难想象，在 ChatGPT 诞生两年后，所谓「大模型窗口期已过」的时间点上，杀出了这样一匹黑马，以所有人意想不到的方式，掀翻了大模型产业的桌子。当所有人都看到 DeepSeek 带来的机遇，当大厂也一反常态不再要求先做出自研的模型技术、而是现在就接入最好的 DeepSeek 模型做 AI 应用，2025AI 会如何发展？

2025 年 2 月 8 日，极客公园「今夜科技谈」直播间邀请极客公园创始人 & 总裁张鹏，昆仑万维 董事长兼 CEO 方汉、秘塔科技 CEO 闵可锐和清华大学交叉信息院 助理教授 吴翼，一起探讨了 DeepSeek 带来的冲击波以及 2025AI 应用还能怎么做？

* DeepSeek 文笔好、思考过程比人类都有逻辑，这会成为接下来做产品的标配动作吗？
* 有了 DeepSeek，蒸馏还能怎么做？为什么蒸馏是常规方法论，与价值观无关？
* 为什么说有了 R1，也并不意味着 AI 应用更好做了？更大的挑战才刚开始。
* DeepSeek 之前，大模型领域默认「老大老二不开源，老三开源赚名声」法则，但反倒是从第一天就坚持开源引领技术生态的 DeepSeek 赢得了天下。开源到底意味着什么？现在，是不是应该问：还有谁没有加入开源队伍？
* 靠优化 AI Infra 实现「价格屠夫」背后，没有人比 DeepSeek 更懂英伟达 CUDA，未来，模型推理价格还可以香到什么程度？
* 达到全球第二的成绩后，DeepSeek，接下来会发什么？

看完这篇，你会对 2025 年接下来 AI 圈即将要发生的大事件，有更好的判断。

![](https://mmbiz.qpic.cn/mmbiz_png/8cu01Kavc5YZhiasTGkkJZ96dico3nbveJyU0DICtL2tdaCe402XovsdsiaTwXPJG8A7BGxyB7DKxQ4zKuWa7Jp2g/640?wx_fmt=png&from=appmsg)

***01***

******DeepSeek-R1：开源模型有史以来最好的成绩******

**张鹏：从你的角度，DeepSeek 这次爆火背后，最值得关注的创新点是什么？**

**吴翼：**DeepSeek-R1 是第一个开源的，并且真正接近、达到 OpenAI o1 水平的模型，后者是一个新的推理类的范式。同时，DeepSeek 还把怎么得到 R1 这个模型的很多细节、大概的 recipe（配方）也告诉你了，在这一点上，它也是第一个。

带给我最大的冲击是两件事情。第一，没想到能这么快做出来，因为从 o1 面世（2024 年 9 月 13 日），到中国的团队开始尝试复现 o1 类似的模型，DeepSeek 真正做这件事满打满算也就半年。在这条技术线上，OpenAI 可能探索了一两年的时间才做出 o1。

第二是当这个模型拿出来的时候，没想到「哇，真的这么好」，R1 是开源、所有人都可以试。

两件事情加起来，一下子就没话说，非常有历史时刻的感觉，然后春节就没过好（哈哈）。

**张鹏：所有人都在思考****，****怎么出来的，为什么不是我们（哈哈）。你们怎么看 DeepSeek 冲击波？**

**闵可锐：**知道这家公司是在 2023 年他们刚成立的时候，当时可能为了招人等诉求，（DeepSeek 创始人梁文锋）稍微有一些对外的发声，看完会感受到这家公司身上很不一样的特质、非常回归本质的讨论问题的方法。所以 DeepSeek 能在一年多的时间做到像现在这样火热的程度，也许有一定的意外性，但是对于他能把这件事做好，并不意外。

**方汉：**最早知道 DeepSeek 是在 2022 年底、2023 年初去买卡的时候，意外得知幻方有万卡。后来注意到 DeepSeek-Coder 模型在代码类 Benchmark 上一度冲到全球第一。

再就是「推理价格屠夫」DeepSeek-V2 的推出，直接把模型推理价格打到了当时业内平均价格的 1/10。这里面有两项技术印象特别深刻，一个是 MLA（多头注意力的优化），第二个是 MTP（Multi-Token Prediction，多 token 预测）。

最近是 V3 和 R1 的推出。V3 是一个挺强的基模，但是它跟 Meta 的 Llama 405B、Qwen 等系列开源模型一样，前面还有两个天花板，OpenAI 的模型和 Anthropic 的 Claude。**但是 DeepSeek-R1 这一次直接能够排到第二名的位置，开源模型有史以来最好的成绩，这是让我们最震惊的。**

![](https://mmbiz.qpic.cn/mmbiz_png/8cu01Kavc5YZhiasTGkkJZ96dico3nbveJ699YJyA04h1IyxIRR99bGyjNavP3NJJibHMqJ00hVmiaAz7KJEjIv4aQ/640?wx_fmt=png&from=appmsg)DeepSeek-R1 在后训练阶段大规模使用了强化学习技术，在仅有极少标注数据的情况下，极大提升了模型推理能力。在数学、代码、自然语言推理等任务上，性能比肩 OpenAI o1 正式版。｜来源：DeepSeek

**张鹏：DeepSeek-R1 里的模型技术，有哪些创新让你们印象比较深刻？**

**方汉：**技术角度，这次 R1 做了很多技术上的改进，像 DualPipe 算法，像用 PTX 去写通讯之类的，最印象深刻的肯定也是训 R1-Zero 用的 GRPO 这个技术，这是整个 R1 里最核心的东西。

因为 OpenAI 在做 o1 的时候，请了上百个数学博士天天解题，数据非常高质量，但他从来不对外界说怎么做数据。大家也知道很多公司会用 PPO，真正能把 PPO 用得特别好的还是 OpenAI 和 Anthropic。国内大家在 PPO 用不好的前提下，DeepSeek 用 GRPO 的方法非常巧妙，省掉了 Critic Model，后者做起来特别大、特别慢。

**通过 GRPO 的方法，可以快速迭代出一批特别高质量的 CoT 数据，这一点特别令人震惊，等于说 OpenAI 自己辛辛苦苦找人花钱做出来的数据，被咣地一下给开源了，**而且从结果上来看，它的质量特别好，不逊于 OpenAI 的内部数据。这一点是非常非常革命性的，我们一直认为合成数据比不上人的数据，但是**R1 这一次有可能表明，合成数据不比人标的数据差。**这给很多人带来了希望，像欧洲、印度、韩国都觉得自己也可以做了。

**闵可锐：**讨论最多的还是 R1-Zero 的技术创新。

过去大家认为，不管是做 SFT（有监督微调），还是做强化学习，都依赖大量人工标注的数据，人工在里面参与度非常重。比如之前传出 Meta 在数据标注上，是以亿美金级别的投入去换得质量相对较高的数据。但是 R1-Zero 表明其实可以大规模降低对于人工标注（数据）的依赖。

同时，R1-Zero 的突破带来了代码能力、数学能力、推理能力的提升。

但我觉得**能火到全民皆知的程度，其实不是由于它的推理能力、代码能力，还是因为 DeepSeek 写东西（的水平）超出了 90% 的人，写作能力非常突出，**这件事震撼到了大家。

***02***

******DeepSeek 文笔好，是因为没有好好做产品？******

**张鹏：很多网友都说被 R1 的文笔惊艳到了，至少公众热情是这么被点燃的，不管是在中国还是海外。就连****AI****创业者也会感慨，以前用 o1 给人的感觉是多了一个理性的员工，今天用 R1 却感觉成为了他的人生导师，竟然能带来很多启发。所谓的模型文笔好，技术上是怎么实现的？**

**吴翼：**简单说，文笔特别好（的原因）就是 DeepSeek 没有好好做产品（哈哈）。

如果用 ChatGPT 写，经常会讲文章 GPT 味特别重。为什么呢？因为 ChatGPT 在安全、对齐（alignment）上做得非常猛。这样就会导致，比如当人跟 AI 一起玩「狼人杀」时，你特别容易看出来哪个是 GPT。因为人类玩家会直接说，「这个人一定是个坏人」，但 GPT 会说，「我觉得这个人好像怎么样，我们应该怎么理性分析……」讲很多啰里八嗦的废话。这就是它「对齐」做得特别好的体现，它希望这个东西不要冒犯到人，希望产品化做得好。

但**DeepSeek 显然没有好好做这件事情，所以大模型本来的这些天花乱坠的想法就被你看到了，而 OpenAI 为了做安全性，为了做所谓的「价值观对齐」，反而是把模型的很多能力收起来。**

第二，如果仔细地去看 R1 的技术报告，它其实分了两步，先用强化学习做出了一版推理模型，但没有直接给你用这个推理模型，而是后面有一个合并模型的过程，最后是完整版的 R1 模型有一些泛化能力。

展开讲，因为在代码、数学这种特定任务上做强化学习训练出来的推理模型 R1-Zero，文字上肯定会差一些，所以 R1-Zero 又跟原来的基模 V3 用 SFT 这种类似于蒸馏或者合并模型的过程，最后合并出了带有泛化能力的模型 R1。这也说明 V3 这个模型确实非常好，**如果 V3 比较差的，最后合并出来你也看不到那么多奇思妙想。换句话说，强化学习很重要，基模也很重要。**

**张鹏：这个视角蛮有意思，反而是过度对齐，会让它的脑洞、想象力或者一些 hallucination（幻觉）被压制了。**

**吴翼：**对，创意其实是 hallucination。

![](https://mmbiz.qpic.cn/mmbiz_jpg/8cu01Kavc5YZhiasTGkkJZ96dico3nbveJZol2xr3t6vibrkFAJu0P5XfDiaotC9Ic01q6LIOpnTPS6NmNHI1vtOBg/640?wx_fmt=jpeg&from=appmsg)作者卫夕向 DeepSeek 提问[「玄武门之变结束的当天，李世民在深夜写下一段独白，你觉得他会写什么？」](https://mp.weixin.qq.com/s?__biz=MTMwNDMwODQ0MQ==&mid=2653072943&idx=2&sn=42192769f13fb530fa9d3e23e0ad898c&scene=21#wechat_redirect)，网友为 DeepSeek 输出的答案而感到惊叹。｜截图来源：微博

**张鹏：可锐，你怎么看它的文字表达很好？背后有什么原因和讲究？**

**闵可锐：**我猜测可能有三个原因，一是刚才提到的 DeepSeek 没有试图把很多偏个性化的一些表达给阉割掉。你会发现很多 GPT 的回复是「端水型的」「安全型的」，但其实比较 boring 的回复。所以 DeepSeek 一定没有在安全性方面做激进的动作，模型输出的表达上相对比较自由。

第二个猜测，很多人觉得 R1 的强化学习本身增加了它的写作能力，但我对这件事是存疑。我听到的一个信息是，之所以有比较好的表达，**背后是有比较资深的、类似于北大中文系的人在帮忙在写数据。人的自由表达和高质量的数据作为对模型回复的一个引导，来达到好的效果。**我会觉得应该是 SFT 这个部分的数据做得非常好。

第三，R1 以及 V3 的模型如果和行业同类模型相比，它其实把规模差不多涨了 10 倍，差不多从一个几十 G 的规模涨到了几百 G。这个规模下它能够储存的信息容量差不多比上一代 Qwen 涨了十倍，这让它在很多比较细致的表达上能够有更好的还原。也就是说**它的压缩率其实不用做得那么高，能够记住更多东西，包括像诗词、或者开放式的问题上。**

总结来说，更大的脑容量、高人撰写的文学性数据作引导和对齐，并且降低了严格的安全对齐（标准），可能是这三点加起来得到了 DeepSeek 的优美深刻的表达。

**张鹏：一些在硅谷的华人****AI****研究员也说，可能过去海外的大模型对于高质量中文数据没有特别较真过，但 DeepSeek 较真了。方汉你怎么看「大家说 DeepSeek 文笔好」？**

**方汉：**虽然我学的是理科，但我高考作文是满分，所以对古文比较熟，我特别喜欢让大模型写古诗词。在这件事上，现在写的最好的模型实际上是 Claude，也就是说 **Claude 的文采比 ChatGPT 要好很多。**我觉得还是数据的原因，大家公认 Anthropic 对数据的品位最高，数据做得最好，他们的数据团队规模在语文和写作方面非常强，我猜 DeepSeek 也是类似。

DeepSeek 内部可能有一套方法，可以从现有的数据里面生成质量非常高的语文数据，这是我的猜想。因为请大量顶尖团队比如北大中文系标数据，DeepSeek 未必竞争得过大厂，（靠人工标注数量和质量取胜）逻辑上讲不通。**DeepSee****k 在不要人干预的情况下，可以用 GRPO 可以生成数学和编程的 CoT 数据，那这些方法能不能用在语文上去生成高质量的语文数据，这是我更相信的一个推断。**

另外，我们在做推理模型的时候有个叫 temperature（温度）的参数，如果把这个参数值设得高，模型就开始胡说八道、特别有创意，但也很容易崩。可能因为 R1 的推理能力很强，哪怕把 temperature 加得比一般模型高，也是比较活跃且不容易崩。

***03***

******「被 DeepSeek 的思考过程震撼到了」******

**张鹏：除了文笔好，很多用户也被 DeepSeek 思考过程的透明和清晰的逻辑打动，R1 是第一家展示思考过程的模型吗？**

**吴翼：****完整思维链的透明展示，确实是 DeepSeek 第一个做出来的，但 R1 不是第一次，第一次真正公开所有思维链的模型是去年 11 月 20 日发布的 DeepSeek-R1-Lite。**

后来 Gemini 跟进了，也公开了思维链，Gemini 的 Flash thinking 的思维链质量也不错。

其实去年 9 月 OpenAI 发布的 o1 也给了这样的中间步骤，只是它不给你看思维链的完整版，就给你一个总结版。从技术视角上，藏没藏思维链差挺多的。不过总结版的思维链虽然不完整，但也挺有价值的，很多人发现即使是「扒」总结版思维链数据，也能对模型有很多提升。

![](https://mmbiz.qpic.cn/mmbiz_jpg/8cu01Kavc5YZhiasTGkkJZ96dico3nbveJUwyEDsv4ljRa3ViasSDeBzRuLC2xe8wicuXMjrsHsFm5kVwDR5Kxw3Ew/640?wx_fmt=jpeg&from=appmsg)图片来源：视觉中国

**张鹏：你觉得****OpenAI****为什么不给大家公开思维链？**

**吴翼：**高质量思维链对于模型的能力提升、以及激发模型让它在第二阶段强化学习训练时能有很好的推理表现、继续用强化学习做 Scaling Law 是很重要的。所以 OpenAI 应该在这件事情上花了一些力气，他知道如果真的把思维链给你去 distill（蒸馏），你很快就能做出来，他就是不让你「抄」。

最近李飞飞老师团队做的、被炒得很热的 S1，50 美金能够让你看到 test-time-in-scaling 的效果，也说明了这个道理。它只输了 1000 条 Gemini 的长思维链数据，就能让模型有比较大的推理表现上的质变，当然它效果还比较一般，50 美金不可能真的把 R1 复现。所以高质量的长思维链数据是重要的，这也是 OpenAI 不愿意给你看的原因。

**方汉：**我觉得 OpenAI 就是想保守机密，OpenAI 一直认为思维链数据是它最值钱的数据，所以很早就出了一个 term sheet（条款），你要是敢 jail break（越狱）问他 CoT 的问题，他会封你的账号。R1 发布之后，OpenAI 也把 o3-mini 的思维链输出了，但这里是总结版的思维链，结果又被网友骂了，然后现在又正在把总结再去掉。

当然大家没有想到的是 DeepSeek 说，要不我试一下，我也不要中间这个步骤，直接给你强化学习行不行？很长时间大家都觉得中间需要搞一步 SFT，结果 DeepSeek 出来跟你说，我们试了一下，好像不需要也行。

**张鹏：因为没有人做出来过，或者没有人按这个方式做出来过。**

**吴翼：**就是**对面有一家告诉你这个东西特重要，「此地无银三百两」，我家一定没有黄金，你千万别来。那大家都会往这上面花很多精力想，最后 DeepSeek 试出来说，你看你没这玩意也行，哈哈哈，或者说有比较便宜的方法能绕过去。**

**张鹏：秘塔科技也在第一时间与 DeepSeek-R1 合作做了相关的功能，思考过程的可视化。可锐，从用户的角度，你怎么看这件事带来的影响？展示透明的思维链本身，是不是一种用户价值交付？**

**闵可锐：**我会觉得思维链，不管是总结版也好，还是像 R1 给到一个相对完整的思维链，最早的出发点可能是通过步骤和步骤之间的推导，提高结果的准确率。

但把它展示出来，我会认为最早是因为中间的等待时长实在太长了。如果**让用户在这无休止地比如像看沙漏一样（等时间），用户体验是非常糟糕的。所以既然有一个中间的推导过程，索性把推导过程显示给用户，但是这似乎带来了一个非常意外的好处。**

很多人反而专门去看思维链，「诶，这个模型怎么思考的？它怎么从不同角度去考虑我提的问题」，这对我来说是稍微有点意外的。我观察到很多人其实还挺喜欢看 R1 的思维链，因为模型把思维链写得像是一个内心独白一样。

**就像有人问它说，「诶，我有一个朋友怎么怎么样」...