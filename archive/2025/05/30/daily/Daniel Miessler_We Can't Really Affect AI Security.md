---
title: We Can't Really Affect AI Security
url: https://danielmiessler.com/blog/ai-security
source: Daniel Miessler
date: 2025-05-30
fetch_date: 2025-10-06T22:43:18.116054
---

# We Can't Really Affect AI Security

[Daniel Miessler](https://danielmiessler.com)

Main Navigation [home](/)[blog](/blog/)[telos](/telos/)[ideas](/ideas/)[projects](/projects/)[predictions](/predictions/)[speaking](/speaking/)[about](/about/)

# We Can't Really Affect AI Security

The baseline for AI Security is set by the market of people's behavior

May 29, 2025

[#ai](/archives/?tag=ai) [#business](/archives/?tag=business) [#cybersecurity](/archives/?tag=cybersecurity) [#society](/archives/?tag=society) [#technology](/archives/?tag=technology) [#recommended](/archives/?tag=recommended) [#top](/archives/?tag=top)

![AI Security - Human Behavior and Cyber Market Dynamics](https://danielmiessler.com/cdn-cgi/imagedelivery/EcOiF3GdYQuwXdQn9UJBuA/ai-security-Human_Behavior_Cyber_Market_Dynamics/public)

We're about to get precisely the right amount of AI Security. No more and no less.

I've talked before about what I called the [Efficient Security Principle](https://danielmiessler.com/blog/efficient-security-principle), which says the excitement for a technology lowers its required security bar.

![ESP](https://danielmiessler.com/cdn-cgi/imagedelivery/EcOiF3GdYQuwXdQn9UJBuA/ai-security-ESP-efficient-security-principle/public)

That's definitely happening with AI, but I'm interested in another aspect of the principle.

**It doesn't really matter what any individual or group does to increase or reduce AI Security, because that security baseline is determined by overall human interaction with the technology.**

The security of MCP is likely to be a great example of punctuated equilibrium here.

1. If we don't have enough security, but not enough bad things happen, security won't increase despite anyone's Heroic efforts.
2. Conversely, we can release a torrent of AI slop with no security whatsoever, and if one or more breaches are so bad that they slap people awake…increased security will happen almost overnight.

In other words, the amount of security that we get and maintain will be precisely the "right" amount.

Not the amount that us security people want—or that really anyone sees as the perfect or adequate amount—but the "right" amount in terms of a business/risk functional equilibrium.

All this to say…

*Don't worry too much about AI Security.*

Government / regulation seems to be an exception, but it too is largely guided by public outcry.

It's going to be a horror show, and it's already started. But there's nothing that any one person or group can do to actually move the baseline.

The baseline moves on its own, with the mass of a dozen suns, based on how well the tech is working for people as a whole compared to how afraid people are to use it.

That equilibrium is not something we can control. It moves by itself based on what actually happens in the world.

* When massive, significant incidents happen—security will increase
* When things are mostly quiet (like the billions lost every year from online banking security issues), people will yawn and accept, and security improvements will stagnate.

As security people, we need to acknowledge that no amount of rooftop screaming will affect this dynamic.

Let's relax a bit, put on our shepherd's gear, and try to guide people the best we can through this insane moment in history.

#### Notes

1. [The Efficient Security Principle](https://danielmiessler.com/blog/efficient-security-principle)

Share

[Post](https://ul.live/share/x?url=https%3A%2F%2Fdanielmiessler.com%2Fblog%2Fai-security&title=We%20Can't%20Really%20Affect%20AI%20Security "Share on X")  [LinkedIn](https://ul.live/share/linkedin?url=https%3A%2F%2Fdanielmiessler.com%2Fblog%2Fai-security&title=We%20Can't%20Really%20Affect%20AI%20Security "Share on LinkedIn") [HN Hacker News](https://ul.live/share/hn?url=https%3A%2F%2Fdanielmiessler.com%2Fblog%2Fai-security&title=We%20Can't%20Really%20Affect%20AI%20Security "Share on Hacker News")  [Reddit](https://ul.live/share/reddit?url=https%3A%2F%2Fdanielmiessler.com%2Fblog%2Fai-security&title=We%20Can't%20Really%20Affect%20AI%20Security "Share on Reddit")  [Facebook](https://ul.live/share/facebook?url=https%3A%2F%2Fdanielmiessler.com%2Fblog%2Fai-security&title=We%20Can't%20Really%20Affect%20AI%20Security "Share on Facebook")  [Forward](https://ul.live/share/email?url=https%3A%2F%2Fdanielmiessler.com%2Fblog%2Fai-security&title=We%20Can't%20Really%20Affect%20AI%20Security "Share via Email")

Follow

[Get The Newsletter](https://ul.live/nlpostfooter?url=https%3A%2F%2Fdanielmiessler.com%2Fblog%2Fai-security&title=We%20Can't%20Really%20Affect%20AI%20Security)  [Follow On X](https://ul.live/xpostfooter?url=https%3A%2F%2Fdanielmiessler.com%2Fblog%2Fai-security&title=We%20Can't%20Really%20Affect%20AI%20Security)  [Subscribe On YouTube](https://ul.live/ytpostfooter?url=https%3A%2F%2Fdanielmiessler.com%2Fblog%2Fai-security&title=We%20Can't%20Really%20Affect%20AI%20Security)  [Follow On LinkedIn](https://ul.live/lipostfooter?url=https%3A%2F%2Fdanielmiessler.com%2Fblog%2Fai-security&title=We%20Can't%20Really%20Affect%20AI%20Security)

Search

This post was tagged with:

aibusinesscybersecuritysocietytechnologyrecommendedtop

[HOME](/)·[BLOG](/blog)·[ARCHIVES](/archives)·[ABOUT](/about)

© 1999 — 2025 Daniel Miessler. All rights reserved.