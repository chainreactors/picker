---
title: 让 LLaMa 能运行在 CPU 上
url: https://buaq.net/go-152627.html
source: unSafe.sh - 不安全
date: 2023-03-09
fetch_date: 2025-10-04T08:59:32.939672
---

# 让 LLaMa 能运行在 CPU 上

* [unSafe.sh - 不安全](https://unsafe.sh)
* [我的收藏](/user/collects)
* [今日热榜](/?hot=true)
* [公众号文章](/?gzh=true)
* [导航](/nav/index)
* [Github CVE](/cve)
* [Github Tools](/tools)
* [编码/解码](/encode)
* [文件传输](/share/index)
* [Twitter Bot](https://twitter.com/buaqbot)
* [Telegram Bot](https://t.me/aqinfo)
* [Search](/search/search)

[Rss](/rss.xml)

[ ]
黑夜模式

![]()

让 LLaMa 能运行在 CPU 上

AI 聊天机器人的炙手可热让 GPU 尤其是英伟达的 GPU 再次成为市场热点。今天流行的聊天机器人如 OpenAI 的 ChatGPT 运行在云服务器上，对普通用户而言日常使用只能依赖于
*2023-3-8 22:41:27
Author: [www.solidot.org(查看原文)](/jump-152627.htm)
阅读量:13
收藏*

---

AI 聊天机器人的炙手可热让 GPU 尤其是英伟达的 GPU 再次成为市场热点。今天流行的聊天机器人如 OpenAI 的 ChatGPT 运行在云服务器上，对普通用户而言日常使用只能依赖于 OpenAI。Meta 的大语言模型 LLaMA 则让工作站用户在配备服务器级 GPU 的本地计算机上运行成为可能。类似开源的文本图像模型 Stable Diffusion，开发者也在快速推动大语言模型的普及化。一位西雅图的开发者将 LLaMA 移植到了 CPU 上。对于 LLaMA-7B 模型（包含 70 亿参数） ，Ryzen 7900X 能每秒推断出多个单词。

https://github.com/markasoftware/llama-cpu

文章来源: https://www.solidot.org/story?sid=74335
 如有侵权请联系:admin#unsafe.sh

© [unSafe.sh - 不安全](https://unsafe.sh) Powered By [PaperCache](https://github.com/code-scan/PaperCache)

* admin#unsafe.sh
* [安全马克](https://aq.mk)
* [星际黑客](https://xj.hk)
* [T00ls](https://t00ls.net)