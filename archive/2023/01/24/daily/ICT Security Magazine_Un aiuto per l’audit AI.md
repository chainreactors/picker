---
title: Un aiuto per l’audit AI
url: https://www.ictsecuritymagazine.com/articoli/un-aiuto-per-laudit-ai/
source: ICT Security Magazine
date: 2023-01-24
fetch_date: 2025-10-04T04:40:19.637115
---

# Un aiuto per l’audit AI

[Salta al contenuto](#main)

[![ICT Security Magazine](https://www.ictsecuritymagazine.com/wp-content/uploads/2016/01/logo-ict-security.jpg)](https://www.ictsecuritymagazine.com/)

* [Home](https://www.ictsecuritymagazine.com/)
* [Articoli](https://www.ictsecuritymagazine.com/argomenti/articoli/)
* RubricheEspandi
  + [Cyber Security](https://www.ictsecuritymagazine.com/argomenti/cyber-security/)
  + [Cyber Crime](https://www.ictsecuritymagazine.com/argomenti/cyber-crime/)
  + [Cyber Risk](https://www.ictsecuritymagazine.com/argomenti/cyber-risk/)
  + [Cyber Law](https://www.ictsecuritymagazine.com/argomenti/cyber-law/)
  + [Digital Forensic](https://www.ictsecuritymagazine.com/argomenti/digital-forensic/)
  + [Digital ID Security](https://www.ictsecuritymagazine.com/argomenti/digital-id-security/)
  + [Business Continuity](https://www.ictsecuritymagazine.com/argomenti/business-continuity/)
  + [Digital Transformation](https://www.ictsecuritymagazine.com/argomenti/digital-transformation/)
  + [Cyber Warfare](https://www.ictsecuritymagazine.com/argomenti/cyber-warfare/)
  + [Ethical Hacking](https://www.ictsecuritymagazine.com/argomenti/ethical-hacking/)
  + [GDPR e Privacy](https://www.ictsecuritymagazine.com/argomenti/gdpr-e-privacy/)
  + [IoT Security](https://www.ictsecuritymagazine.com/argomenti/iot-security/)
  + [Industrial Cyber Security](https://www.ictsecuritymagazine.com/argomenti/industrial-cyber-security/)
  + [Blockchain e Criptovalute](https://www.ictsecuritymagazine.com/argomenti/blockchain-e-criptovalute/)
  + [Intelligenza Artificiale](https://www.ictsecuritymagazine.com/argomenti/intelligenza-artificiale/)
  + [Geopolitica e Cyberspazio](https://www.ictsecuritymagazine.com/argomenti/geopolitica-cyberspazio/)
  + [Interviste](https://www.ictsecuritymagazine.com/argomenti/interviste/)
* [Notizie](https://www.ictsecuritymagazine.com/argomenti/notizie/)
* [Pubblicazioni](https://www.ictsecuritymagazine.com/pubblicazioni/)
* [Cybersecurity Video](https://www.ictsecuritymagazine.com/argomenti/cybersecurity-video/)
* [Eventi](https://www.ictsecuritymagazine.com/eventi/)
* [Newsletter](https://www.ictsecuritymagazine.com/newsletter/)

[Linkedin](https://www.linkedin.com/company/ict-security-magazine/) [YouTube](https://www.youtube.com/%40ictsecuritymagazine1403) [RSS](https://www.ictsecuritymagazine.com/feed/)

[![ICT Security Magazine](https://www.ictsecuritymagazine.com/wp-content/uploads/2016/01/logo-ict-security.jpg)](https://www.ictsecuritymagazine.com/)

Attiva/disattiva menu

[![Forum ICT Security 2025](https://www.ictsecuritymagazine.com/wp-content/uploads/banner-header-2025.jpg)](https://www.ictsecuritymagazine.com/eventi/forumictsecurity2025)

![](https://www.ictsecuritymagazine.com/wp-content/uploads/audit-AI.jpg)

# Un aiuto per l’audit AI

A cura di:[Stefano Gorla e Attilio Rampazzo](#molongui-disabled-link)  Ore 23 Gennaio 2023

Come accennato nei precedenti articoli:

* [E’ possibile una Governance e un Controllo dell’AI?](https://www.ictsecuritymagazine.com/articoli/e-possibile-una-governance-e-un-controllo-dellai/);
* [E’ possibile un controllo dell’Intelligenza Artificiale?](https://www.ictsecuritymagazine.com/articoli/e-possibile-un-controllo-dellintelligenza-artificiale/);
* [La Governance dell’AI attraverso le norme ISO](https://www.ictsecuritymagazine.com/articoli/la-governance-dellai-attraverso-le-norme-iso/);
* [Ancora sulla Governance dell’AI](https://www.ictsecuritymagazine.com/articoli/ancora-sulla-governance-della-ai/);
* [Un approccio alla Governance dell’AI;](https://www.ictsecuritymagazine.com/articoli/un-approccio-alla-governance-della-ai/)
* [Modello di autovalutazione relativo a un sistema di Intelligenza Artificiale;](https://www.ictsecuritymagazine.com/articoli/modello-di-autovalutazione-relativo-a-un-sistema-di-intelligenza-artificiale/)

il controllo sui sistemi AI è di fondamentale importanza per verificare la correttezza e il soddisfacimento dei principi e la riduzione dei rischi derivanti dall’AI.

Questo può essere fatto con diversi sistemi o metodologie, che attraverso delle check list, permettono la verifica del sistema e la conduzione delle verifiche ispettive (sia di parte prima, seconda che terza).

In questo articolo si vogliono indicare alcuni strumenti utili sia all’auditor che all’organizzazione.

Un utile strumento potrebbe essere una check list suddivisa in alcune domande, come quelle sottoelencate, alle quali l’organizzazione deve rispondere magari considerando anche un grado di maturità:

1. I requisiti e la legislazione applicabile sono stati identificati?
2. I requisiti contrattuali sono stati identificati e applicati?
3. Esiste un processo di verifica della compliance e del suo ciclo di vita?
4. Viene verificata periodicamente la conformità ai requisiti legali in particolare alla protezione dei dati personali?
5. Viene implementato il principio di minimizzazione dei dati?
6. Viene elaborata una DPIA per ogni progetto?
7. Viene rivista l’analisi dei rischi in caso di cambiamenti o nuovi progetti?
8. Quale è il livello di conoscenza sulla sicurezza e sulla mitigazione dei rischi all’interno dell’organizzazione in ambito ML?
9. Esiste un controllo sulle vulnerabilità dei sistemi ML?
10. E’ possibile che la vulnerabilità del ML si possa applicare agli stakeholder esterni?
11. Sono comunicati gli incidenti alle autorità?
12. Sono correttamente raccolti e assemblati i campioni di dati in set di addestramento e validazione?
13. Sono verificati i rischi di parzialità e discriminazione della popolazione in determinati gruppi sociali?
14. Esiste un processo di prevenzione dei pregiudizi e delle discriminazioni?
15. Esiste un processo che verifichi le scelte di modellizzazione con i bias prodotti?
16. I dati di test sono in ambienti separati?
17. Se si utilizzano più set di dati per i modelli viene preservata la protezione dei dati personali?
18. I test sui dati sono validati?
19. Esistono delle metriche di prestazione prima dell’addestramento del modello?
20. Esiste un sistema di monitoraggio dei modelli sviluppati?
21. Il processo decisionale di validazione e monitoraggio è documentato?
22. Vengono effettuati audit di terza parte?
23. L’organizzazione riceve audit di seconda parte?
24. Esiste una documentazione del ciclo di vita dei modelli ML?
25. Sono definite nei progetti le condizioni e i limiti di validità?
26. Vengono analizzati e comunicati gli incidenti?
27. E’ definita e condivisa la catena del valore del modello ML?
28. Sono previste attività in subappalto?
29. I modelli di AI sono utilizzati solo all’interno dell’organizzazione?
30. L’azienda sviluppa modelli di AI per conto terzi?
31. I modelli di AI sviluppati prevedono la supervisione umana?
32. I modelli sono spiegabili e interpretabili?
33. I modelli sono trasparenti?
34. E’ stato calcolato l’impatto di CO2 dell’attività?
35. E’ stato valutato l’impatto sociale?
36. E’ stata affrontata la dimensione etica del modello?

Un altro strumento è quello realizzato dal CNIL “**[Introduction to the self-assessment guide for AI systems](https://www.cnil.fr/en/introduction-self-assessment-guide-ai-systems)”,** una guida all’autovalutazione dei principali problemi di protezione dei dati negli scenari più comuni.

Lo strumento è suddiviso in sette schede dove per ogni argomento, brevemente introdotto, vengono poste alcune domande e richiesti dei commenti esplicativi.

**1) Fare le domande giuste prima di utilizzare un sistema di intelligenza artificiale**

* Obiettivo e proporzionalità
* Fornitori, utenti di sistemi di intelligenza artificiale e individui

**2) Raccolta e qualificazione dei dati di formazione**

* Elaborazione lecita dei dati nel rispetto della normativa
* Dai dati grezzi a un set di dati di formazione di qualità
* Identificare i rischi di parzialità e correggerli in modo efficace

**3) Sviluppo e addestramento di un algoritmo**

* Progettazione e sviluppo di un algoritmo affidabile
* Applicando un meticoloso protocollo ...