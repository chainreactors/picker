---
title: 专题·大模型安全 | AIGC时代大模型的安全风险与防护实践
url: https://mp.weixin.qq.com/s?__biz=MzA5MzE5MDAzOA==&mid=2664224770&idx=2&sn=fc8aac14a041c78cfeb09b9bf33770c6&chksm=8b59dafbbc2e53edd106130b0c9569faa331c461d2885f67a8c1063c98af3361d5c56734b372&scene=58&subscene=0#rd
source: 中国信息安全
date: 2024-09-07
fetch_date: 2025-10-06T18:28:46.617862
---

# 专题·大模型安全 | AIGC时代大模型的安全风险与防护实践

![cover_image](https://mmbiz.qpic.cn/sz_mmbiz_jpg/1brjUjbpg5xMSUJlibptbugF3bBicnzf9SrFgx45pBLhqPUmWq77qFwKCpHF6MSOFWmHNjjZEDfiaO0F4N8RDH3Dg/0?wx_fmt=jpeg)

# 专题·大模型安全 | AIGC时代大模型的安全风险与防护实践

原创

孙松儿

中国信息安全

![](https://mmbiz.qpic.cn/sz_mmbiz_gif/1brjUjbpg5ynhvIsjCPSBGgtxjRZIDdLtx3f9BAQL9qmcRMibcFITYibuOHdbj96JJxFQGSumrqBKyQF6HIpuWRA/640?wx_fmt=gif&from=appmsg)

![](https://mmbiz.qpic.cn/sz_mmbiz_png/1brjUjbpg5ynhvIsjCPSBGgtxjRZIDdL8IwvFpQM8P6Oe5EZoURf3kaPTA5VgkeYvZ8jqicqTUVCz3O8pcLfmyA/640?wx_fmt=png&from=appmsg)

![](https://mmbiz.qpic.cn/sz_mmbiz_gif/1brjUjbpg5ynhvIsjCPSBGgtxjRZIDdLtx3f9BAQL9qmcRMibcFITYibuOHdbj96JJxFQGSumrqBKyQF6HIpuWRA/640?wx_fmt=gif&from=appmsg)

**扫码订阅《中国信息安全》**

邮发代号 2-786

征订热线：010-82341063

文 | 新华三集团高级副总裁、新华三信息安全技术有限公司总裁 孙松儿

当前，生成式人工智能（AIGC）技术飞速发展，尤其是以 GPT 为代表的大语言模型（简称“大模型”）的出现，加速了智能新时代的到来。然而，随着技术的蓬勃发展，大模型的网络安全也面临着巨大的挑战。如何更大程度地发挥大模型的社会和商业价值，促进 AIGC 健康长久发展，已成为业界普遍关注的话题。在此背景下，大模型的安全性成为制约 AIGC 技术发展前景的关键要素。

**一、大模型面临的“三重”安全风险**

大模型作为一种全新的技术手段，加速了各行业从“数字化”走向“智能化”的转变。然而，在人工智能技术与业务深度融合的同时，也带来了诸多潜在的安全风险。经过业务实践，目前大模型主要面临“三重”安全风险。从大模型自身的“内因”来看，大模型训练过程中的训练安全和推理过程中的内容合规是两个关键环节；从“外因”来看，如何防御外部攻击者高度隐蔽、快速迭代的持续精准攻击，成为抵御外部威胁的重点。

* **风险一：大模型训练安全**

**1. 训练数据带来的风险**

大模型在训练过程中通常需要海量的训练数据，然而这些数据中可能存在部分违规内容。这些违规数据会误导大模型，形成错误的引导和不公平的结果，从而产生负面影响。此外，一些描述不准确、完整度不足、内容过时的低质量训练数据也会导致模型训练偏差，输出逻辑混乱的内容，进一步降低大模型训练的效果。

**2. 模型算法自身风险**

大模型通过深度学习等人工智能算法，实现了对海量数据的高效处理与模式识别，极大地提升了人工智能的智能化水平。然而，这些复杂的算法体系也蕴含着诸多安全隐患。

一是算法偏见风险。由于训练数据的局限性和算法自身的局限性，大模型可能存在偏见和歧视性输出，对社会公正和个体权益造成威胁；二是算法可控性风险。随着大模型在关键领域的应用加深，其算法的可控性和稳定性成为重要考量因素，一旦算法失控，可能造成严重的经济损失；三是算法缺陷。攻击者利用算法设计中存在的缺陷引导大模型输出误导性内容，甚至导致大模型失效。

* **风险二：大模型内容合规风险**

虽然大模型具备生成高质量自然语言内容的能力，但受模型训练影响，可能生成有害信息，包括虚假信息、误导性内容以及带有偏见和歧视的言论。这些内容违反社会公序良俗，甚至触犯法律法规。由于大模型强大的生成能力，这类问题可能出现在各种形式的内容中，包括文字、图像、语音和视频等多模态内容。

此外，恶意用户的恶意引导也可能诱使大模型生成意料之外的甚至是恶意的内容输出。这就是所谓的提示注入攻击，攻击者利用大模型基于上下文内容生成响应的特性，通过设计“提示”干扰正常的内容输入，比如在输入问题时加入一些隐晦的指示，以绕过现有的审查体系，生成攻击者希望得到的恶意内容。

* **风险三：大模型运行环境风险**

大模型作为一个重要的业务应用，与其他应用一样面临巨大的安全挑战。由于大模型与垂直领域的深度融合，它逐渐成为攻击者的主要攻击目标。

除了传统的 DDoS 攻击、网络入侵等攻击手段外，攻击者开始针对大模型进行持续、精准的攻击。首先，由于大模型的训练和推理需要依赖海量的硬件资源，攻击者对算力基础设施的攻击逐渐增多；其次，大模型在为内外部用户提供应用服务时，传统保护方案缺乏精细化、动态的访问控制手段，导致数据泄露、越权访问等风险增加；最后，由于大模型的日常访问流量巨大，且作为攻击者的重要目标，攻击手段变得更加复杂和隐蔽。因此，在高吞吐场景下进行加密流量监测已成为重要挑战。

**二、大模型安全防护策略及实践**

2023 年 7 月，国家互联网信息办公室发布《生成式人工智能服务管理办法》，从内容监管、算法监管、数据监管、服务监管以及惩罚监管等多个维度提出全面要求，强调了促进 AIGC 技术健康发展与规范应用的重要性。2024 年 5 月，全国网络安全标准化技术委员会发布《网络安全技术 生成式人工智能服务安全基本要求》（征求意见稿），进一步从技术层面明确了 AIGC 服务的安全能力要求。

因此，面对大模型所面临的三大安全挑战，需要从大模型的训练安全、内容合规安全以及运行环境安全三个方面出发，构建一个更加全面有效、智能动态的网络安全防护体系，实现大模型从训练到推理、从外部环境到内部应用的全面安全。

**（一）训练安全：垂直行业数据安全治理与模型训练**

大模型的训练数据以及其自身算法带来的风险，最终可能导致大模型输出不精准、不正确或不可用的内容。这就需要引入训练数据治理和模型训练微调等手段，以优化算法缺陷，降低大模型自身的偏见，并解决大模型可控性的风险。

数据是大模型训练的基石，因此数据安全治理是降低训练风险的关键。需要确保训练数据的完整性和准确性，剔除不相关、冗余或错误的数据，并将其转换为一致的格式。同时，对数据进行精确的标注，扩展数据集规模，以提升模型的泛化能力。通过不断改进数据治理流程，以提高数据的有效性与安全性。

为了降低大模型自身的算法偏见、可控性和缺陷带来的风险，需要进行多轮的模型训练迭代，持续优化大模型。这包括利用大量且广泛的数据集进行大规模预训练，以及进行定向微调以产生多个候选模型。每个候选模型都需经过风险评估和可用性评估，若评估结果显示模型未达到预期的效果，则需要对模型进行进一步优化。

这种大模型数据治理与螺旋式前进的模型训练和微调方法，构建了一个高度安全的垂直领域大模型共建方案。这不仅降低了大模型的安全风险，还提升了大模型在垂直领域应用的有效性、可靠性和实用性。目前，新华三正在与多家行业头部客户合作共建大模型，在安全前提下满足用户的定制化需求。

**（二）内容合规：大模型内容安全防护**

在满足业务应用需求与国家监管要求的双重考量下，内容安全已经成为大模型实际使用中的“生死红线”。因此，构建一个体系化的大模型内容防护机制显得至关重要。一个出色的大模型内容防护体系应从输入侧、模型侧和输出侧三个层面对大模型进行综合防护。

**在输入侧，**需对用户的输入进行严格审查，以确保其合规性与安全性。当系统监测到用户输入中包含恶意内容时，应立即中止当前会话，以避免潜在的安全风险。这既涉及显而易见的恶意内容，也包括更为隐蔽的恶意指代。

**在模型侧，**管理是内容合规的核心，需要监控用户与大模型交互的全过程。通过实时监测，可以及时发现并阻止恶意用户试图实施的提示注入攻击，避免引导大模型产生违规内容。针对涉及敏感红线问题的情况，由内容安全产品代替回答，以确保回答的客观性和全面性，防止大模型误导用户或传播不合规信息。

**在输出侧，**由于大模型生成的内容具有一定的随机性，因此存在不可控的风险。为此，必须对大模型输出的内容进行持续的检测和审查，重点检测输出内容中是否存在违规内容、侵权内容和隐私泄露的问题，确保用户能获得安全可靠的合法信息。

新华三基于自主研发的“百业灵犀”私域大模型，推出了名为“灵犀卫士”的大模型安全防护体系。该体系从模型的输入侧、模型侧及输出侧为大模型提供全生命周期的安全保护。目前，“灵犀卫士”已在政务、金融、运营商等多个行业进行了落地实践，取得了行业客户的高度认可与信赖。

**（三）运行安全：智算安全底座**

面对新型网络攻击行为的高度隐蔽性、快速迭代、持续攻击和精准打击，企业在构建和运行大模型时必须高度重视其运行环境的安全性。通过加强算力基础设施监控、业务访问控制和加密流量监测等措施，企业可以有效防范和应对各类攻击威胁，确保大模型安全稳定运行。

由于大模型业务依赖于海量算力资源，其在运行过程中面临着漏洞利用、网络攻击、数据泄漏等安全风险。为了应对这些潜在的威胁，需要我们在现有安全防护体系的基础上，进一步根据大模型的特性进行细化和补充，以提升大模型的整体安全防护能力，确保业务的安全可靠性。

**在基础设施层面，**海量算力服务器是大模型运行的基石。为了确保持久稳定的算力支持，必须加强对硬件设施的持续监控和监管。应建立完善的算力服务器监测体系，实时监测算力服务器的运行状态，及时发现并应对硬件故障或异常状况。

**在业务访问层面，**大模型的用户包括外部用户和内部用户，他们各自拥有不同的访问权限，因此，实施有效的访问权限控制以及快速动态的授权机制至关重要。在传统防护体系的基础上，我们可以进一步引入零信任安全模型，根据业务需求和用户状态来快速调整权限，从而避免“一次授权、持续访问”所带来的安全风险。

**在流量监管层面，**大模型产生了大量的业务流量，其中可能隐藏着各种形式的加密攻击。因此，提升对加密流量的监测能力成为防范这类攻击的关键所在。通过引入先进的流量分析工具和技术进行详细的流量分析和异常检测，我们能够识别潜在的安全威胁，并采取相应的防御措施来保障大模型的正常运行。

**三、结 语**

人工智能的发展势头强劲，其技术与业务的深度融合也将不断深化。但不可忽视的是，安全作为保障 AIGC 的核心基石，拥有至关重要的业务价值。如果缺乏安全保障，人工智能产业化落地将缺乏稳固的根基，难以持续发展。更重要的是，大模型的安全发展需要与行业场景深度融合，才能让大模型真正应用于实际。因此，大模型的安全建设需要实战化、行业化、场景化。只有在实战中不断锤炼大模型的安全能力，才能应对日益复杂的攻防挑战；只有紧密贴合行业需求，才能持续增强模型的专业能力，使大模型真正变得安全可靠。

（本文刊登于《中国信息安全》杂志2024年第6期）

**分享网络安全知识 强化网络安全意识**

**欢迎关注《中国信息安全》杂志官方抖音号**

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/1brjUjbpg5ynhvIsjCPSBGgtxjRZIDdLefI4H4mhtibLFZS8pTP01FHIs5icib3SGNSdrEmmBzZN2SopvWwVwt4SA/640?wx_fmt=jpeg&from=appmsg)

**《中国信息安全》杂志倾力推荐**

**“企业成长计划”**

**点击下图 了解详情**

[![](https://mmbiz.qpic.cn/sz_mmbiz_png/1brjUjbpg5ynhvIsjCPSBGgtxjRZIDdLKt5siciaMJyULhRN8HuH912hKCW8Gc4FSibviceNhIicClDiat9Kibw4wWc9g/640?wx_fmt=png&from=appmsg)](http://mp.weixin.qq.com/s?__biz=MzA5MzE5MDAzOA==&mid=2664162643&idx=1&sn=fcc4f3a6047a0c2f4e4cc0181243ee18&chksm=8b5ee7aabc296ebc7c8c9b145f16e6a5cf8316143db3edce69f2a312214d50a00f65d775198d&scene=21#wechat_redirect)

预览时标签不可点

![]()

微信扫一扫
关注该公众号

继续滑动看下一个

轻触阅读原文

![](http://mmbiz.qpic.cn/sz_mmbiz_png/1brjUjbpg5xcg6pmGiagMsJTqnHObJGHSj6TEe6InbwlHLIxFVhPohvicQibAcuia5wDEoRISsAkUyYPUB06cU9mibw/0?wx_fmt=png)

中国信息安全

向上滑动看下一个

知道了

![]()
微信扫一扫
使用小程序

取消
允许

取消
允许

取消
允许

×
分析

![跳转二维码]()

![作者头像](http://mmbiz.qpic.cn/sz_mmbiz_png/1brjUjbpg5xcg6pmGiagMsJTqnHObJGHSj6TEe6InbwlHLIxFVhPohvicQibAcuia5wDEoRISsAkUyYPUB06cU9mibw/0?wx_fmt=png)

微信扫一扫可打开此内容，
使用完整服务

：
，
，
，
，
，
，
，
，
，
，
，
，
。

视频
小程序
赞
，轻点两下取消赞
在看
，轻点两下取消在看
分享
留言
收藏
听过